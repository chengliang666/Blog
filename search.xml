<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[调第三方厂家接口实现文件文件上传httpclient]]></title>
    <url>%2F20210810%2F%E8%B0%83%E7%AC%AC%E4%B8%89%E6%96%B9%E5%8E%82%E5%AE%B6%E6%8E%A5%E5%8F%A3%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0httpclient.html</url>
    <content type="text"><![CDATA[前言这种情况算是很少见的，前端上传文件到服务端，服务端接收文件，再调第三方接口，将文件存到第三方服务器。 从客户端接收文件的就不说了，比较常见，就记录下调第三方接口带参数。 代码url为路径jsonObject为常规的请求参数token 为鉴权file 为文件。大伙根据自己的需求进行修改。核心代码为： 12345678910111213141516MultipartEntityBuilder reqEntity = MultipartEntityBuilder.create();reqEntity.addBinaryBody("file", new FileInputStream(file), ContentType.DEFAULT_BINARY, file.getName()); Iterator iter = jsonObject.entrySet().iterator(); while (iter.hasNext()) &#123; Map.Entry entry = (Map.Entry) iter.next(); System.out.println(entry.getKey().toString()); System.out.println(entry.getValue().toString()); StringBody value = new StringBody(entry.getValue().toString(), ContentType.create("text/plain", Consts.UTF_8)); reqEntity.addPart(entry.getKey().toString(),value); &#125; HttpEntity httpEntity = reqEntity.build(); HttpPost httppost = new HttpPost(urlBuilder.toString()); httppost.setEntity(httpEntity); 主要是使用MultipartEntityBuilder 将文件通过body 进行传输。完整方法代码。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public static String sendPost(String url, JSONObject jsonObject, String token,File file) &#123; StringBuilder urlBuilder = new StringBuilder(baseURLPath); urlBuilder.append(url); log.info("URL:" + url); log.info("Parm:" + jsonObject); FileBody fileBody=new FileBody(file); MultipartEntityBuilder reqEntity = MultipartEntityBuilder.create(); try &#123; reqEntity.addBinaryBody("file", new FileInputStream(file), ContentType.DEFAULT_BINARY, file.getName()); Iterator iter = jsonObject.entrySet().iterator(); while (iter.hasNext()) &#123; Map.Entry entry = (Map.Entry) iter.next(); System.out.println(entry.getKey().toString()); System.out.println(entry.getValue().toString()); StringBody value = new StringBody(entry.getValue().toString(), ContentType.create("text/plain", Consts.UTF_8)); reqEntity.addPart(entry.getKey().toString(),value); &#125; HttpEntity httpEntity = reqEntity.build(); HttpPost httppost = new HttpPost(urlBuilder.toString()); httppost.setEntity(httpEntity); setHttpHeader(httppost, token); RequestConfig config = RequestConfig.custom() .setConnectTimeout(1000) .setConnectionRequestTimeout(1000) .setSocketTimeout(10 *1000) .build(); //数据传输的超时时间 httppost.setConfig(config); String result = getPostResult(httppost); log.info(result); return result; &#125; catch (Exception e) &#123; log.error(e); return ""; &#125; &#125;private static void setHttpHeader(HttpPost httppost, String token) &#123; httppost.setHeader("Authorization", "Bearer " + token); &#125;/** * 获取post请求返回结果 * * @param httppost * @return */ private static String getPostResult(HttpPost httppost) &#123; String result = null; try (CloseableHttpResponse response = httpclient.execute(httppost);) &#123; HttpEntity entity = response.getEntity(); result = EntityUtils.toString(entity); if (result.contains("Invalid token")) &#123; result = "Token 过期，请重新登录"; &#125; &#125; catch (Exception e) &#123; log.error(e.toString()); result = "HTTP请求异常,请重试"; &#125; return result; &#125; 使用的是httpclient。1234567891011121314151617181920212223242526272829303132&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpcore-nio&lt;/artifactId&gt; &lt;version&gt;4.4.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpcore&lt;/artifactId&gt; &lt;version&gt;4.4.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient-win&lt;/artifactId&gt; &lt;version&gt;4.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient-cache&lt;/artifactId&gt; &lt;version&gt;4.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpasyncclient&lt;/artifactId&gt; &lt;version&gt;4.0-beta3&lt;/version&gt; &lt;/dependency&gt;]]></content>
      <categories>
        <category>springBoot番外篇</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
        <tag>上传文件</tag>
        <tag>httpclient</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单优雅的搭建个人博客]]></title>
    <url>%2F20210810%2F%E7%AE%80%E5%8D%95%E4%BC%98%E9%9B%85%E7%9A%84%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2.html</url>
    <content type="text"><![CDATA[前言啊啊啊~~~ ,经过差不多两天的持续摸索优化，个人博客算是初步完成了，现在自己看的效果还是非常不错的。这篇文章就是讲我怎么搭建一个这样的博客的。早在17年的时候就用hexo 结合github搭建过个人博客，但是那时候还太年轻，也没有维护，后面就废掉了。18年的时候又一时兴起搭建了一个。比17年的时候好看些，但是没有什么访问量，可能没有做seo 优化，也没有维护多长时间就放着了，前几天上去看，界面显示都还正常，就是内容太幼稚了。所以时隔一年，我胡汉三又回来了。痛下决心，把整体的博客都搭建好了，包含界面渲染，RSS,评论系统，站内搜索，seo 优化等等。现在让我们开始吧。博客传送门：coding:http://quellanan.coding.me/ github:https://quellanan.github.io/ 最终效果我们先来看看效果吧，这样对你们可能更有吸引力，更有动力搭建一个属于自己的bolg 啦。 主页面是这样的，包含首页、标签、分类、归档、关于、互动、搜索、还有右侧的主页。最喜欢标签这一页，可以看出整个网站对哪一类的文章写的比较多。 还可以通过标签找到对应的文章。还有就就是页脚的网站统计，页面访问人数和访问量的统计。已经整个站点博文的字数。这些相信都是自建博主们最关心的。我也是最关心这部分哈哈，毕竟访问量和人数上去了就有持续更新的动力啦。打赏功能，已经版权申明，还有侧边的文章目录也是超赞的。 评论功能，这个评论也是很给力的吧，增加了博主和读者之间的交流。和评论类似还有一个，就是网站右下角那个类似微信图标的那个，那个也是可以直接和博主沟通的哟，不赖吧。这些只是网站的一部分功能，其他的就不说了，开始动手吧 环境准备 安装git：https://git-scm.com/book/zh/v2/起步-安装-Git安装git 之后又配置用户名和邮箱，和github 一致 1234#全局配置用户名git config --global user.name "nameVal"#全局配置邮箱git config --global user.email "eamil@qq.com" 安装node.js：https://nodejs.org/en/这两个不管你linux 还是windows 都非常好安装，网上关键字搜索一下，有官方教程。 注册github登录账号：https://github.com/创建好和用户名一样的项目 注册coding登录账号：https://coding.net/login也是一样的，创建一个和名称相同的项目。这里说一下为什么要用coding，其实不用也可以，coding 和github 的作用一样的，都是作为pages 以及使用他们的域名。不同的是github 是国外的，而coding 是国内的。github搭建的博客不容易被百度检索到，而coding 可以。大家可以根据个人喜好选择吧。这里我是两个都用了，反正就多一条配置。 配置秘钥12$ cd ~$ ssh-keygen -t rsa -C "your_email@youremail.com" 将生成的秘钥配置到github 和coding 上就好了 安装hexo安装好git 和node 之后，安装hexo 就很方便1npm install hexo-cli -g 随后我们创建一个blog 文件夹，用来存放我们的blog.123cd bloghexo initnpm install 这样基本的框架就已经搭建好了，可以启动看下效果1234hexo clean //清缓存hexo g //编译hexo s //本地运行hexo d // 上传到github 或者coding 主题选择在搭建好框架之后，现在当然是找一个自己喜欢的主题啦，我个人比较喜欢next ,然后就在网上找了一个next 主题，功能配置基本都有了，我就是参照这个大佬的配置过来的。 配置：https://github.com/ipyker/hexo-next-theme 将这位大佬的主题下载下来后，放到我们自己的主题中去就好了。常见的修改按照这位大佬提示的修改就可以。 保存源码好了，主题和框架都有了，那接下来其实写博客发布就好了，其实前面的我前两年走到这里了，所以前面没有很细的讲。但是有一些基础的人应该都可以做到，如果不行，可以通过我提到的关键字搜索也可以在网上找到详细的教程。为什么这次又要重新搭建，因为之前没有保存源码，导致github 上只存了pages 的代码。没有保存源码，所以如果源码丢了就得重新搭建了。所以这次学聪明了知道保存源码，不管是换电脑还是什么的，做号备份就不怕了。我这里讲源码保存在github 上，我们在github项目项目上创建一个分支 save，用来保存源码。master 分支用来pages页面展示。将创建的save 分支设置为默认分支。 然后在本地clone 项目。进入项目123git add .git commit -m "your description"git push origin save 我们 _config.yml 配置是提交到 master 分支 123456deploy: type: git repository: github: git@github.com:QuellanAn/QuellanAn.github.io.git coding: git@git.dev.tencent.com:quellanan/QuellanAn.git branch: master 现在开始，之后的操作就简单了。想要编译发布就 123hexo clean hexo ghexo d 保存到github就12345git pull git add .git statusgit commint -m "description"git push origin save 我博文的源码地址：https://github.com/QuellanAn/QuellanAn.github.io这些都是我已经配置好了，你们可以直接clone下来，进入 blog 文件夹然后进行运行修改就可以了。所以我前面都讲的比较简单。 SEO现在我们博客已经建好了，我们要新增博客的话在source / _posts 目录下增加就好了。 但是我们现在面临的一个问题是，我们的博客没有访问量怎么办，不能通过谷歌搜索和百度搜索搜索到，而是需要直接通过输入准确的网址进行访问，这样肯定是不利于我们增加博客浏览量的。所以我们需要将我们的网址添加到百度和谷歌搜索中。 谷歌：https://search.google.com/search-console将下载的html 放到public 文件夹下。然后12hexo ghexo d 发布到我们的网站上。然后进行验证就可以验证通过。这个验证之后，我们再提交站点地图。站点地图我都配置好了，如果你们用我的模版的话，直接在网站站点地图提交就好了 这样过段时间谷歌就能搜索到你的博客啦。 百度提交站点：https://ziyuan.baidu.com/site/index添加网站，验证方法和google 是一样的，都用html 文件验证就好了验证完成之后，点击Robots,检测并更新。我的模版里面已经配置好了。可以直接检测到。 虽然我做了这些，但是好像百度还没有搜录，还得再等两天再看看。 番外好了，到此为止，个人博客搭建就到这这里了，大家如果也想要搭建一个自己的博客，可以把文中说的准备工作做好，然后自己下载我的源码来用，把信息修改成自己的就好了。有什么不懂了可以及时加我微信沟通。因为我模版里，我的博文原稿都在里面，所以各位用的时候记得删掉，或者记得标记为转载谢谢❤ 可能讲的内容不够详细，没有细节没有讲到，对小白不太友好，但是考虑到其实网上有很多详细的教程，我这里就把我认为重要的讲了出来，希望对大家有帮助。 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>个人博客</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将个人博客迁移到云服务器上]]></title>
    <url>%2F20210810%2F%E5%B0%86%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E5%88%B0%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A.html</url>
    <content type="text"><![CDATA[前言之前通过github 和coding 来搭建的个人博客，但是搜索引擎一直不是很好，并且总感觉不稳定，访问很慢。最近刚刚买了一个云服务器，所以就打算将个人博客迁移到云服务器上。 服务器环境准备我们登录云服务器，主要做一些准备工作。 安装git1yum install git 创建git 用户这里我们需要创建一个git 用户来做服务器库。方便我们本地将文件推送到服务器库。12adduser gitsudo passwd git 然后给git 用户分配root 权限。12chmod 740 /etc/sudoersvi /etc/sudoers 改好之后，修改会权限1chmod 400 /etc/sudoers 上面这些都是在root 用户下操作的。 SSH 配置想要我们本地直接推送文件到服务器上，需要配置SSH连接了。所以我们在自己本地生成ssh秘钥。1ssh-keygen 然后copy 下id_rsa.pub的内容。上面是本地操作的，接下来，我们上我们服务器，进入git 用户根目录下。12345su gitcd ~mkdir .sshcd .sshvim authorized_keys authorized_keys 文件的内容就是我们本地复制的秘钥。这样本地就可以和服务器进行免密登录啦。 服务器创建仓库现在我们切换到root 用户操作。12345678#repo作为为Git仓库目录mkdir /var/repochown -R git:git /var/repochmod -R 755 /var/repo#hexo作为网站根目录mkdir /var/www/hexochown -R git:git /var/www/hexochmod -R 755 /var/www/hexo 上面的操作后，这两个文件的用户和用户组都是git . 做完上面这些，切换到git 用户操作。进入到 /var/repo 目录下，初始化一个git仓库12cd var/repogit init --bare blog.git 创建一个新的 git 钩子，用于自动部署 在 /var/repo/blog.git 下，有一个自动生成的 hooks 文件夹。我们需要在里边新建一个新的钩子文件 post-receive。1vim /var/repo/hexoBlog.git/hooks/post-receive post-receive 内容如下:12#!/bin/bashgit --work-tree=/var/www/hexo --git-dir=/var/repo/blog.git checkout -f 增加post-receive 文件的写权限1chmod 755 post-receive 好了，服务器上的配置到此就都配置好了。 本地配置修改我本地已经安装了nodeJS、git、hexo 这些东西，所以这些就不说了。我进入本地的博客目录。主要是修改_config.yml 配置。url 修改为你的域名或者云服务器的外网ip 地址。1234deploy: type: git repo: git@192.168.1.51:/var/repo/blog.git branch: master deploy 推送到我们云服务上，IP就是我们云服务器的ip，可以指定端口，表示访问到是什么端口，不指定的话，就是默认的80 端口。修改好之后，就在当前目录下打开 git base123hexo clean //清除hexo g //编译hexo d //上传发布 在执行hexo d 可能会报错，我报错的第一个本地git 版本低导致的，所以升级一下本地git 版本，在git base 中执行1$ git update-git-for-windows 还有可能提示没有权限创建文件，这主要是我们需要用git 用户来初始化仓库。按照我前面的操作的来，就不会出现这个问题。 nginx 部署hexo d 执行成功的话。我们还差最后一步，才能在浏览器上访问。我们需要配置nginx 。至于下载nginx和 安装可以看这篇文章，这里就不说了。centOS7 安装nginx 我们进入/usr/local/nginx/conf/目录下。修改nginx.conf 文件。 1234location / &#123; root /var/www/hexo; index index.php index.html index.htm default.php default.htm default.html; &#125; 路径指向我们存放的/var/www/hexo 才可以。最后我们就可以通过域名或者IP访问个人博客啦。由于我的域名备案还没有下来，所以暂时用的是IP 访问的，等域名备案下来了，就可以用域名访问啦。 现在将个人博客搭建在了自己的服务器上，关于SEO的问题应该会好解决一些。百度和谷歌的SEO等我域名备案下来了再弄一波吧，现在先暂时这样吧就。]]></content>
      <categories>
        <category>个人博客</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何优雅实现属性的动态注入]]></title>
    <url>%2F20210810%2F%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%AE%9E%E7%8E%B0%E5%B1%9E%E6%80%A7%E7%9A%84%E5%8A%A8%E6%80%81%E6%B3%A8%E5%85%A5.html</url>
    <content type="text"><![CDATA[前言这是在实际开发项目中遇到的一个问题。从数据库查询返回的 List&lt; Map&lt; String, Object>> 的集合。并且返回的列名是中文的，项目也没有使用mybatis 直接使用的jdbcTemplate. 并且字段还超级多，这样将数据转换的时候如果一个一个的注入就会让代码臭长臭长的，所以才有了动态注入。我这里我整个思路都贴出来。 实例类Entry我们先建一个entry类。用于对象存储。我这里 创建一个BaseDateBean 的类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374@Setter@Getterpublic class BaseDateBean &#123; private String startTime; private String operator; private String code; private String testNumber; private String iphoneCardCode; private String sampleNumber; private String sampleTime; private String callNumber; private String callStatus; private String downInstantaneousSpeedCard; private String upInstantaneousSpeedCard; private String ssid; private String bssid; private String encryptType; private String intranetIp; private String externalIp; private String rssi; private String WIFIFrequency; private String WIFIChannel; private String baiduLongitude; private String baiduLatitude; private String originalLongitude; private String originalLatitude; private String positioningPrecision; private String positioningType; private String businessType; private String networkType; private String speedType; private String tac; private String eci; private String mnc; private String mcc; private String rsrq; private String earfcnDl; private String earfcnUl; private String frequencyDl; private String band; private String sinr; private String cdmaRxlev; private String evdoRxlev; private String earfcn; private String psc; private String uarfcn; private String rscp; private String rsrp; private String imsi; private String imei; private String lac; private String ci; private String signalStrength; private String snr; private String pci; private String nid; private String bid; private String sid; private String cdmaDbm; private String cdmaEcio; private String evdoDbm; private String evdoEcio; private String evdoSnr; private String arfcn; private String frequencyUl; private String bsic; private String rxlev; private String averageSpeed; private String updatedLongitude; private String updatedLatitude; private String averageUpstreamRate; private String averageDownstreamRate;&#125; 可以看到在实际项目中属性还是很多的，我这个还只是初版的，所以如果一个一个的set注入就很low了。 创建map映射在创建好实体类后，还得创建一个静态的map 集合，将数据库的列名和我们实体类的属性名做一个一一对应。这里创建的这个map 集合是我个人愚见。没有想到更好的办法就先这样处理的。我们创建一个BaseDataMap类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public class BaseDataMap&#123; private BaseDataMap()&#123;&#125; public static final Map&lt;String,String&gt; cnEnMap=new HashMap&lt;&gt;(); static&#123; cnEnMap.put("测试开始时间","startTime"); cnEnMap.put("运营商","operator"); cnEnMap.put("编号","code"); cnEnMap.put("测试编号","testNumber"); cnEnMap.put("手机卡编号","iphoneCardCode"); cnEnMap.put("采样编号","sampleNumber"); cnEnMap.put("采样时间","sampleTime"); cnEnMap.put("呼叫编号","callNumber"); cnEnMap.put("呼叫状态","callStatus"); cnEnMap.put("下行瞬时速度","downInstantaneousSpeedCard"); cnEnMap.put("上行瞬时速度","upInstantaneousSpeedCard"); cnEnMap.put("SSID","ssid"); cnEnMap.put("BSSID","bssid"); cnEnMap.put("加密类型","encryptType"); cnEnMap.put("内网IP","intranetIp"); cnEnMap.put("外网IP","externalIp"); cnEnMap.put("RSSI","rssi"); cnEnMap.put("WIFI频率","WIFIFrequency"); cnEnMap.put("WIFI信道","WIFIChannel"); cnEnMap.put("百度经度","baiduLongitude"); cnEnMap.put("百度纬度","baiduLatitude"); cnEnMap.put("原始经度","originalLongitude"); cnEnMap.put("原始纬度","originalLatitude"); cnEnMap.put("定位精度","positioningPrecision"); cnEnMap.put("定位类型","positioningType"); cnEnMap.put("数据业务类型","businessType"); cnEnMap.put("网络类型","networkType"); cnEnMap.put("速度类型","speedType"); cnEnMap.put("TAC","tac"); cnEnMap.put("ECI","eci"); cnEnMap.put("MNC","mnc"); cnEnMap.put("MCC","mcc"); cnEnMap.put("RSRQ","rsrq"); cnEnMap.put("EARFCN DL","earfcnDl"); cnEnMap.put("EARFCN UL","earfcnUl"); cnEnMap.put("FREQUENCY DL","frequencyDl"); cnEnMap.put("BAND","band"); cnEnMap.put("SINR","sinr"); cnEnMap.put("CDMA RXLEV","cdmaRxlev"); cnEnMap.put("EVDO RXLEV","evdoRxlev"); cnEnMap.put("EARFCN","earfcn"); cnEnMap.put("PSC","psc"); cnEnMap.put("UARFCN","uarfcn"); cnEnMap.put("RSCP","rscp"); cnEnMap.put("RSRP","rsrp"); cnEnMap.put("IMSI","imsi"); cnEnMap.put("IMEI","imei"); cnEnMap.put("LAC","lac"); cnEnMap.put("CI","ci"); cnEnMap.put("信号强度","signalStrength"); cnEnMap.put("SNR","snr"); cnEnMap.put("PCI","pci"); cnEnMap.put("NID","nid"); cnEnMap.put("BID","bid"); cnEnMap.put("SID","sid"); cnEnMap.put("CDMA DBM","cdmaDbm"); cnEnMap.put("CDMA ECIO","cdmaEcio"); cnEnMap.put("EVDO DBM","evdoDbm"); cnEnMap.put("EVDO ECIO","evdoEcio"); cnEnMap.put("EVDO SNR","evdoSnr"); cnEnMap.put("ARFCN","arfcn"); cnEnMap.put("FREQUENCY UL","frequencyUl"); cnEnMap.put("BSIC","bsic"); cnEnMap.put("RXLEV","rxlev"); cnEnMap.put("速率","averageSpeed"); cnEnMap.put("更正后经度","updatedLongitude"); cnEnMap.put("更正后纬度","updatedLatitude"); cnEnMap.put("上行平均速率","averageUpstreamRate"); cnEnMap.put("下行平均速率","averageDownstreamRate"); &#125;&#125; 可以看到就是一个动态的map。 映射类接下来就是核心代码啦。我们创建一个ReflectHelper类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Slf4jpublic class ReflectHelper &#123; private Class cls; /** * 传过来的对象 */ private Object obj; private Hashtable&lt;String, Method&gt; getMethods = null; private Hashtable&lt;String, Method&gt; setMethods = null; public ReflectHelper(Object o) &#123; obj = o; initMethods(); &#125; public void initMethods() &#123; getMethods = new Hashtable&lt;&gt;(); setMethods = new Hashtable&lt;&gt;(); cls = obj.getClass(); Method[] methods = cls.getMethods(); // 定义正则表达式，从方法中过滤出getter / setter 函数. String gs = "get(\\w )"; Pattern getM = Pattern.compile(gs); String ss = "set(\\w )"; Pattern setM = Pattern.compile(ss); // 把方法中的"set" 或者 "get" 去掉,$1匹配第一个 String rapl = "$1"; String param; for (int i = 0; i &lt; methods.length; i) &#123; Method m = methods[i]; String methodName = m.getName(); if (Pattern.matches(gs, methodName)) &#123; param = getM.matcher(methodName).replaceAll(rapl).toLowerCase(); getMethods.put(param, m); &#125; else if (Pattern.matches(ss, methodName)) &#123; param = setM.matcher(methodName).replaceAll(rapl).toLowerCase(); setMethods.put(param, m); &#125; &#125; &#125; public boolean setMethodValue(String property,Object object) &#123; Method m = setMethods.get(property.toLowerCase()); if (m != null) &#123; try &#123; // 调用目标类的setter函数 m.invoke(obj, object); return true; &#125; catch (Exception ex) &#123; ex.printStackTrace(); return false; &#125; &#125; return false; &#125;&#125; 上面代码可以看到其实也就两个方法setMethodValue 和initMethods 。initMethods 方法是在实例化 ReflectHelper 这个类的时候执行的，主要的工作就是找到我们需要动态注入实例类的get 和set 方法。而setMethodValue 方法就是给这个属性赋值的。 实现方法 现在准备工作做好了，怎么使用呢? 1234567891011121314151617181920212223private List&lt;BaseDateBean&gt; getBaseDateBean(List&lt;Map&lt;String, Object&gt;&gt; mapList)&#123; List&lt;BaseDateBean&gt; list=new ArrayList&lt;&gt;(); if(mapList==null||mapList.isEmpty())&#123; return list; &#125; BaseDateBean baseDateBean; for(Map&lt;String, Object&gt; map:mapList)&#123; baseDateBean=new BaseDateBean(); for(Map.Entry&lt;String, Object&gt; entry : map.entrySet())&#123; String mapKey = entry.getKey(); log.info(mapKey); ReflectHelper reflectHelper = new ReflectHelper(baseDateBean); log.info(BaseDataMap.cnEnMap.get(mapKey)); String value=entry.getValue()==null?ConstantPool.SEPARATORNULL:entry.getValue().toString(); log.info(value); if(entry.getValue()!=null)&#123; reflectHelper.setMethodValue(BaseDataMap.cnEnMap.get(mapKey),String.valueOf(entry.getValue())); &#125; &#125; list.add(baseDateBean); &#125; return list; &#125; 遍历list 集合中的map，动态的将属性值注入到实体类中。 番外 我这里是适合我业务开发设计的思路，给大家借鉴参考。 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>动态注入</tag>
        <tag>映射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四、docker 仓库(让我们的镜像有处可存)]]></title>
    <url>%2F20210810%2F%E5%9B%9B%E3%80%81docker%20%E4%BB%93%E5%BA%93(%E8%AE%A9%E6%88%91%E4%BB%AC%E7%9A%84%E9%95%9C%E5%83%8F%E6%9C%89%E5%A4%84%E5%8F%AF%E5%AD%98).html</url>
    <content type="text"><![CDATA[前言前面讲完了docker 镜像和容器，以及通过Dockerfile 定制属于我们自己的镜像，那那现在就是需要将我们自己定制的镜像存放到仓库中供他们使用。这一套流程才算是正式走完了。从获取镜像，操作镜像容器，定制镜像，上传镜像。会了这些，也算是docker 正式入门了。 上传到共有仓库docker 官网有一个共有的仓库，大家应该都知道，和github 类似。dockehub可以管理你自己的镜像。我们需要创建一个账号用来管理。 官网：https://hub.docker.com/ 我们创建好账号后，就可以在我们本机的电脑上登录到官网了。1docker login 用户名 网址 网址可以不填，默认的就是去登录官网，登录官网之后就可以上传我们自己的镜像了1234docker push [OPTIONS] NAME[:TAG]eg:docker push quellanan/hello:1.0.0 我这截图是上传过一次，再上传的时候提示已经存在，说明是上传成功的。我们可以查看一下：1docker search quellanan 私有仓库docker 官方提供了一个私用仓库的镜像，我们可以直接使用。docker-registry. 下载我们先下载registry 镜像1docker pull registry 容器运行1docker run -d -p 5000:5000 --restart=always --name registry registry 到现在我们私有仓库已经有了，现在我们如何将自己本地镜像上传私有仓库呢？ 上传首先我们需要使用docker tag 将镜像重命名，前缀需要和私用仓库一致，才能上传成功。12docker tag java:8 127.0.0.1:5000/java:8docker push 127.0.0.1:5000/java:8 通过下面命令查看是否成功1docker push 127.0.0.1:5000/java:8 上面证明我们已经将镜像上传到我们的私有仓库了。 下载那现在我们先将本地的镜像删除掉，然后从私服上下载镜像，看是否能够下载下来。123docker image rm 127.0.0.1:5000/java:8docker pull 127.0.0.1:5000/java:8 证明我们创建的私服是可以用的，但是有没有感觉有点别扭，不能想dockerhub 那样直观的查看我们私有仓库的镜像，没有可视化界面。所以接下来我们用另一个镜像来搭建我们私有仓库。 Nexus3Nexus 是管理maven 的jar 包工具，Nexus3 支持对镜像的管理。 下载我们先下载nexus3的镜像1docker pull sonatype/nexus3 启动下载成功后，我们来启动对应的容器。1docker run -d --name nexus3 --restart=always -p 8081:8081 -p 8082:8082 -p 8083:8083 --mount src=nexus-data,target=/nexus-data sonatype/nexus3 这里说明一下为什么要启动三个端口。8082是私有仓库，不启动的话，好像我们本地根本连不上去，一直报超时。8083为后面代理dockerhub 做准备。 容器启动之后我们在页面上访问1192.168.252.53:8081 可以看到我们的 nexus3的镜像已经启动成了，我们需要登录才能进行配置。网上说的用户名为admin，密码为admin123 我试了发现登录不上去。 然后看提示说密码存放在这个位置，所以我们进入到容器。查看我们的密码。123docker psdocker exec -it /bin/bashcat /nexus-data/admin.password 找到密码后，我们在界面登录后，会让我们修改密码。 配置登录成功后，我们开始配置我们docker的私有仓库。选择Create Repostory 选择docker(hosted) 配置仓库名和端口 这些都配置好了，现在我们怎么使用这个私有仓库呢，我们在/etc/docker/daemon.json 文件中加上私有仓库的地址。1234567&#123; "registry-mirrors": [ "https://registry.docker-cn.com", "https://dockerhub.azk8s.cn" ], "insecure-registries":["192.168.252.53:8082","192.168.252.53:8083"]&#125; registry-mirrors 是配置国内镜像，不需要的可以不配置。insecure-registries 就是设置我们自己的私有仓库地址。 重启12systemctl daemon-reloadsystemctl restart docker 测试现在我们来登录上我们私有仓库(密码我改成了admin123)1docker login -u admin -p admin123 192.168.252.53:8282 一样的我们打标签。1docker tag java:8 192.168.252.53:8082/java:8 上传1docker push 192.168.252.53:8082/java:8 可以看到我们已经将镜像上传的nexus 上了，我们现在在界面上看下。整个的界面就是这样的。 说明我们用 nexus3 搭建的私有仓库是没有问题的。 Nexus3 代理仓库上面我们只是配置了docker(host)，这个相当于我们的私有仓库，但是我们现在使用docker login 我们自己的仓库，如果我们需要的镜像我们仓库没有，就会很麻烦，需要重新登录到共有仓库上下载下来，再上传到我们的私有仓库，那有没有办法可以一步到位呢？ 下面我们就来操作一波。 docker(proxy)上面我们已经配置好了私有仓库的不用动，下面我们来配置代理仓库， 选择docker(proxy),name 自定义。主要的Proxy 这里需要注意一下。1https://registry-1.docker.io docker(group)端口设置8083 将代理的和个人仓库加到group中 这样上面就配置好了。 番外这篇算是马马虎虎的写完了吧，但总感觉不经如意，又不知道怎么修改，就先这样发出来吧，后续调整。 好了，就说这么多啦 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四、Spring Cloud之熔断处理 Hystrix]]></title>
    <url>%2F20210810%2F%E5%9B%9B%E3%80%81Spring%20Cloud%E4%B9%8B%E7%86%94%E6%96%AD%E5%A4%84%E7%90%86%20Hystrix.html</url>
    <content type="text"><![CDATA[前言熔断处理什么呢？在微服务项目中，有很多的服务，在服务消费者调用服务提供者的时候可能会出现网络异常或者请求超时或者阻塞等等一系列问题，不过不进行处理的话，就可能导致，长时间等待，进程阻塞，最终导致系统瘫痪。 所以就有了熔断处理，当服务提供者的接口不能访问或者异常异常时，进行降级处理，服务消费者能够正常的处理返回特定是数据。从而达到容灾的目的。 看了一下Hystrix ，其实有很多东西，我们就先来看看Hystrix 的简单使用，由于上节我们也说了Fegin 中集成了Hystrix 和ribbon .所以我们就直接使用Fegin 来实现一个简单的熔断处理的操作。 pom.xml其实我们完全可以在上一节的ribbon-consumer 的基础上来，我这里为了保持独立性，所以copy 了一份ribbon-consumer 改成hystrix-consumer。pom文件引入fegin 的依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 在主类中增加@EnableFeignClients，其实这里仅仅使用hystrix 的话，可以使用@EnableCircuitBreaker。 application.properties配置文件中开启熔断处理,将feign.hystrix.enabled设置为tue12#开启熔断处理feign.hystrix.enabled=true fallback重点来啦，我们上一节在HelloService 中调服务提供者的接口，所以要做熔断处理的话，就需要在这里进行降级处理，就需要写一个降级处理的方法，如果服务提供者的接口不通，就调用这个方法，返回给客户端。所以我们在server层创建一个fallback 文件夹，在fallback 包下创建HelloServiceFallback类实现 HelloService。内容如下：12345678910111213141516171819202122@Componentpublic class HelloServiceFallback implements HelloService &#123; @Override public String hello() &#123; return "hello error"; &#125; @Override public String hello2(@RequestParam(value = "name") String name) &#123; return "hello2 error"; &#125; @Override public String hello3(@RequestParam(value = "name") String name, @RequestParam(value = "age") String age) &#123; return "hello3 error"; &#125; @Override public String hello4(@RequestBody Map&lt;String, Object&gt; parms) &#123; return "hello4 error"; &#125;&#125; 注意给整个类加上@Component 注解，然后就是实现HelloService 中的方法啦。 然后我们需要在HelloService 中的@FeignClient 注解做修改1@FeignClient(name = "ribbon-provider",fallback = HelloServiceFallback.class) name 用来指定服务提供者的服务名，fallback 用来指定降级处理的类。这里就是我们刚刚写HelloServiceFallback。好了我们来启动项目测试一下。启动这三个项目，分别是注册中心，服务提供者hystrix-consumer，服务消费者ribbon-provider-9004然后我们在界面输入1http://localhost:9006/fegin 然后关闭服务提供者，再调接口试试。可以看到服务提供者的接口断掉之前和之后返回的结果是不一样的。说明我们的熔断处理是生效的啦。 番外今天就说这么多吧，就先学习一下Hystrix 的基本使用，其他的一些功能，我们后续再说 代码上传到github： https://github.com/QuellanAn/springcloud 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springCloud</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springCloud</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[升级nginx ,为nginx配置https证书]]></title>
    <url>%2F20210810%2F%E5%8D%87%E7%BA%A7nginx%20%2C%E4%B8%BAnginx%E9%85%8D%E7%BD%AEhttps%E8%AF%81%E4%B9%A6.html</url>
    <content type="text"><![CDATA[前言买了服务器和域名后真的是为所欲为，发现自己的网站总是提示不安全，所以就想着要弄一个证书。刚好腾讯云上有免费申请的证书，所以就弄了一个。 申请证书我的证书是在腾讯云上申请的，很快也很方便中，具体怎么操作，就不说了。申请好之后下载。解压后获取如下文件 升级nginx我发现我服务器上的nginx 上次竟然安装的是1.6.2 版本太低了，不支持ssl.支持ssl 需要nginx 1.10.1 以上。所以我直接将版本升级到了1.16.1了。升级也很简单，将下载的安装包解压。12345tar -zxvf nginx-1.16.1.tar.gzcd nginx-1.16.1#重新添加这个ssl模块./configure --with-http_ssl_modulemake 不用make install .将nginx 命令copy 过去就可以了。1cp objs/nginx /usr/local/nginx/sbin/nginx 升级成功。 配置证书我们在nginx.conf 中增加配置123456789101112131415161718192021server &#123; #SSL 访问端口号为 443 listen 443 ssl; #填写绑定证书的域名 server_name quellanan.xyz/; #证书文件名称 ssl_certificate 1_quellanan.xyz_bundle.crt; #私钥文件名称 ssl_certificate_key 2_quellanan.xyz.key; ssl_session_timeout 5m; #请按照以下协议配置 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #请按照以下套件配置，配置加密套件，写法遵循 openssl 标准。 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; location / &#123; #网站主页路径。此路径仅供参考，具体请您按照实际目录操作。 root /var/www/hexo; index index.php index.html index.htm default.php default.htm default.html; &#125; &#125; 还要增加一个80 端口的映射。12345server &#123; listen 80; server_name quellanan.xyz; rewrite ^/(.*)$ https://quellanan.xyz:443/$1 permanent; &#125; 这样就配置好了，重启nginx 服务，但是发现https 并不能访问，弄了一晚上没有出来。详细问题可以见这个：腾讯云配置了ssl 证书，浏览器却无法访问？]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>https</tag>
        <tag>ssl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十二、SpringBoot 优雅的集成Spring Security]]></title>
    <url>%2F20210810%2F%E5%8D%81%E4%BA%8C%E3%80%81SpringBoot%20%E4%BC%98%E9%9B%85%E7%9A%84%E9%9B%86%E6%88%90Spring%20Security.html</url>
    <content type="text"><![CDATA[前言至于什么是Spring security ，主要两个作用，用户认证和授权。即我们常说的，用户只有登录了才能进行其他操作，没有登录的话就重定向到登录界面。有的用户有权限执行某一操作，而有的用户不能执行则是授权。算是一个项目安全框架。和shiro 框架一样。二者的不同大家可以百度下。Spring security 是Spring家族的一员，所以Springboot算是对Spring security 进行的天然的支持。 之所以这样说，spring security 被人诟病的配置繁琐复杂，在springboot中变的简单起来。如果我们只是demo 效果，可以做到0配置实现。 下面我们就一起来见识一下吧 依赖我们在pom.xml 文件中引入Spring security 的statter12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 测试我们先来0配置的看看。引入依赖以后，我们创建一个HelloController 内容如下：12345678@RestControllerpublic class HelloController &#123; @RequestMapping("/hello") public String hello()&#123; return "hello world"; &#125;&#125; 然后我们启动项目，按照我们正常的理解，直接访问1localhost:8080/hello 会返回hello world 。但结果却是重定向到了/login 。下面的界面是Spring security 自带的。其实上面可以看到，Spring security 已经起作用了，没有登录不能访问 /hello 接口。 默认的用户名为 user;密码在我们项目启动时控制台有打印，每次都会不一样，随机生成的。我们输入账号密码，再试试可以看到，在登录之后，我们在请求 /hello 会直接返回hello world , 那是不是只要登录一次，后面就可以一直访问呢？当然不是的，登录成功之后，会将信息保存在session 中，再登录的时候，就会通过session 校验，这样就可以访问到了，当session过期获取我们手动清理掉后，就需要重新登录了。我们来试试。打开控制台，application 中的cookies 中的jsessionid 清理掉。我们接着请求试试，可以发现删除后，就会重新回到登录界面。 简单配置用户和密码上面我们使用的默认的用户名和密码，但是实际上我们肯定不会这么做的，上面只是说明springboot 完全的集成了Spring security 。下面我们先来简单的配置用户名密码，之所以这样说，因为我们实际过程中应该还是不会这么用的。之所以要讲，让大家了解的更全面，也为下面铺垫。 application.properties 中配置首先我们来简单的，我们可以直接在application.properties 中配置用户名和密码。来代替默认用户名和密码的效果。123spring.security.user.name=quellananspring.security.user.password=123456spring.security.user.roles=admin 分别是设置用户名，密码，角色。我们这里暂时只用了用户认证，所以角色设不设置无所谓。配置好这些之后我们重启项目在界面上试试再。没有问题，但是没有什么用，我们实际中是不会这么干的吧。 内存中配置在内存中配置的话，相对来说要复杂点，我们创建一个config 包，在包下创建SecurityConfig 类继承 WebSecurityConfigurerAdapter1234567891011121314151617181920@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.inMemoryAuthentication() .passwordEncoder(passwordEncoder()) // 指定加密方式 .withUser("qaz").password(passwordEncoder().encode("123456")).roles("admin") .and() .withUser("test").password(passwordEncoder().encode("123456")).roles("USER"); &#125; @Bean public PasswordEncoder passwordEncoder() &#123; // BCryptPasswordEncoder：Spring Security 提供的加密工具 return new BCryptPasswordEncoder(); &#125;&#125; 这里我们重写了configure(AuthenticationManagerBuilder auth) 方法，就是将定义的用户配置到内存中。这里有一个问题需要说明一下，就是这里配置的话，密码需要用BCryptPasswordEncoder 加密。如果不加密的话，项目编译启动不会报错，但是登陆的时候就会提示账号密码错误。还有一个问题就是，如果我们在这配置了，那我们在application.peoperties 中配置的就会失效。 上面说的这两种方法，其实都是不常用的，我们在实际项目中根本不会在项目中写死用户信息的。基本上都是存在数据库中。所以下面我们就开始讲解我们最常用的模式吧。 由于这一类，涉及的较多，就单独一级标题出来，不放在二级标题里面了。 从数据库进行用户认证既然是用到数据库，项目中自然要引入数据的配置啦，我这里用的是mysql 和mybatis.这是整个项目成型后的目录结构，先放出来，大家心里有底，然后一步一步的来。 建库建表简单的三张表，user,roles,roles_user 。下面是 sql。直接执行就可以12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/*Date: 2017-12-26 18:36:12*/CREATE DATABASE `quellanan` DEFAULT CHARACTER SET utf8;USE `quellanan`;SET FOREIGN_KEY_CHECKS=0;-- ------------------------------ Table structure for roles-- ----------------------------DROP TABLE IF EXISTS `roles`;CREATE TABLE `roles` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(32) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8;-- ------------------------------ Records of roles-- ----------------------------INSERT INTO `roles` VALUES ('1', '超级管理员');INSERT INTO `roles` VALUES ('2', '普通用户');INSERT INTO `roles` VALUES ('3', '测试角色1');INSERT INTO `roles` VALUES ('4', '测试角色2');INSERT INTO `roles` VALUES ('5', '测试角色3');-- ------------------------------ Table structure for roles_user-- ----------------------------DROP TABLE IF EXISTS `roles_user`;CREATE TABLE `roles_user` ( `id` int(11) NOT NULL AUTO_INCREMENT, `rid` int(11) DEFAULT '2', `uid` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `rid` (`rid`), KEY `roles_user_ibfk_2` (`uid`), CONSTRAINT `roles_user_ibfk_1` FOREIGN KEY (`rid`) REFERENCES `roles` (`id`), CONSTRAINT `roles_user_ibfk_2` FOREIGN KEY (`uid`) REFERENCES `user` (`id`) ON DELETE CASCADE) ENGINE=InnoDB AUTO_INCREMENT=131 DEFAULT CHARSET=utf8;-- ------------------------------ Records of roles_user-- ----------------------------INSERT INTO `roles_user` VALUES ('1', '1', '1');INSERT INTO `roles_user` VALUES ('2', '2', '2');INSERT INTO `roles_user` VALUES ('3', '3', '3');INSERT INTO `roles_user` VALUES ('4', '1', '4');-- ------------------------------ Table structure for user-- ----------------------------DROP TABLE IF EXISTS `user`;CREATE TABLE `user` ( `id` int(11) NOT NULL AUTO_INCREMENT, `username` varchar(64) DEFAULT NULL, `nickname` varchar(64) DEFAULT NULL, `password` varchar(255) DEFAULT NULL, `enabled` tinyint(1) DEFAULT '1', `email` varchar(64) DEFAULT NULL, `userface` varchar(255) DEFAULT NULL, `regTime` datetime DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=21 DEFAULT CHARSET=utf8;-- ------------------------------ Records of user-- ----------------------------INSERT INTO `user` VALUES ('1', 'quellanan', '', '$2a$10$Hv0YGLi/siOswCTP236MtOTWbClcM6rN1LCyqwfRmrwCJZqXHsj5a', '1', 'quellanan@qq.com','', '2017-12-08 09:30:22');INSERT INTO `user` VALUES ('2', 'qaz', '', '$2a$10$6H69XLebCrGhHeHzDXEoH.0x8tMFS0XfdDPwI5s.Eu9pbqRpncA.G', '1', 'quellanan@qq.com','', '2017-12-08 09:30:22');INSERT INTO `user` VALUES ('3', 'wsx', '', '$2a$10$6H69XLebCrGhHeHzDXEoH.0x8tMFS0XfdDPwI5s.Eu9pbqRpncA.G', '1', 'quellanan@qq.com','', '2017-12-08 09:30:22');INSERT INTO `user` VALUES ('4', 'test', '', '$2a$10$6H69XLebCrGhHeHzDXEoH.0x8tMFS0XfdDPwI5s.Eu9pbqRpncA.G', '1', 'quellanan@qq.com','', '2017-12-08 09:30:22');SET FOREIGN_KEY_CHECKS=1; pom.xml 增加依赖我们首先在原先pom 文件基础上增加，如下依赖。123456789101112131415161718192021&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; 前面三个是mysql 和mybatis的依赖。lombok 是一个工具类插件。 同时我们需要修改一下pom 文件中的build ，不然我们项目可能会找不到mybatis 的xml文件。1234567891011121314151617181920&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 配置application.properties12345678spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.url=jdbc:mysql://127.0.0.1:3306/quellanan?allowMultiQueries=true&amp;useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTCspring.datasource.username=rootspring.datasource.password=123456spring.datasource.max-idle=10spring.datasource.max-wait=10000spring.datasource.min-idle=5spring.datasource.initial-size=5 这里如果想要打印mybatis 的sql 日志。可以添加一个mybatis-config.xml文件，和application.properties 同目录1234567&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;setting name="logImpl" value="STDOUT_LOGGING" /&gt; &lt;/settings&gt;&lt;/configuration&gt; 并在application.properties 中加上1mybatis.config-location=classpath:/mybatis-config.xml entry我们在entry 包下创建 RoleEntry。代码如下：123456@Getter@Setterpublic class RoleEntry &#123; private Long id; private String name;&#125; 我们在创建 UserEntry ，但是UserEntry 比较特殊，因为我们需要使用Spring security 。所以这里，UserEntry 需要实现 UserDetails。代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879@Setter@Getterpublic class UserEntry implements UserDetails &#123; private Long id; private String username; private String password; private String nickname; private boolean enabled; private List&lt;RoleEntry&gt; roles; private String email; private String userface; private Timestamp regTime; /** * 获取角色权限 * @return */ @Override public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() &#123; List&lt;GrantedAuthority&gt; authorities = new ArrayList&lt;&gt;(); for (RoleEntry role : roles) &#123; authorities.add(new SimpleGrantedAuthority("ROLE_" + role.getName())); &#125; return authorities; &#125; /** * 获取密码 * @return */ @Override public String getPassword() &#123; return password; &#125; /** * 获取用户名 * @return */ @Override public String getUsername() &#123; return username; &#125; /** * 用户账号是否过期 */ @Override public boolean isAccountNonExpired() &#123; return true; &#125; /** * 用户账号是否被锁定 */ @Override public boolean isAccountNonLocked() &#123; return true; &#125; /** * 用户密码是否过期 */ @Override public boolean isCredentialsNonExpired() &#123; return true; &#125; /** * 用户是否可用 */ @Override public boolean isEnabled() &#123; return enabled; &#125;&#125; 可以看到，基本上都是重写的方法。也比较简单。 mapper这里我将xml 文件和接口放在一起了，你们也可以在resources 中创建一个mapper,将xml 文件放在哪里。mapper层没有什么好说的，是mybatis 的一些知识，我们这里讲代码贴出来。 RolesMapper1234@Mapperpublic interface RolesMapper &#123; List&lt;RoleEntry&gt; getRolesByUid(Long uid);&#125; RolesMapper.xml123456789&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.zlflovemm.security.mapper.RolesMapper"&gt; &lt;select id="getRolesByUid" parameterType="long" resultType="com.zlflovemm.security.entry.RoleEntry"&gt; SELECT r.* FROM roles r,roles_user ru WHERE r.`id`=ru.`rid` AND ru.`uid`=#&#123;uid&#125; &lt;/select&gt;&lt;/mapper&gt; UserMapper1234@Mapperpublic interface UserMapper &#123; UserEntry loadUserByUsername(@Param("username") String username);&#125; UserMapper.xml123456789&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.zlflovemm.security.mapper.UserMapper"&gt; &lt;select id="loadUserByUsername" resultType="com.zlflovemm.security.entry.UserEntry"&gt; SELECT * FROM user WHERE username=#&#123;username&#125; &lt;/select&gt;&lt;/mapper&gt; service在service 层我们要注意一点，我们需要实现 UserDetailsService 接口。我们先创建一个UserService 继承 UserDetailsService。然后创建一个UserServiceImpl 来时实现UserService 从而达到实现UserDetailsService的目的。这样做是为了保证项目结构的统一层次。 UserService12public interface UserService extends UserDetailsService &#123;&#125; UserServiceImpl1234567891011121314151617181920212223@Service@Slf4j@Transactionalpublic class UserServiceImpl implements UserService &#123; @Autowired UserMapper userMapper; @Autowired RolesMapper rolesMapper; @Override public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException &#123; UserEntry user = userMapper.loadUserByUsername(s); if (user == null) &#123; //避免返回null，这里返回一个不含有任何值的User对象，在后期的密码比对过程中一样会验证失败 return new UserEntry(); &#125; //查询用户的角色信息，并返回存入user中 List&lt;RoleEntry&gt; roles = rolesMapper.getRolesByUid(user.getId()); user.setRoles(roles); return user; &#125;&#125; 可以看到，主要是为了实现 loadUserByUsername的方法。在这个方法中我们 loadUserByUsername和getRolesByUid 就是我们在mapper 定义的查询数据库数据的方法。 SecurityConfig前面做了这么多，其实都是准备工作，主要的目的就是提供一个Bean 。做完上面这些，我们再回到 SecurityConfig 中，其实我们现在需要修改的很少了。我们将用户写在内存的方法注释掉。通过数据库查询。1234567891011121314151617181920@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Autowired UserService userService; @Bean public PasswordEncoder passwordEncoder() &#123; // BCryptPasswordEncoder：Spring Security 提供的加密工具 return new BCryptPasswordEncoder(); &#125; @Override public void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.userDetailsService(userService) .passwordEncoder(passwordEncoder());//passwoldEncoder是对密码的加密处理，如果user中密码没有加密，则可以不加此方法。注意加密请使用security自带的加密方式。 &#125;&#125; 可以和开始的 SecurityConfig 文件对比下，其实你就是多了一个userService，然后configure(AuthenticationManagerBuilder auth)中是通过userService 进行校验的。 测试好了，其实到这里，我们就已经完成了，我们启动项目，就可以看到和之前写在内存中达到一样的效果。 过滤以为到这就完了，其实还有一点哈哈。我们现在是所有的接口都需要先登录才能访问，没有登录的话就跳转到login界面。实际上我们肯定有些是不需要认证也可以访问的，比如以下静态文件或者注册的请求。所以我们还是要配置一下过滤。 其实也很简单，一样的在 SecurityConfig 文件中 重写 configure(HttpSecurity http) 方法。这里我直接参考官网上的。https://spring.io/guides/gs/securing-web/ 该configure(HttpSecurity)方法定义应保护哪些URL路径，不应该保护哪些URL路径。具体而言，“ /”和“ / home”路径配置为不需要任何身份验证。所有其他路径必须经过验证。用户成功登录后，他们将被重定向到之前要求身份验证的页面。有一个由指定的自定义“ /登录”页面loginPage()，每个人都可以查看它。 我们代码中 把 loginPage(“/login”) 注释掉就好了，如果不注释的话，就需要我们自己写login 界面和请求。我们这里就用框架自带的。12345678910111213@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; http.authorizeRequests() .antMatchers("/", "/hello").permitAll() .anyRequest().authenticated() .and() .formLogin() //.loginPage("/login") .permitAll() .and() .logout() .permitAll();&#125; 这样配置就说明 /hell 和 / 请求不会拦截，其他的请求，需要先登录才能访问。为了更方便的看到效果，我们在HelloController 中再加两个方法12345678910 @RequestMapping("/hello2") public String hello2()&#123; return "hello adada"; &#125; @RequestMapping("/") public String hello3()&#123; return " qazqeee"; &#125;&#125; 现在我们启动来看下效果。证明我们配置的过滤是有效果的。 番外到此算是差不多结束了，其实还有很多知识点，不是一篇文章能讲完的，这里算是抛转引玉，希望对大家有帮助。后面我也会持续更新 好了，源码我上传到github 上啦https://github.com/QuellanAn/security 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十三、springboot 优雅集成spring-boot-admin 实现程序监控]]></title>
    <url>%2F20210810%2F%E5%8D%81%E4%B8%89%E3%80%81springboot%20%E4%BC%98%E9%9B%85%E9%9B%86%E6%88%90spring-boot-admin%20%E5%AE%9E%E7%8E%B0%E7%A8%8B%E5%BA%8F%E7%9B%91%E6%8E%A7.html</url>
    <content type="text"><![CDATA[前言我们知道项目的监控是尤为重要的，但是我们如果用jdk 自带的jconsole 和jvisualvm 的话会非常繁琐，且界面不是很友好。之前我们使用了spring boot 项目，但是都没有对项目有一个很好的监控。在spring 家族中有 spring-boot-admin 可以很好的帮我们起到监控微服务项目的作用。 spring-boot-admin 是一个针对 Spring Boot 的 Actuator 接口进行 UI 美化封装的监控工具，它可以在列表中浏览所有被监控 spring-boot 项目的基本信息、详细的 Health 信息、内存信息、JVM 信息、垃圾回收信息、各种配置信息（比如数据源、缓存列表和命中率）等，还可以直接修改 logger 的 level。 spring-boot-admin 分为服务端和客户端。服务端是一个单独的微服务，用来查看监控的项目的运行情况，客户端是我们一个个的微服务项目。所以要想让我们的项目被服务端监控到，就需要将我们的服务注册到服务端去。 好了，我们来动手试试吧。 admin-server我们先来搭建spring-boot-admin 的服务端，上面说了服务端是一个单独的项目。所以我们创建一个新的springboot 项目。创建好后，我们做一下修改。 pom.xml在pom 文件中，我们引入 如下依赖12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.quellanan&lt;/groupId&gt; &lt;artifactId&gt;springbootadmin&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;springbootadmin&lt;/name&gt; &lt;description&gt;springbootadmin project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-boot-admin.version&gt;2.2.1&lt;/spring-boot-admin.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-boot-admin.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 上面是我整个的pom 文件，可以看到我引入了web 、admin-starter-server、security。如果考虑其他的，可以只引用admin-starter-server 就可以实现效果。 启动类在我们的启动类上加入@EnableAdminServer 注解，如果不加的话，项目可以正常启动，但是看不到任何东西。@EnableAdminServer 注解的作用就是启动监控。1234567@SpringBootApplication@EnableAdminServerpublic class SpringbootadminApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootadminApplication.class, args); &#125;&#125; 配置 security这样配置好之后，就可以启动项目啦，但是我们这里先不启动，因为上一节我们学习了，spring-boot-security .这里我们将它用起来。我们前面已经引入了 security ,接下来，我们在application中增加配置12spring.security.user.name=adminspring.security.user.password=123456 表示这个用户才能访问。另外我们创建一个 SecurityConfig 类 继承 WebSecurityConfigurerAdapter 重写 configure(HttpSecurity http) 方法。代码如下：123456789101112131415161718192021222324@Configurationpublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; SavedRequestAwareAuthenticationSuccessHandler successHandler = new SavedRequestAwareAuthenticationSuccessHandler(); successHandler.setTargetUrlParameter("redirectTo"); successHandler.setDefaultTargetUrl("/"); http.authorizeRequests() .antMatchers("/assets/**").permitAll() .antMatchers("/login").permitAll() .anyRequest().authenticated().and() .formLogin().loginPage("/login") .successHandler(successHandler).and() .logout().logoutUrl("/logout").and() .httpBasic().and() .csrf() .csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse()) .ignoringAntMatchers( "/instances", "/actuator/**" ); &#125;&#125; 现在我们启动一下项目看看。启动项目后输入1http://localhost:8080 会跳转到 登录界面，进入主页现在是什么都没有的。 admin-client到此我们服务端的配置就已经可以了，现在我们来配置一下客户端，我们随便找一个Springboot 项目，或者自己创建一个新的项目都可以。 pom.xml我们先在pom 文件中加入admin-client 依赖，注意这里的版本需要和server 的版本一致。12345&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;/dependency&gt; application.properties然后我们在 application.properties 文件中加入如下配置。12345spring.boot.admin.client.url=http://localhost:8080management.endpoints.web.exposure.include=*spring.application.name=sdwlzlapp-filespring.boot.admin.client.username=adminspring.boot.admin.client.password=123456 spring.boot.admin.client.url 指向我们服务端的项目接口路径。management.endpoints.web.exposure.include 表示将所有端口都暴露出来，可以被监控到。spring.application.name 表示改项目在spring-boot-admin 上的的显示名称。spring.boot.admin.client.username 和password 就是设置的用户名和密码了，这里需要注意的是，如果admin-server 中没有集成 security 的话，不用配置用户名和密码也可以注册进去，在服务端可以监控到，但如果admin-server 集成了security，就需要保证client 中配置的用户名和server 中配置的用户名密码保持一致。 测试配置了上面这些，就就可以将项目注册到admin-server 中啦，我们启动一下项目。 现在还有一个问题，如果我们项目本身就集成的安全框架，比如security ，没有登录的话不能访问接口，那这样的项目怎么被admin-server 监控到呢？比如就我们上节将的security 的demo ，我们注册进来，虽然监控到了，但是是一个失败的状态。可以看到，不难发现问题，那就是监控的接口也被项目本身拦截了，所以才导致是失败的状态，那要怎么修改了呢，其实也好处理，将这几个接口放开就可以了。我们在项目的SecurityConfig 类中configure(HttpSecurity http)加上代码如下：123456789101112131415@Override protected void configure(HttpSecurity http) throws Exception &#123; http.authorizeRequests() .antMatchers("/", "/hello").permitAll() .antMatchers( "/actuator/**").permitAll() .antMatchers( "/instances").permitAll() .anyRequest().authenticated() .and() .formLogin() //.loginPage("/login") .permitAll() .and() .logout() .permitAll(); &#125; 这样我们重启项目，就发现可以监控成功了。 番外 到此为止，我们也算是将spring-boot-admin的大致功能演示了下。 代码上传到github：https://github.com/QuellanAn/springbootadmin 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十一、springboot 配置log4j2以及打包成zip文件]]></title>
    <url>%2F20210810%2F%E5%8D%81%E4%B8%80%E3%80%81springboot%20%E9%85%8D%E7%BD%AElog4j2%E4%BB%A5%E5%8F%8A%E6%89%93%E5%8C%85%E6%88%90zip%E6%96%87%E4%BB%B6.html</url>
    <content type="text"><![CDATA[前言其实我们前面已经配置了日志，但是最近总感觉日志日志格式看的不舒服，并且每次打包都是一个jar 文件，lib都包含在jar 中，每次做很小的修改都需要重新替换jar文件，jar文件会比较大，传输起来比较慢。所以做一些改进。 配置log4j2好了，废话不多说了，先来在Springboot中配置log4j2吧。 pom.xmlspringboot 项目默认的是使用logback 的，所以我们想要使用log4j ，需要将原来的logback 框架屏蔽掉，再引入log4j.首先我们在pom.xml 文件中加入123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt;&lt;!-- 去掉默认配置 --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;/dependency&gt; 编写log4j2.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;Configuration status="WARN" monitorInterval="300" packages="cn.mastercom.cat"&gt; &lt;properties&gt; &lt;property name="MtnoWebRoot" &gt;$&#123;sys:user.dir&#125;/logs&lt;/property&gt; &lt;property name="INFO_FILE"&gt;zlflovemm_log&lt;/property&gt; &lt;property name="ERROR_FILE"&gt;zlflovemm__error&lt;/property&gt; &lt;/properties&gt; &lt;Appenders&gt; &lt;Console name="Console" target="SYSTEM_OUT"&gt; &lt;ThresholdFilter level="ALL" onMatch="ACCEPT" onMismatch="DENY"/&gt; &lt;PatternLayout pattern="%d&#123;HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n" /&gt; &lt;/Console&gt; &lt;RollingRandomAccessFile name="infolog" fileName="$&#123;MtnoWebRoot&#125;/$&#123;INFO_FILE&#125;.log" filePattern="$&#123;MtnoWebRoot&#125;/$&#123;INFO_FILE&#125;-%d&#123;yyyy-MM-dd&#125;-%i.log"&gt; &lt;PatternLayout pattern="%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%t] [%X&#123;sessionID&#125;] [%X&#123;imei&#125;] %-5level %logger&#123;36&#125; - %msg%n" /&gt; &lt;!-- --&gt; &lt;Policies&gt; &lt;TimeBasedTriggeringPolicy interval="1" modulate="true" /&gt; &lt;SizeBasedTriggeringPolicy size="2MB" /&gt; &lt;/Policies&gt; &lt;DefaultRolloverStrategy max="1000"&gt; &lt;Delete basePath="$&#123;MtnoWebRoot&#125;" maxDepth="1"&gt; &lt;IfFileName glob="$&#123;INFO_FILE&#125;*.log" /&gt; &lt;IfLastModified age="30d" /&gt; &lt;/Delete&gt; &lt;/DefaultRolloverStrategy&gt; &lt;/RollingRandomAccessFile&gt; &lt;RollingRandomAccessFile name="errorlog" fileName="$&#123;MtnoWebRoot&#125;/$&#123;ERROR_FILE&#125;.log" filePattern="$&#123;MtnoWebRoot&#125;/$&#123;ERROR_FILE&#125;-%d&#123;yyyy-MM-dd&#125;-%i.log"&gt; &lt;PatternLayout pattern="%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n" /&gt; &lt;Policies&gt; &lt;TimeBasedTriggeringPolicy interval="1" modulate="true" /&gt; &lt;SizeBasedTriggeringPolicy size="200MB" /&gt; &lt;/Policies&gt; &lt;DefaultRolloverStrategy max="1000"&gt; &lt;Delete basePath="$&#123;MtnoWebRoot&#125;" maxDepth="1"&gt; &lt;IfFileName glob="$&#123;INFO_FILE&#125;*.log" /&gt; &lt;IfLastModified age="30d" /&gt; &lt;/Delete&gt; &lt;/DefaultRolloverStrategy&gt; &lt;/RollingRandomAccessFile&gt; &lt;Async name="Async"&gt; &lt;AppenderRef ref="infolog"/&gt; &lt;AppenderRef ref="errorlog"/&gt; &lt;/Async&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;asyncRoot level="INFO"&gt; &lt;AppenderRef ref="infolog"/&gt; &lt;AppenderRef ref="errorlog" level="error"/&gt; &lt;AppenderRef ref="Console" /&gt; &lt;/asyncRoot&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 上面配置的是生成日志的格式，大家可以自行修改。以及配置了单个日志文件最大为200M ,只保留最近30天的文件。 application.properties 配置123#日志配置logging.config=classpath:log4j2.xmldebug=false 实现上面这三步，就轻松的在项目中使用log4j日志啦。 打包外置配置文件上面配置的日志，先不测试了，等这个打包的配置也配置好了，再来一起测试。 如果我们直接使用自带的mvn package 的话，会将我们依赖的jar 包已经配置文件统统打包成可运行的jar 文件。这样虽然方便，但是这样的话每次都需要重新打包，并且传输起来比较麻烦，所以我们就需要将lib 和配置文件从jar 文件中分离。这样项目修改了，只需要替换一下比较小的部分就可以了。 pom.xml 修改打开我们的pom.xml 文件,最下面我们的中我们加入如下代码。因为我们的项目之前加入了打包成docker 镜像，所以整个的都贴出来，不需要打包成docker的可以去掉。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111&lt;build&gt; &lt;!--打包后的项目名称--&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;targetPath&gt;$&#123;project.build.directory&#125;$&#123;file.separator&#125;classes&lt;/targetPath&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;!--这里必须包含.xml否则Mybatis的xml无法打包--&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;!--java编译插件--&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!--打jar包的插件--&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib&lt;/classpathPrefix&gt; &lt;!--程序启动入口--&gt; &lt;mainClass&gt;com.quellan.zlflovemm.ZlflovemmApplication&lt;/mainClass&gt; &lt;/manifest&gt; &lt;manifestEntries&gt; &lt;Class-Path&gt;./&lt;/Class-Path&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;excludes&gt; &lt;exclude&gt;config/**&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!--not append assembly id in release file name--&gt; &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt; &lt;descriptors&gt; &lt;!--注意这里的路径--&gt; &lt;descriptor&gt;src/main/build/package.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- Docker --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;!-- 将插件绑定在某个phase执行 --&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;build-image&lt;/id&gt; &lt;!-- 用户只需执行mvn package ，就会自动执行mvn docker:build --&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!-- 指定生成的镜像名 --&gt; &lt;imageName&gt;$&#123;docker.image.prefix&#125;/$&#123;project.artifactId&#125;:$&#123;project.version&#125;&lt;/imageName&gt; &lt;!-- 指定标签 --&gt; &lt;imageTags&gt; &lt;imageTag&gt;$&#123;project.version&#125;&lt;/imageTag&gt; &lt;/imageTags&gt; &lt;!-- 指定 Dockerfile 路径 --&gt; &lt;dockerDirectory&gt;src/main/docker&lt;/dockerDirectory&gt; &lt;!-- 指定远程 docker api地址 --&gt; &lt;dockerHost&gt;http://127.0.0.1:2375&lt;/dockerHost&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;!-- jar包所在的路径此处配置的对应target目录 --&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;!-- 需要包含的jar包,这里对应的是Dockerfile中添加的文件名 --&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 需要注意的是，如下两个地方，第一个di地方需要需改成我们自己项目的启动类。第二个地方需要配置我们的package.xml 文件路径。内容我们待会讲。 package.xml我们在pom.xml 中配置好了后，我们在src/main 目录下创建一个build 包，早build 目录下创建package.xml 文件。路径就是上面配置的，大家可以按照自己的喜好来。内容如下：12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;assembly xmlns="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3 http://maven.apache.org/xsd/assembly-1.1.3.xsd"&gt; &lt;id&gt;package&lt;/id&gt; &lt;formats&gt; &lt;format&gt;zip&lt;/format&gt; &lt;/formats&gt; &lt;!-- 改为false不会出现两层相同的目录 --&gt; &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt; &lt;fileSets&gt; &lt;fileSet&gt; &lt;directory&gt;bin&lt;/directory&gt; &lt;outputDirectory&gt;$&#123;file.separator&#125;&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;fileSet&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;outputDirectory&gt;$&#123;file.separator&#125;&lt;/outputDirectory&gt; &lt;excludes&gt; &lt;exclude&gt;static/**&lt;/exclude&gt; &lt;exclude&gt;templates/**&lt;/exclude&gt; &lt;/excludes&gt; &lt;/fileSet&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;outputDirectory&gt;$&#123;file.separator&#125;&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;*.jar&lt;/include&gt; &lt;/includes&gt; &lt;/fileSet&gt; &lt;/fileSets&gt; &lt;dependencySets&gt; &lt;dependencySet&gt; &lt;useProjectArtifact&gt;true&lt;/useProjectArtifact&gt; &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;!--&lt;unpack&gt;false&lt;/unpack&gt; --&gt; &lt;excludes&gt; &lt;!--&lt;exclude&gt;$&#123;project.name&#125;-$&#123;project.version&#125;&lt;/exclude&gt; --&gt; &lt;exclude&gt;$&#123;groupId&#125;:$&#123;artifactId&#125;&lt;/exclude&gt; &lt;/excludes&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;/assembly&gt; 测试好啦，上面的已经配置好啦，我们来测试一下。直接mvn package成功后会生成如下文件，包含jar 和zip 文件。 zip 文件解压后，就是我们第一次部署的文件，后面修改代码只用替换jar文件就可以了。 我们生成的日志文件 番外好了，就说这么多啦代码上传到github：https://github.com/QuellanAn/zlflovemm 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十、Spring boot 简单优雅的整合 Swagger2]]></title>
    <url>%2F20210810%2F%E5%8D%81%E3%80%81Spring%20boot%20%E7%AE%80%E5%8D%95%E4%BC%98%E9%9B%85%E7%9A%84%E6%95%B4%E5%90%88%20Swagger2.html</url>
    <content type="text"><![CDATA[前言swagger2 是什么，我这里就不说了，就是一个简单的接口文档，方便前后端联调。 其实之前没有想要到要使用swagger 的。因为我之前用的是YAPI ,不过这个是一个单独的工具。并且是开源的，整个团队协作使用起来非常方便。但是这里我们坐个人项目的话，就使用比较简单的swagger2了，我们在在springboot中使用swagger2 比较简单。 pom.xml一切从配置开始的，我们映入swagger2 ,需要先引入依赖。如下：12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; SwaggerConfig引入依赖后，我们就需要来写一个配置，我们在config 目录下创建一个SwaggerConfig类。内容如下：1234567891011121314151617181920212223@Configuration@EnableSwagger2public class SwaggerConfig &#123; @Bean public Docket createRestApi()&#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage("com.quellan.zlflovemm.controller")) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo()&#123; return new ApiInfoBuilder() .title("Spring Boot中使用Swagger2构建RESTful APIs") .description("SpringBoot整合Swagger，详细信息......") .version("1.0.0") .build(); &#125;&#125; 可以看到代码不复杂，就是创建了一个Docket 的bean。唯一需要注意的是注意配置好接口的目录。 其实到了这一步，我们就已经配置好了。我们启动项目测试一下。启动项目后，在浏览器上输入：1http://localhost:9090/zlflovemm/swagger-ui.html 可以看到我们之前写的接口已经在界面上显示出来了。不过现在的接口还惨不忍睹，你们自己实践的时候可以看看，需要我们再做些工作。到这里有些朋友可能会出现问题，发现没有出现这种界面，可能是配置不对，要不就是你们的配置了拦截器。我自己开始弄的时候就出现了页面访问不了的情况。然后发现是我们上篇文章番外中设置的拦截器导致的。我们可以先把注释掉。 接口中的配置我们就用用户类的接口来写吧，毕竟还是写文档还是很麻烦的。写好后的代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273@Slf4j@RestController@RequestMapping("/user")@Api(tags = "用户管理相关接口")public class UserController &#123; @Autowired private UserService userService; @ApiOperation("获取用户列表") @RequestMapping(value = "/list") public List&lt;UserEntry&gt; findUserList()&#123; return userService.findUserList(); &#125; @ApiOperation("新增用户信息") @ApiImplicitParams(&#123; @ApiImplicitParam(name = "userName",value = "用户名",defaultValue = "zlf"), @ApiImplicitParam(name="password",value = "密码",defaultValue = "zlf"), @ApiImplicitParam(name = "email",value = "邮箱",defaultValue = "11@qq.com") &#125;) @RequestMapping(value = "/add",method = RequestMethod.GET) public String addUser(@RequestParam(value = "userName")String uaserName,@RequestParam(value = "password")String password,@RequestParam(value = "email")String email)&#123; int falg=userService.addUser(uaserName,password,email); if(falg&gt;0)&#123; return "success"; &#125; return "error"; &#125; @ApiOperation("删除用户信息") @ApiImplicitParam(name = "id",value = "1",defaultValue = "1") @RequestMapping(value = "/delete",method = RequestMethod.GET) public String deleteUser(@RequestParam(value = "id")int id)&#123; if(userService.deleteUser(id)&gt;0)&#123; return "success"; &#125; return "error"; &#125; @ApiOperation("获取用户列表2") @RequestMapping(value = "/list2",method = RequestMethod.GET) public List&lt;UserEntry&gt; findUserList2()&#123; return userService.findUserList2(); &#125; @ApiOperation("新增用户信息2") @ApiImplicitParams(&#123; @ApiImplicitParam(name = "userName",value = "用户名",defaultValue = "zlf"), @ApiImplicitParam(name="password",value = "密码",defaultValue = "zlf"), @ApiImplicitParam(name = "email",value = "邮箱",defaultValue = "11@qq.com") &#125;) @RequestMapping(value = "/add2",method = RequestMethod.GET) public String addUser2(@RequestParam(value = "userName")String uaserName,@RequestParam(value = "password")String password,@RequestParam(value = "email")String email)&#123; int falg= userService.addUser2(uaserName,password,email); if(falg&gt;0)&#123; return "success"; &#125; return "error"; &#125; @ApiOperation("删除用户信息2") @ApiImplicitParam(name = "id",value = "1",defaultValue = "1") @RequestMapping(value = "/delete2",method = RequestMethod.GET) public String deleteUser2(@RequestParam(value = "id")int id)&#123; if(userService.deleteUser2(id)&gt;0)&#123; return "success"; &#125; return "error"; &#125;&#125; 在类上加入@Api(tags = “用户管理相关接口”) 表示这个类的作用。在单个接口上，我们通过@ApiOperation，@ApiImplicitParams，@ApiImplicitParam来写备注了。@ApiOperation 用来注明接口的功能。@ApiImplicitParam 用来设置接口有单个参数的，@ApiImplicitParams 用来设置接口多个参数的，怎么使用，代码中有样例。 接下来，我们来看下界面上。可以看到，界面上已经可以显示出来了，这比我们刚刚开始没有配置一些注释要友好了很多，点击 execute 可以调试接口，还是可以满足基本需求的。但是大家也同样发现了，swagger 对我们的代码侵入是非常严重的，我们项目中本来代码就很多，我们还要加上这么多的注解代码，对我们写代码是很不友好的。 番外到此为止，springboot 配置swagger2 就已经实现好了，整体上比较简单，这些希望对大家有帮助。 好了，就说这么多啦代码上传到github：https://github.com/QuellanAn/zlflovemm 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[六、springboot 简单优雅是实现短信服务]]></title>
    <url>%2F20210810%2F%E5%85%AD%E3%80%81springboot%20%E7%AE%80%E5%8D%95%E4%BC%98%E9%9B%85%E6%98%AF%E5%AE%9E%E7%8E%B0%E7%9F%AD%E4%BF%A1%E6%9C%8D%E5%8A%A1.html</url>
    <content type="text"><![CDATA[前言上一篇讲了 springboot 集成邮件服务，接下来让我们一起学习下springboot项目中怎么使用短信服务吧。项目中的短信服务基本上上都会用到，简单的注册验证码，消息通知等等都会用到。所以我这个脚手架也打算将短息服务继承进来。短息服务我使用的平台是阿里云的。网上有很多的短信服务提供商。大家可以根据自己的需求进行选择。 准备工作在阿里云上开通服务，以及进行配置。这些阿里云官方文档都写的很清楚，怎么做就不细说的，大家可以参考一下这篇文章:https://blog.csdn.net/qq_27790011/article/details/78339856 配置好之后你需要获取如下信息： accessKeyId 、accessSecret 这两个是秘钥。在用户AccessKey 中可以找到。 signName 是签名名称。 templateCode 是模版code 添加依赖和配置有了上面的准备工作，我们接下来开始在我们的项目中开发吧。一样的先在pom.xml 文件中加入依赖：123456789101112&lt;!--阿里云短信服务--&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-core&lt;/artifactId&gt; &lt;version&gt;4.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.61&lt;/version&gt; &lt;/dependency&gt; 这个fastjson 不是必须的，就看你项目中有没有用到啦，没有用到的话，添加第一个依赖就好了。 然后在application.properties文件中加入配置，这四个参数，就是准备工作中我们获取的四个参数。 service 层和邮件服务一样，我们这里没有涉及到数据库，就先直接写service 层，创建SmsService 接口和 SmsServiceImpl 类。 SmsServiceImpl的代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@Service@Slf4jpublic class SmsServiceImpl implements SmsService &#123; @Value("$&#123;sms.accessKeyId&#125;") private String accessKeyId; @Value("$&#123;sms.accessSecret&#125;") private String accessSecret; @Value("$&#123;sms.signName&#125;") private String signName; @Value("$&#123;sms.templateCode&#125;") private String templateCode; @Override public boolean sendSms(String iponeNUmber) &#123; DefaultProfile profile = DefaultProfile.getProfile("cn-hangzhou", accessKeyId, accessSecret); IAcsClient client = new DefaultAcsClient(profile); CommonRequest request = new CommonRequest(); request.setMethod(MethodType.POST); request.setDomain("dysmsapi.aliyuncs.com"); request.setVersion("2017-05-25"); request.setAction("SendSms"); request.putQueryParameter("RegionId", "cn-hangzhou"); request.putQueryParameter("PhoneNumbers", iponeNUmber); request.putQueryParameter("SignName", signName); request.putQueryParameter("TemplateCode", templateCode); JSONObject object=new JSONObject(); String randCode=getRandCode(6); log.info("验证码为：&#123;&#125;",randCode); object.put("code",randCode); request.putQueryParameter("TemplateParam", object.toJSONString()); try &#123; CommonResponse response = client.getCommonResponse(request); log.info(response.getData()); return true; &#125; catch (Exception e) &#123; log.error("&#123;&#125;",e); &#125; return false; &#125; /** * 生成随机验证码 * @param digits * @return */ public static String getRandCode(int digits) &#123; StringBuilder sBuilder = new StringBuilder(); Random rd = new Random((new Date()).getTime()); for(int i = 0; i &lt; digits; i) &#123; sBuilder.append(String.valueOf(rd.nextInt(9))); &#125; return sBuilder.toString(); &#125;&#125; 整体的代码逻辑很简单，首先是通过Value注解将配置文件中配置的那四个参数获取到。 sendSms()方法中 : DefaultProfile 和 IAcsClient 是创建DefaultAcsClient实例并初始化。三个参数分别对应的是:地域ID，RAM账号的AccessKey ID， RAM账号AccessKey Secret。 DescribeInstancesRequest 是创建API请求并设置参数。request.putQueryParamete()我们修改主要是修改这里面的参数。PhoneNumbers 是接收信息的手机号，这里我发送的是短信验证码。所以我这里生成一个6位的短息验证码。具体需求大家可以根据需求进行调整。 controller 层controller 层比较简单，就一个发送短信的接口，在sms包下创建SmsController类，代码如下：12345678910111213@RestController@RequestMapping("/sms")public class SmsController &#123; @Autowired private SmsService smsService; @RequestMapping(value = "/send",method = RequestMethod.GET) public String sendSms(@RequestParam(value = "userName")String userName)&#123; smsService.sendSms(userName); return "success"; &#125;&#125; 测试到此为止，短信服务已经搭建好了，现在我们来测试一下，我们首先启动项目，然后调用接口：1http://localhost:9090/zlflovemm/sms/send?userName=13265459362 然后看下日志 看看到我们的手机上收到了短信。 可以看到短信服务是配置成功了的。整体来说没有我们想象中的那么复杂。 番外好了，就说这么多啦，今天项目的代码也同步到github 上啦。github地址：https://github.com/QuellanAn/zlflovemm 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[六、Spring Cloud之配置中心config]]></title>
    <url>%2F20210810%2F%E5%85%AD%E3%80%81Spring%20Cloud%E4%B9%8B%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83config.html</url>
    <content type="text"><![CDATA[前言前面我们讲了微服务的注册中心、负载均衡、熔断处理、网管服务。接下来我们讲配置中心，为什么要用配置中心呢？其实我们接触一段时间就可以发现，我们的项目还是非常多的，每个项目都有自己的一份配置，这样管理起来就显得很不方便了，所以微服务中就提供了config 配置中心，将所有服务的配置都集中在config 服务中，这样方便统一管理。 怎么说呢？就好比每个项目都比如一个房间，每个房间都需要一把钥匙才能开启。而config 则是管理这些钥匙的，好比钥匙链，想要启动那个项目，就需要先从config中获取对应的钥匙，然后启动项目。 下面让我们来看下怎样部署一个config吧。配置中心分为服务端和客户端，和eureka 有点像，服务端是一个单独的项目，用来管理其他服务的配置，其他的服务就是客户端。 配置中心服务端映入config-server 依赖首先我们创建一个config 的子模块，用来做config 服务端，然后在pom.xml 文件中加入config-server依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 启动类在启动类中，我们加入@EnableConfigServer 注解 配置文件在配置文件中我们加入如下配置：12345678server.port=9008spring.application.name=config-server#使用本地属性文件spring.profiles.active = native#属性文件地址，只要指定文件夹的路径spring.cloud.config.server.native.searchLocations=classpath:/properties 这里我们spring.profiles.active = native 表示你从本地加载配置文件，后面我们再从git 上加载配置文件。如果不配置加载文件的地址，就会从src/main/resources 中加载文件。我这里配置了从properties文件夹下加载，所以在resources 文件夹下创建一个properties 文件夹。我们一eureka-server 服务为例。我们将这个项目的配置放到properties 文件夹下，并改名为quellanan-eurekaserver.properties 客户端配置好了，上面的服务端就已经配置好了，接下来我们来配置客户端。 pom.xml在pom.xml 文件中引入config 依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; bootstrap.properties在resources 目录下创建一个 bootstrap.properties 文件，至于为什么要是这个而不是application.properties 文件，是由加载机制决定的，加载的时候会先加载bootstrap.properties 文件，然后加载application.properties ，文件内容如下：1234spring.application.name=quellananspring.cloud.config.profile=eurekaserverspring.cloud.config.label=masterspring.cloud.config.uri=http://localhost:9008/ 在本地也是一样的，spring.application.name和spring.cloud.config.profile拼起来就是文件名称。 测试好了，服务端和客户端都配置好了，我们现在先将客户端的application.properties 文件删除掉，然后启动这两个项目，先启动config。可以看到eureka-server 成功的从config 中加载到了配置文件并启动了项目。 番外 就这样简单的一个配置中心就已经实现了，最后说一个，既然我们有配置中心，那我们按在项目本身的application.properties 写的配置会加载么？答案是会加载的，至于比配置中心先加载还是后加载，我个人偏向于后加载，在application.properties 中写的属性可以覆盖配置中心中的属性。但是建议，依然使用了配置中心，就希望将所有的配置都放到配置中心里面，不要单独的在项目中新增配置，这样会增加管理的成本。 代码上传到github： https://github.com/QuellanAn/SpringCloud 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤ 阅读原文]]></content>
      <categories>
        <category>springCloud</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springCloud</tag>
        <tag>zuul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[八、springboot 简单优雅的通过docker-compose 构建]]></title>
    <url>%2F20210810%2F%E5%85%AB%E3%80%81springboot%20%E7%AE%80%E5%8D%95%E4%BC%98%E9%9B%85%E7%9A%84%E9%80%9A%E8%BF%87docker-compose%20%E6%9E%84%E5%BB%BA.html</url>
    <content type="text"><![CDATA[前言这个项目有一段时间没有更新了，不过我可没有偷懒哟，是偷偷准备了一个大招，现在是时候展示啦哈哈。 我们今天要做的，就是将我们的项目通过docker-compose 构建成镜像运行。为什么要这样做呢？比我我前面的这些教程，用到了mysql,如果你们想要运行我的程序，就必须在自己电脑上装mysql 数据库才行，也就是项目用依赖了哪些环境，都必须先将这些环境部署好才能运行项目，那我们要做的，只用安装docker和docke-compose ，然后运行就完事了，不用管什么环境的。 初一听，好像还行，但是根本没有接触docker-compose 怎么办？不要慌，一个专题带你飞，虽不能让你所向披靡，但也足你叱咤江湖啦传送门：docker自我修炼从0到1 还有我查看项目发现竟然没有配置Redis，但是Redis 使用也是很广泛的，我之前的文章有详细的讲解springboot项目怎么使用redis。我这里只是简单的将他配上去确保架构的完整性，就不做更多的讲解，需要详细了解的可以参考Redis–从零开始随笔 好了，前面说了这么多无非是想表达这篇文章分两个大部分，部署Redis和通过docker-compose 搭建。 配置Redis增加配置在pom.xml文件中增加Redis的依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; 在application.properties 中存在redis 连接信息。1234567891011121314151617#配置redis# Redis数据库索引（默认为0）spring.redis.database=0 # Redis服务器地址spring.redis.host=192.168.252.53# Redis服务器连接端口spring.redis.port=6389 # Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制） 默认 8spring.redis.lettuce.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1spring.redis.lettuce.pool.max-wait=-1# 连接池中的最大空闲连接 默认 8spring.redis.lettuce.pool.max-idle=8# 连接池中的最小空闲连接 默认 0spring.redis.lettuce.pool.min-idle=0 简单使用配置好了，我们还是说一下简单使用，这些在之前也有讲，代码也是差不多的。我们在controller 层创建一个 redis 包，在Redis包下创建一个RedisController类。代码如下：12345678910111213141516171819202122@RestController@RequestMapping("/redis")@Slf4jpublic class RedisController &#123; @Autowired private StringRedisTemplate stringRedisTemplate; @RequestMapping(value = "/add",method = RequestMethod.GET) public String add(@RequestParam(value="key")String key,@RequestParam(value = "value") String value)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); ops.set(key,value); return "success"; &#125; @RequestMapping(value = "/get",method = RequestMethod.GET) public String get(@RequestParam(value = "key")String key)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); return (String) ops.get(key); &#125;&#125; 好了项目整合Redis 就这么多了，至于测试我们待会后面部署好了一起测试。接下来开始重头戏。 docker-compose 部署我们现在有一个springboot项目，现在怎么构建成一个镜像放在服务器上运行呢？我们一步步来，首先是增加配置。 pom.xml还是我们熟悉的pom.xml 我们需要在pom.xml 中 build–&gt;plugins 中增加配置：1234567891011121314151617181920212223242526272829303132333435363738&lt;!-- Docker --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;!-- 将插件绑定在某个phase执行 --&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;build-image&lt;/id&gt; &lt;!-- 用户只需执行mvn package ，就会自动执行mvn docker:build --&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!-- 指定生成的镜像名 --&gt; &lt;imageName&gt;$&#123;docker.image.prefix&#125;/$&#123;project.artifactId&#125;:$&#123;project.version&#125;&lt;/imageName&gt; &lt;!-- 指定标签 --&gt; &lt;imageTags&gt; &lt;imageTag&gt;$&#123;project.version&#125;&lt;/imageTag&gt; &lt;/imageTags&gt; &lt;!-- 指定 Dockerfile 路径 --&gt; &lt;dockerDirectory&gt;src/main/docker&lt;/dockerDirectory&gt; &lt;!-- 指定远程 docker api地址 --&gt; &lt;dockerHost&gt;http://127.0.0.1:2375&lt;/dockerHost&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;!-- jar包所在的路径此处配置的对应target目录 --&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;!-- 需要包含的jar包,这里对应的是Dockerfile中添加的文件名 --&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt; 上面都有注释没有什么好讲的，其中指定生成镜像名的${docker.image.prefix} 的值在properties 中配置。 Dockerfile我们在项目的src–&gt;main 创建一个docker 包，包下创建一个Dockerfile 问价 ，内容如下：1234FROM java:8VOLUME /tmpADD zlflovemm-1.0.0.jar zlflovemm-1.0.0.jarENTRYPOINT ["java","-jar","/zlflovemm-1.0.0.jar"] mvn package接下来我们使用maven package 打包，就可以将项目打包成镜像并发送到我们配置的服务器上。可以看到我们的镜像已经到我们的服务器了。 docker-compose.yml我们现在项目镜像有了，现在需要通过docker-compose.yml 将项目，mysql .redis 都管理起来。我们创建一个docker-compose.yml 内容如下：1234567891011121314151617181920212223242526272829303132333435version: "3"services: webapp: image: quellanan/zlflovemm:1.0.0 ports: - "9001:9090" volumes: - "/data" depends_on: - redis - mysql redis: image: redis:latest restart: always ports: - "6389:6379" volumes: - /redis/redis.conf:/etc/redis/redis.conf command: redis-server /etc/redis/redis.conf mysql: image: mysql:latest restart: always environment: MYSQL_ROOT_PASSWORD: "123456" MYSQL_USER: 'root' MYSQL_PASS: '123456' ports: - "3306:3306" volumes: - "./db:/var/lib/mysql" - "./conf/my.cnf:/etc/my.cnf" - "./init:/docker-entrypoint-initdb.d/" webapp 和Redis 配置我就不说了，上一篇文章已经说了，这里我们说一下mysql 的配置。image:mysql:laster 我们选择最新的版本的mysql 镜像。1234environment: MYSQL_ROOT_PASSWORD: "123456" MYSQL_USER: 'root' MYSQL_PASS: '123456' environment 配置的是mysql 的root 用户密码普通的用户及密码。配置我们自定义的mysql 配置，如果使用的默认的，这里的数据卷其实可以不用指定。1234volumes: - "./db:/var/lib/mysql" - "./conf/my.cnf:/etc/my.cnf" - "./init:/docker-entrypoint-initdb.d/" 我们创建好了docker-compose 后，在同级目录下执行1docker-compose up 就可以看到镜像容器已经启动了。项目包含三个镜像,现在我们来验证一下项目正常启动没有。 测试由于我们使用了docker镜像的mysql 。所以之前的项目使用的数据库需要重新执行一次，我们代码中有，我就不贴出来了。项目的接口我们现在调一下看看。12# 检测项目正常启动没有http://192.168.252.53:9001/zlflovemm/ 12# 检测mysql 是否正常http://192.168.252.53:9001/zlflovemm/user/list 123# 检测Redis 是否正常http://192.168.252.53:9001/zlflovemm/redis/add?key=a&amp;value=123http://192.168.252.53:9001/zlflovemm/redis/get?key=a 番外到此为止，将springboot项目构建成镜像完成啦，感觉整篇文件将的比较粗糙，这篇主要是整合，详细的都在前面的博客已经讲了，所以这里就没有再讲了。 好了，就说这么多啦代码上传到github：https://github.com/QuellanAn/zlflovemm 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五、springboot 简单优雅是实现邮件服务]]></title>
    <url>%2F20210810%2F%E4%BA%94%E3%80%81springboot%20%E7%AE%80%E5%8D%95%E4%BC%98%E9%9B%85%E6%98%AF%E5%AE%9E%E7%8E%B0%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1.html</url>
    <content type="text"><![CDATA[前言spring boot 的项目放下小半个月没有更新了，终于闲下来可以开心的接着写啦。之前我们配置好mybatis 多数据源的，接下来我们需要做一个邮件服务。比如你注册的时候，需要输入验证码来校验。这个验证码就可以通过邮件来发送。当然现在验证码大部分都是通过短信，单邮件有时候也是必不可少的。所以我们的spring架手架还是将邮件服务也搭建起来。下一篇将短信服务也整合进来。好了，言归正传。搭建邮件服务没有接触可能会觉得很麻烦或者单机环境测试环境都实现不了。觉得没有邮件服务。其实我们个人使用的话，是可以做到的。qq邮箱，网易邮箱都可以的。我这里使用的是QQ邮箱。网上有很多相关的教程。 邮箱服务器准备登录QQ邮箱，点击设置 –&gt;账户 可以找到 下图这个。 需要开通 POP3/SMTP服务。开通这个后，会生成一个秘钥。这个秘钥我们待会会在项目中用到。拿小本本记下来哈哈。 添加依赖和配置邮箱准备好了，我们就开始我们的项目吧。首先在pom.xml 文件中添加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt; &lt;/dependency&gt; 然后在application.proteries 文件中添加配置，改成自己的邮箱。password 就是刚刚生成的那个秘钥。QQ邮箱的服务器地址是：smtp.qq.com 。网易的大家可以搜一下。123456spring.mail.host=smtp.qq.comspring.mail.username=1186154608@qq.comspring.mail.password=abcdefgqazqazspring.mail.default-encoding=UTF-8mail.from=1186154608@qq.com Service 层配置信息都好了之后，我们就可以来使用啦。这里我们暂时没有涉及到数据库，就直接写Service层和controller 层。在service 包下创建一个MailService 和MailServiceImpl MailServiceImpl 中代码12345678910111213141516171819@Service@Slf4jpublic class MailServiceImpl implements MailService&#123; @Autowired private JavaMailSender mailSender; @Value("$&#123;mail.from&#125;") private String mailFrom; @Override public void sendSimpleMail(String mailTo) &#123; SimpleMailMessage message=new SimpleMailMessage(); message.setFrom(mailFrom); message.setTo(mailTo); message.setSubject("simple mail"); message.setText("hello world"); mailSender.send(message); log.info("邮件已经发送"); &#125;&#125; 这里我们就先简单的测试一下看看邮件能不能发送。mailFrom 是发件人，mailTo 是收件人。message.setSubject()设置邮件主题。message.setText()设置邮件内容。 mailSender.send(message)是发送短信。 controller层 我们创建一个MailController类。代码如下： 123456789101112 @RestController@RequestMapping("/mail")public class MailController &#123; @Autowired private MailService mailService; @RequestMapping(value = "/send",method = RequestMethod.GET) public String sendMail(@RequestParam(value = "userName")String userName)&#123; mailService.sendSimpleMail(userName); return "success"; &#125;&#125; 可以看到就一个发送的接口。很简单，参数传过来接收人的邮箱就好了。 测试 到此为止，我们邮件服务的demo 就已经搭建好了。我们接下来测试测试一下。我们启动项目。然后调接口 1http://localhost:9090/zlflovemm/mail/send?userName=1303123974@qq.com 提示已经发送成功啦，我们进邮箱看下我们发送情况。可以看到是发送成功了。所以说明我们的邮件服务搭建成功了。 所以现在看来，springboot 集成邮件服务是非常简单的，配置邮件服务器，就可以直接使用啦。 发送附件有时候我们发送邮件不仅仅发送内容，还需要发送附件，那怎么实现呢。其实也很简单。那些配置还是不变。我们在service 层。写一个sendMail方法。如下12345678910111213141516171819@Override public void sendMail(String mailTo) &#123; MimeMessage message=mailSender.createMimeMessage(); MimeMessageHelper helper = null; try &#123; helper = new MimeMessageHelper(message, true); helper.setFrom(mailFrom); helper.setTo(mailTo); helper.setSubject("simple mail"); helper.setText("hello world", true); FileSystemResource file = new FileSystemResource(new File("E:\\myself\\test.xls")); String fileName = file.getFilename(); helper.addAttachment(fileName, file); mailSender.send(message); log.info("邮件已经发送"); &#125; catch (MessagingException e) &#123; log.error("&#123;&#125;",e); &#125; &#125; 可以看到和我们开始测试的时候，有一点不同。这里先1MimeMessage message=mailSender.createMimeMessage(); MimeMessage 比 SimpleMailMessage 功能更强大，可以发送附件，也可以将内容转成html 格式发送。所以一般实际使用的时候都使用MimeMessage。另外发送附件，还需要借助MimeMessageHelper 。MimeMessageHelper是辅助MimeMessage的。1234helper.setFrom(mailFrom);helper.setTo(mailTo);helper.setSubject("simple mail");helper.setText("hello world", true); 这些和前面是一样的，发件人收件人，主题，内容。helper.addAttachment()是添加附件的。 好了，接下我们测试一下。可以看到发送的邮件是有附件的。证明没问题。 番外好了，就说这么多啦，今天项目的代码也同步到github 上啦。github地址：https://github.com/QuellanAn/zlflovemm 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五、docker-compose开锋（docker 三剑客）]]></title>
    <url>%2F20210810%2F%E4%BA%94%E3%80%81docker-compose%E5%BC%80%E9%94%8B%EF%BC%88docker%20%E4%B8%89%E5%89%91%E5%AE%A2%EF%BC%89.html</url>
    <content type="text"><![CDATA[前言终于写到docker-compose了，其实我最开始接触docker的时候，是因为一个开源项目需要用docker 环境和docke-compose 所以我最先接触的是docker-compse 后面才恶补的docker的一些基础知识。 可以看到docker-composer 和docker 有关系，但是你也了解docker-compose 的命令 简单的操作docker 容器。 说了这么多，还没有说docker-compose 有什么作用，为什么要使用docker-coompose。其实我们都知道，在我们实际的项目中，一个项目一般都是前端服务端数据库都进行分离的。所以一个项目一般都是有多个镜像组成的。那怎么将这一组镜像管理起来呢？就是通过docker-compose 啦 docker-compose 中有两个重要呢的概念服务(service ): 就是我们上面说的一个应用容器，仅仅负责真个项目的中的一部分，比如数据库mysql. 项目(project)：就是我们上面说你的项目啦，包含一组容器。 docker-compose 通过 docker-compose.yml 文件对这一组容器进行配置。 好了，正式开始接触 docker-compose吧 安装docker-compose 安装很简单，windos 版本的已经自带了。我们可以通过1docker-compose -v 查看我们本机安装的docker-compose 版本。Linux 安装也很简单。在官网上也有：https://github.com/docker/compose/releases12345678910sudo apt-get update#安装最新的docke-cesudo apt-get install docker-ce# 下载最新的docker-composecurl -L https://github.com/docker/compose/releases/download/1.25.0-rc4/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose# 修改docker-compose 权限chmod x /usr/local/bin/docker-compose 卸载 docke-compose1sudo rm /usr/local/bin/docker-compose 本地安装如果上面安装不行的话，或者报错，可以用下面的方式进行安装。 在上面的官网上找到对应版本的Assests 选择对应的文件下载。 下载下来后，我们放到 /usr/local/bin/ 目录下。执行下面操作1234#改名sudo mv docker-compose-Linux-x86_64 ./docker-compose#增加执行权限sudo chmod x /usr/local/bin/docker-compose 这样就和上面的效果是一样的啦，我们可以通过-v ```查看安装成功没有。1234567# docker-compose.yml知道了docker-compose 那最重要的就是docker-compose.yml 文件啦，通过这个文件就可以管理项目的镜像了，那我们怎么写docker-compose.yml 文件呢？官方提供了很多模版，我们按照模版来写就可以了。## 主模版 version: “3” services: webapp: image: examples/web ports: - &quot;80:80&quot; volumes: - &quot;/data&quot; 12345可以看到格式就是我们熟悉的yml 格式，和我们springboot 项目中配置是差不多的。我们前面知道的一个项目是由一组服务组成的，也就是你对应文件中的services。webapp 就是我们为服务起的一个名字，image 对应的镜像名，ports 镜像暴露的端口，volumes 镜像的数据卷。可以看到，里面的命令和docker run 的指令是差不多的。## depends_on解决容器的依赖，表示一个容器依赖其他的其他容器，比如说 version: “3” services: webapp: image: examples/web ports: - &quot;80:80&quot; volumes: - &quot;/data&quot; depends_on: - redis - mysql redis: image: redis:latest restart: always ports: - &quot;6379:6379&quot; mysql: image: mysql:latest restart: always ports: - &quot;3306:3306&quot; 123456789还是上面的例子，只不过我多加了两个 service 。表示这个项目中用到了mysql 和redis 并且在webapp 中使用depends_on 表示redis 和mysql 先webapp 启动。更多的模版，大家用的时候可以参考官网上就可以了我感觉。知道是什么意思就可以，不用都记下来。https://yeasy.gitbooks.io/docker_practice/content/compose/compose_file.html# docker-compose 指令我们可以通过帮助指令来查看docker-compose 怎么使用。 docker-compose –help12基本语法格式： docker-compose [-f=…] [options] [COMMAND] [ARGS…]1234567891011121314151617181920212223242526272829303132我这里也就将一下常见的，因为通过```--help```都可以查到。## docker-compose config用于检查我们的docker-compose.yml 文件的内容格式是否正确，在我们运行之前先检测一下比较好。## docker-compose up用来启动项目，比如我们现在有一个docker-compose.yml 文件，那我们进入到这个文件目录，执行```docker-compose up```就可以将项目依赖的镜像下载下来，并启动相应的容器服务。整个项目都启动起来了，直接使用就好了，可谓是相当强大了。docker-compose up -d 表示后台启动。## docker-compose down 和 up 对应，用来停止我们的项目。## docker-compose restart 重启我们项目其他的也不说了，可以查看官网：https://docs.docker.com/compose/reference/overview/# demo 光说不练假把式，我们上面说的一堆基础的知识，还是需要我们实践才行，不然我们不会有什么实质性的收获。所以接下来我们就搭建一个简单的demo。我们还是用前面的的hello的项目，我们对项目进行一些修改，增加 redis。这里我就不具体的讲啦，有不会的可以看我这篇文章，写的很简单明了：[三、Redis在SpringBoot中使用案例](https://blog.csdn.net/qq_27790011/article/details/98344732)我们这里先在在pom.xml 中增加redis 依赖： &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; 12在application.properties 中增加redis 配置 #配置redis Redis数据库索引（默认为0）spring.redis.database=0 Redis服务器地址spring.redis.host=192.168.252.53 Redis服务器连接端口spring.redis.port=6389 Redis服务器连接密码（默认为空）spring.redis.password= 连接池最大连接数（使用负值表示没有限制） 默认 8spring.redis.lettuce.pool.max-active=8 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1spring.redis.lettuce.pool.max-wait=-1 连接池中的最大空闲连接 默认 8spring.redis.lettuce.pool.max-idle=8 连接池中的最小空闲连接 默认 0spring.redis.lettuce.pool.min-idle=0 12在controller 包中创建一个redisController 类 @RestController@RequestMapping(“/redis”)@Slf4jpublic class RedisController { @Autowired private StringRedisTemplate stringRedisTemplate; @RequestMapping(value = &quot;/add&quot;,method = RequestMethod.GET) public String add(@RequestParam(value=&quot;key&quot;)String key,@RequestParam(value = &quot;value&quot;) String value){ ValueOperations ops=stringRedisTemplate.opsForValue(); ops.set(key,value); return &quot;success&quot;; } @RequestMapping(value = &quot;/get&quot;,method = RequestMethod.GET) public String get(@RequestParam(value = &quot;key&quot;)String key){ ValueOperations ops=stringRedisTemplate.opsForValue(); return (String) ops.get(key); } }1234567好了，我们将项目打包成镜像，至于怎么打包成镜像上一篇我已经讲了，不会的可以查看:[三、DockerFile 定制属于自己的专属镜像](https://blog.csdn.net/qq_27790011/article/details/102729974#docker_162)## 准备我们的redis.conf我们使用 redis 镜像，但是我们不想使用默认的配置，想要使用自己的配置启动redis。所以我们来复制一份redis.conf 。我就修改了 #设置redis 可以远程访问bind 0.0.0.0 #后台启动daemonize yes12345![file](https://img-blog.csdnimg.cn/20191108155950758.jpeg)redis.conf 放在我们上图的redis目录下。## docker-compose.yml我们来编写docker-compose.yml ，直接套用上面的模版。 version: “3” services: webapp: image: quellanan/hello:1.0.0 ports: - &quot;9000:9000&quot; volumes: - &quot;/data&quot; depends_on: - redis redis: image: redis:latest restart: always ports: - &quot;6389:6379&quot; volumes: - /redis/redis.conf:/etc/redis/redis.conf command: redis-server /etc/redis/redis.conf 12345可以看到基本上是根据模版来的，指定我们镜像，端口，数据卷。这里webapp 的没有什么好说的 ，上面都说了，一看就能懂，说一下redis的。images 指定的镜像为redis:latest ，如果你本地没有这个镜像，就会从官网上下载。restart:always 表示自动重启。 ports:”6389:6379”1表示镜像启动redis容器的端口是6379，映射到服务器的6389 端口，所以我们在项目配置的redis 端口应该是6389. volumes: /redis/redis.conf:/etc/redis/redis.conf12表示将 ./redis/redis.conf 文件加载到 容器中的 /etc/redis/redis.conf 位置。说明第一个路径是相对路径，第二个路径是绝对路径。 command: redis-server /etc/redis/redis.conf12345表示在启动redis 容器的时候会执行的命令。这样就可以实现启动redis镜像加载我们自己的配置文件了。## docker-compose up准备工作都做好了，开始我们大展拳脚，哈哈，其实不然，我们准备工作做好了，就已经成功一大半了，我们接下来要做的就是 就是通过docker-compose 启动镜像。我们直接在存放docker-compose.yml 目录下执行： docker-compose up1234![file](https://img-blog.csdnimg.cn/20191108155951768.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9xdWVsbGFuYW4uYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70)这样我们就启动成功了。如果想后台启动的话输入： docker-compose up -d123## 测试我们项目启动，现在来测试一下到底成功没有。 http://192.168.252.53:9000/123这个是测试项目是正常启动了。![file](https://img-blog.csdnimg.cn/20191108155951218.jpeg)我们接下来看看我们配置的redis 有没有成功。 http://192.168.252.53:9000/redis/add?key=a&amp;value=123qazhttp://192.168.252.53:9000/redis/get?key=a12345678![file](https://img-blog.csdnimg.cn/20191108155952431.jpeg)![file](https://img-blog.csdnimg.cn/20191108155952729.jpeg)可以看到界面上接口没有问题了，redis已经已经生效了，我们还不太确定，可以去服务器上看下。![file](https://img-blog.csdnimg.cn/20191108155952359.jpeg)。本地没有装redis ，我们可以进入到redis容器中去查看。操作如下：先通过```docker ps ```查看redis 容器id然后通过下面命令进入容器。 docker exec -it 容器id /bin/bash1最后连接redis redis-cli` 番外好了，就说这么多啦 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五、Spring Cloud之网关服务 zuul]]></title>
    <url>%2F20210810%2F%E4%BA%94%E3%80%81Spring%20Cloud%E4%B9%8B%E7%BD%91%E5%85%B3%E6%9C%8D%E5%8A%A1%20zuul.html</url>
    <content type="text"><![CDATA[前言问：什么是网关服务？答：给外部提供单一的访问接口，并做过滤和拦截处理的服务。 问：微服务架构中网关服务有什么作用?答：我们微服务架构中项目众多，如果直接抛给外部，将会很容易引起调用错误并且大大增加了维护成本，所以我们需要提供单一访问接口，外部请求全部通过统一端口网关，然后在分发到不同的服务器。如果熟悉nginx 的同学想必就知道，其实就是nginx 反向代理的功能。 问：那为什么不使用nginx，而是使用zuul答： nginx 确实可以实现网关的功能，但是我们同样的要维护nginx.conf 文件，如果项目够多，是很容易出问题的，使用zuul 的话，可以和eureka 天然的融合，使得管理维护起来更加方便。 下面我们就来看下怎么实现zuul 吧。 pom.xml我们创建一个zuul 的模块，pom.xml 文件中引入zuul 和erueka123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 启动类在启动类中我们加入@EnableZuulProxy 注解将springBootApplication 注解换成@SpringCloudApplication 注解。EnableZuulProxy 注解表示启动zuul 网关服务。SpringCloudApplication 注解，我们来看下源码123456789@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootApplication@EnableDiscoveryClient@EnableCircuitBreakerpublic @interface SpringCloudApplication &#123;&#125; 可以看到包含的注解主要是SpringBootApplication、EnableDiscoveryClient、EnableCircuitBreaker 而这三个注解，我们前面都接触过的，SpringBootApplication就是Springboot项目启动的专用注解，EnableDiscoveryClient注解是将服务注册到服务中心，并发现服务的。EnableCircuitBreaker 是实现熔断处理的注解，所以说SpringCloudApplication 注解是对三个的一层封装，所以我们以后构建微服务的时候，使用SpringCloudApplication 注解会更方便。 application.properties接下来我们在配置问价中增加如下配置123456server.port=9007spring.application.name=zuuleureka.client.serviceUrl.defaultZone=http://localhost:8000/eureka/zuul.routes.test-a.path=/a/**zuul.routes.test-a.service-id=ribbon-consumer server.port和spring.application.name 用来指定项目启动的端口和项目在注册中心的名称，eureka.client.serviceUrl.defaultZone用来指定注册中心的地址。zuul.routes.*.path 和zuul.routes.*.service-id 用来指定我们的目的项目。比如我这里配置的ribbon-consumer 项目，将localhost:9007/a/** 转发到ribbon-consumer 对应的接口上。 测试 好了，我们现在就把网关配置好了。我们现在启动一下项目，启动如下几个项目进行测试吧就。 其中EurekaServer是注册中心，ribbon-consumer 是服务消费者，ribbon-consumer 是服提供者，zuul 是网关。我们启动好这几个项目后，我们输入一下地址： 1http://localhost:9007/a/index 可以看到其实访问的是1http://localhost:9003/index 默认映射上面的可以看到，我们主要的配置就是在配置文件中配置好目标地址的路径。但是这样的话，和nginx 有什么区别呢，如果项目足够多配置起来还是会出错的，所以前面说zuul 和eureka 可以无缝连接，所以，这里zuul 做了一个默认映射，为所有注册到注册中心的服务提供了一个唯一对应的默认映射。怎么说呢，我们看一下服务中心的控制台。zuul 将eureka 中服务名作为映射前缀，比如1http://localhost:9007/ribbon-consumer/index 可以看到，达到了一样的效果，ribbon-consumer 就是服务名。 请求过滤前面我们讲了zuul 网关可以转发请求，但是它还有一个强大的功能，那就是请求过滤，我们知道具体项目中我们的接口会做安全限制，所以在具体的项目中会写过滤器和拦截器。在微服务项目中，我们既然提供了统一的网关服务，所以我们可以将安全校验和具体业务剥离出来，将安全校验放在zuul 网关中来统一处理，这样减少了冗余代码，也方便维护。那么怎在zuul 中实现请求过滤呢？继承ZuulFilter 类。 我们创建一个AccessFilter你类来继承ZuulFilter 。代码如下：123456789101112131415161718192021222324252627282930313233@Slf4jpublic class AccessFilter extends ZuulFilter &#123; @Override public String filterType() &#123; return "pre"; &#125; @Override public int filterOrder() &#123; return 0; &#125; @Override public boolean shouldFilter() &#123; return true; &#125; @Override public Object run() throws ZuulException &#123; RequestContext ctx=RequestContext.getCurrentContext(); HttpServletRequest request=ctx.getRequest(); String token=request.getParameter("token"); if(token == null || !token.equals("123456"))&#123; log.info("token is error!"); ctx.setSendZuulResponse(false); ctx.setResponseStatusCode(500); return "error"; &#125; log.info("token is ok"); return null; &#125;&#125; 直接将书上的解释拿出来了。主要的方法是run方法，获取请求中的request 和参数，对参数进行校验从而过滤。这里我就是对token 进行简单的校验，也就是说只有检验通过了才能访问目标接口。昨晚上面这些还不够，还差一步，在项目zuul 服务启动的时候，需要将 AccessFilter bean 注册服务中。所以我们在启动类中注入1234@Beanpublic AccessFilter accessFilter()&#123; return new AccessFilter();&#125; 好了，我们来启动一下项目看看。可以看到就可以起到拦截的作用。 番外 到此为止，zuul 网关服务搭建好了，并运行一个非常简单的例子。 代码上传到github： https://github.com/QuellanAn/SpringCloud 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤ 阅读原文]]></content>
      <categories>
        <category>springCloud</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springCloud</tag>
        <tag>zuul</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二、docker 镜像容器常用操作(让我们用docker 溜得飞起)]]></title>
    <url>%2F20210810%2F%E4%BA%8C%E3%80%81docker%20%E9%95%9C%E5%83%8F%E5%AE%B9%E5%99%A8%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C(%E8%AE%A9%E6%88%91%E4%BB%AC%E7%94%A8docker%20%E6%BA%9C%E5%BE%97%E9%A3%9E%E8%B5%B7).html</url>
    <content type="text"><![CDATA[前言上篇讲了我们如何安装docker，现在该我们一展拳脚的时候了。接下来让我们一起学习一下docker常见的操作，让我们能够会使用 docker。 基本概念在讲使用之前，还是先将一下docker 的基本概念，毕竟上篇就讲了docker 的安装。一些基本的名词还是需要了解一下的。docker 最重要的就是镜像和容器了，还有一个仓库。 那什么是docker 镜像呢？ docker 镜像就相当于一个 root 文件系统，不仅包含容器运行的程序和资源，还包含运行依赖的配置。但是镜像不包含任何动态的数据。 通俗的来讲就像是我们项目运行需要各种依赖和配置以及各种部署。然后我们将这些环境和程序都打包在一起，形成一个可以直接运行的包。就相当于是docker镜像，将所有需要的环境都集成在一起。在哪都可以运行。 docker 镜像是分层存储的。docker镜像在构建的时候是一层层构建的前一层是后一层的基础，使得镜像在复用、定制变得更加简单。也由于镜像是分层存储的，所以镜像显示的size 大小并不是实际占用的物理内存。因为有很多中间镜像都是公用的。所以实际占用的内存会比显示的size要小。 查看容器实际的占用的内存使用1docker system df 现在知道镜像了，那镜像怎么使用呢？ 那就是通过容器啦，容器和镜像的关系就像是 对象和实例的关系。也就是说根据镜像创建一个可以直接运行的容器。容器是镜像的具体体现，所以容器就有创建，启动，停止，删除等操作。 镜像的使用好了，前面知道了什么是docker 镜像和容器，那现在就我们来看看怎么使用他们吧。 下载镜像我们安装好docker 后，怎么获取镜像呢？和git 拉取一样也是使用pull.1docker pull 详细的参数使用可以通过pull --help ```来查看12比如我们现在下载一个nginx的景象 docker pull nginx1默认会下载latest 的镜像，表示下载最新的镜像。也可以下载稳定版本的，或者下载指定版本的。 docker pull nginx:stable docker pull nginx:1.1612345![file](https://img-blog.csdnimg.cn/20191022172419766.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI3NzkwMDEx,size_16,color_FFFFFF,t_70)## 查询镜像我们镜像下载下来了，我们怎么查看我们电脑上有哪些镜像呢？其实上面我已经用了 docker image ls或者docker images 两者的效果是一样的。12具体使用一样的可以使用```docker image --help```。我们接下来将我们常用的。查询显示虚悬镜像 docker images -f dangling=true123虚悬镜像是没有作用的，占用内存空间，虚悬镜像怎么来呢？一般是我们下载镜像，依赖一些中间镜像，然后我们删除了下载的镜像，但是只是删除了上层镜像，依赖的镜像没有删除。这样没有依赖的中间镜像就成了虚悬镜像，是可以删除的。删除虚悬镜像 docker image prune1其他的一些查询操作。 #列出中间层镜像docker images -a #列出部分镜像docker images 仓库名 #过滤docker images -f since=仓库名docker images -f before=仓库名1234## 删除镜像我们现在知道怎么拉取镜像，以及在本地查看镜像，那我们想要删除镜像怎么删除呢？ docker image rm 镜像id1234我们可以通过镜像id 来删除镜像，并且不用完整的镜像id ,只要可以做唯一区分就好了。![file](https://img-blog.csdnimg.cn/2019102217242068.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI3NzkwMDEx,size_16,color_FFFFFF,t_70)除了通过镜像id 来删除镜像，还可以通过以下的几种方式来删除，更过的可以通过```docker image rm --help```来查看 删除所有仓库名为***的镜像docker image rm $(docker images -q 仓库名) 删除仓库名在***之前的镜像docker image rm $(docker images -q -f before=仓库名)123456789# 容器的使用上面讲了镜像的获取查看删除操作，那我们怎么根据镜像来操作相关的容器呢？## 创建和启动前面说了镜像和容器的关系就像是对象和实例的关系。我们一般使用都是使用实例，一样的我们docker使用也是使用docker容器。那我们怎么根据镜像来创建容器并使用它呢？使用 docker run1比如我们前面下载了那么多Nginx，我们现在启动你nginx 试试。 docker run -p 8080:80 nginx:stable1-p 是用来指定映射端口的，8080是我们设置访问那个端口，80 是Nginx本身的端口。也可以后台启动 docker run -d -p 8180:80 nginx:stable1设置容器name docker run –name myNginx -d -p 8280:80 nginx:stable12345678910![file](https://img-blog.csdnimg.cn/20191022172420349.jpeg)![file](https://img-blog.csdnimg.cn/20191022172419372.jpeg)我们现在在浏览器上访问一下8080，8081，8082这几个端口，应该都可以访问的。![file](https://img-blog.csdnimg.cn/20191022172420923.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI3NzkwMDEx,size_16,color_FFFFFF,t_70)## 终止容器上面的容器启动了，我们现在想要停止容器，我们该怎么做呢？如果我们没有后台启动，想要终止容器的话，直接Ctrl C 就可以退出来。如果我们是后台启动的，我们就需要通过 docker container stop 容器id12345![file](https://img-blog.csdnimg.cn/20191022172421213.jpeg)可以看到，删除的时候一样的不需要完整的id ,只要可以唯一区分就可以。## 查看容器其实上面已经用到了如何查询容器。 docker container ls1这个是查看正运行的容器。查看所有容器使用 docker containe la -a1更多的命令可以查看 docker container ls –help12345![file](https://img-blog.csdnimg.cn/20191022172421446.jpeg)上图可以看到我已经停止了三个Nginx容器。用 -a 才会显示。 ## 重启容器我们又想将关的容器重新启动，那怎么做 docker container start 容器id #重启运行中的容器docker container restart 容器id1234![file](https://img-blog.csdnimg.cn/20191022172421768.jpeg)## 删除容器 docker container rm 容器id 删除运行中的容器docker container -f 容器id 删除所有没有运行的容器docker container prune` 番外到此为止，我们常用的镜像和容器的操作就会使用啦。都是一些命令。忘记的可以–help 查看一下。 好了，就说这么多啦 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二、Vue 页面渲染过程]]></title>
    <url>%2F20210810%2F%E4%BA%8C%E3%80%81Vue%20%E9%A1%B5%E9%9D%A2%E6%B8%B2%E6%9F%93%E8%BF%87%E7%A8%8B.html</url>
    <content type="text"><![CDATA[前言上篇博文我们依葫芦画瓢已经将hello world 展现在界面上啦，但是是不是感觉新虚虚的，总觉得这么多文件，项目怎么就启动起来了呢？怎么访问到8080 端口就能进入到我们的首页呢。整个的流程是怎么样的呢？ 我也是刚刚接触，所以就会有这样的困惑，所以这篇就简单的理解一下项目页面渲染的过程。 渲染过程我们上篇文章说main.js 是无用的，是废代码，只是起到支撑框架的。但是其实我们应该有感觉，把他删除了整个项目就跑步起来了。其实main.js 算是项目的入口了。我们就从这个文件看起。123456789101112import Vue from 'vue'import App from './App'import router from './router'Vue.config.productionTip = falsenew Vue(&#123; el: '#app', router, components: &#123; App &#125;, template: '&lt;App/&gt;'&#125;) 可以看到代码非常的少，就导入了vue.js、我们的APP.vue 以及index.js第一次做动图，操作像是老年人，大家见谅。上图可以大概的看到引入的三个文件是什么了。Vue.config.productionTip = false 我们这里暂时不管，知道是一个配置信息就可以了，感兴趣的可以百度一下就知道什么意思了。123456new Vue(&#123; el: '#app', router, components: &#123; App &#125;, template: '&lt;App/&gt;'&#125;) 上面这些，如果完全没有vue 语法知识的话，确实不知道什么意思，但是我们看官网教程，起步的时候都是在当个html 文件中使用vue 的。在js 中就会用到这个。可以看到，其实都是差不多的，所以这里的作用就是实例化一个Vue。当然我们项目中，这里是为整个项目实例化了一个Vue ,el 指定的元素，这里就是我们index.html 中的div啦。router 就指定路由，也就是我们在index.js 配置的路由信息。components 指定的组件信息。项目有一个父组件就是APP.vue。我们自己写的所有组件都是在这个父组件之下的。怎么说呢，也就是说所有的界面，最外层的div 就是APP.vue 定义的。div 中其他的div 才是我们自己写的。看下面这个应该就会有所感觉吧。所以这里我们就可以解答上篇文章，为什么我们只是写了一个hello world 。但是为什么界面上呈现的会有图标，还有样式。因为在APP.vue 中设置了这些动洗。我们APP.vue 中的这些内容注释掉就可以看到效果。 我们将APP.vue logo和样式去掉，再来看看内容1234567891011&lt;template&gt; &lt;div id="app"&gt; &lt;router-view/&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name: 'App'&#125;&lt;/script&gt; 是不是发现和我们在组件中自己写的Hello.vue 格式完全一样，哈哈没错，vue文件就是这样的格式。可以看到template 渲染的是id 为app 的盒子(div)。这里应该是覆盖了index.html中的d 也为app 的盒子。 所有的 router-view 中的内容，都会被自动替换。script 中的代码则是脚本代码。 至此，整个过程就出来了：项目启动首先会读取main.js 。实例化一个vue,然后渲染APP.vue 文件内容，我们自己写的vue 组件则是通过路由转接到父组件下的。 番外我们项目的流程就讲到这里把，算是对上篇的补充，让我们对项目启动，界面渲染算是有一个大概的了解啦，我们接下来就按照官网上讲一下vue 的一些语法和特性，但是与官网上不同的是，官网上都是一个个的html,而我们就在这个项目的基础的上。将会是一个个的vue 文件。 代码上传到github：https://github.com/QuellanAn/zlflovemmVue 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>vue</category>
      </categories>
      <tags>
        <tag>vue</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二、Spring Cloud之注册中心 Eureka]]></title>
    <url>%2F20210810%2F%E4%BA%8C%E3%80%81Spring%20Cloud%E4%B9%8B%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%20Eureka.html</url>
    <content type="text"><![CDATA[前言算是正式开始学习 spring cloud 的项目知识了，大概的知道Springcloud 是由众多的微服务组成的，所以我们现在一个一个的来学习吧。 注册中心，在微服务中算是核心了。所有的服务都会注册到注册中心，请求服务的时候，并不会直接去请求服务地址，而是先通过注册中心再转到目的地址。虽然Eureka 已经停止维护了，但是我们暂时使用起来还是没有问题的。 Eureka 主要有服务注册中心、服务提供者和服务消费。很多时候服务消费者也是服务提供者。所以就 Eureka 而言，分为 Eureka 服务端和Eureka 客户端，服务端就是注册中心，客户端就是服务提供者和消费者。 单机模式好了，我们动手搭建一个Eureka 的服务端吧先，服务端有单机模式和集群模式，我们先来单机模式。 更具上篇文章讲的，我们使用maven 模块化开发，我们创建一个父级maven项目,pom.xml 文件内容如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;cn.quellanan&lt;/groupId&gt; &lt;artifactId&gt;SpringCloud&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Hoxton.SR1&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;modules&gt; &lt;module&gt;eureka-server-8000&lt;/module&gt; &lt;module&gt;eureka-server-8001&lt;/module&gt; &lt;module&gt;eureka-server-8002&lt;/module&gt; &lt;module&gt;zlflovemm&lt;/module&gt; &lt;/modules&gt;&lt;/project&gt; 可以看到文件中指定了spring boot 和Spring cloud 等基础依赖的版本，这样保证各个模块版本的一致性。 子模块接下来我们创建一个eureka-server-8000 的子模块。 pom.xmlpom.xml的内容如下：12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;cn.quellanan&lt;/groupId&gt; &lt;artifactId&gt;SpringCloud&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/parent&gt; &lt;groupId&gt;com.quellanan.springcloud&lt;/groupId&gt; &lt;artifactId&gt;eureka-server-8000&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;name&gt;eureka-server-8000&lt;/name&gt; &lt;description&gt;eureka project for Spring Boot&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 可以看到继承了父级pom,额外的增加了 spring-cloud-starter-netflix-eureka-server 的依赖。 @EnableEurekaServer在启动类中增加@EnableEurekaServer 注解，表示启用Eureka 服务端。1234567@SpringBootApplication@EnableEurekaServerpublic class EurekaServer8000Application &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServer8000Application.class, args); &#125;&#125; application.properties配置文件中增加如下配置1234567891011spring.application.name=spring-cloud-eureka-server-8000server.port=8000#表示是否将自己注册到Eureka Server，默认为true。eureka.client.register-with-eureka=true# 表示是否从Eureka Server获取注册信息，默认为true。eureka.client.fetch-registry=true#设置与Eureka Server交互的地址，查询服务和注册服务都需要依赖这个地址。多个地址可使用 , 分隔。eureka.client.serviceUrl.defaultZone=http://localhost:$&#123;server.port&#125;/eureka/ 现在我们就可以启动项目看看可以看到我们将自身注册到了服务中。 Eureka 客户端前面说了，服务提供者和服务消费者都是客户端，其实就是我们具体的某一业务的项目。所以我们再创建一个子模块。我这里分开吧，我们分别创建服务提供者和服务消费者。 服务提供者我们创建一个eureka-client-provider的子模块，pom 文件中引入spring-cloud-starter-netflix-eureka-client。1234567891011121314151617181920&lt;parent&gt; &lt;groupId&gt;cn.quellanan&lt;/groupId&gt; &lt;artifactId&gt;SpringCloud&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/parent&gt; groupId&gt;com.quellanan.springcloud&lt;/groupId&gt; &lt;artifactId&gt;eureka-client-provider&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;name&gt;eureka-client-provider&lt;/name&gt; &lt;description&gt;eureka-client-provider 服务提供者&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 启动类中加入@EnableEurekaClient注解或者@EnableDiscoveryClient注解都可以。123456789@SpringBootApplication@EnableDiscoveryClientpublic class EurekaClientProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaClientProviderApplication.class, args); &#125;&#125; application.properties 中增加如下配置1234server.port=9000#服务名，在注册时所用spring.application.name=eureka-client-providereureka.client.serviceUrl.defaultZone=http://localhost:8000/eureka/ 这里指定的eureka的服务中心的地址为8000。如上配置就可以将服务注册到注册中心啦。我们在写一个测试接口。创建一个IndexController 类，内容如下：1234567@RestControllerpublic class HelloController &#123; @RequestMapping("/hello") public String hello()&#123; return "hello world "; &#125;&#125; 服务消费者我们一样的创建一个 eureka-client-consumer的模块。pom文件如下：12345678910111213141516171819202122232425&lt;parent&gt; &lt;groupId&gt;cn.quellanan&lt;/groupId&gt; &lt;artifactId&gt;SpringCloud&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/parent&gt; &lt;groupId&gt;com.quellanan.springcloud&lt;/groupId&gt; &lt;artifactId&gt;eureka-client-consumer&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;name&gt;eureka-client-consumer&lt;/name&gt; &lt;description&gt;eureka-client-consumer 服务消费者&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 相对于服务提供者，我们增加了Feign 依赖，主要用来发现服务和实现客户端负载均衡，我们这里用来发现服务就可以了。 在启动类中@EnableDiscoveryClient 用来发现服务，并注入RestTemplate 的实例bean 用来对服务提供的接口进行调用。@LoadBalanced 是开启客户端负载均衡的，最开始我没有加这个注解，但是发现不加的话，服务消费者就不能通过服务名来获取可用的服务提供者的实例。所以这里大家可以试验一下。123456789101112@EnableDiscoveryClient@SpringBootApplicationpublic class EurekaClientConsumerApplication &#123; @Bean @LoadBalanced public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(EurekaClientConsumerApplication.class, args); &#125;&#125; 我们接下写一个接口，调用服务消费者，我们创建一个IndexController，内容如下：1234567891011@RestControllerpublic class IndexController &#123; private static final String applicationName = "eureka-client-provider"; @Autowired private RestTemplate restTemplate; @RequestMapping("/index") public String getHello()&#123; String url = "http://"+ applicationName +"/hello"; return restTemplate.getForObject(url,String.class); &#125;&#125; 这里我们可以看到applicationName 就是服务提供者的服务名。实际中，一种类型的服务可能有好几台服务器，可能物理地址和ip不一样，但是保证他们的服务名一样就可以了，这样服务消费者就可以通过服务名获取可用的列表，再通过复杂均衡策略选择其中一个实例访问。 最后我们在application中加上如下配置：1234server.port=9001#服务名，在注册时所用spring.application.name=eureka-client-consumereureka.client.serviceUrl.defaultZone=http://localhost:8000/eureka/ 测试现在我们启动注册中心和客户端这两个项目来看下。启动后，我们输入1http://localhost:8000 可以发现我们的客户端已经注册到注册中心啦。服务提供者和服务消费者都已经注册到了注册中心啦。我们再来调接口试试。我们输入如下：1http://localhost:9001/index 可以看到其实获取了9000服务提供者的接口。这样就实现了服务的注册和发现啦，并实现远程调用。 集群模式（高可用）上面我们我们搭建的注册中心只是单机模式，只有一个Eureka 服务端，单实际应用中注册中心其实是尤为重要的，所以就需要搭建集群环境，其实Eureka 对集群模式是天然的支持的，我们搭建也非常简单。为什么这么说呢，我们前面可以看到只要配置了eureka.client.serviceUrl.defaultZone 就就会被对应的注册中线检测到，所以我们代码完全一样，只需要将eureka.client.serviceUrl.defaultZone相互指引就可以了，就就可以简单的搭建一个高可用的环境。下面我们来搭建一个，因为我们就一台服务器，所以就用不同的端口，其实代码完全一样的，只是配置文件中配置不一样，我们分别把三个分配置文件贴出来。8000端口的1234567891011spring.application.name=spring-cloud-eureka-server-8000server.port=8000#表示是否将自己注册到Eureka Server，默认为true。eureka.client.register-with-eureka=true# 表示是否从Eureka Server获取注册信息，默认为true。eureka.client.fetch-registry=true#设置与Eureka Server交互的地址，查询服务和注册服务都需要依赖这个地址。多个地址可使用 , 分隔。eureka.client.serviceUrl.defaultZone=http://localhost:8001/eureka/,http://localhost:8002/eureka/ 8001端口：12345678spring.application.name=spring-cloud-eureka-server-8001server.port=8001#表示是否将自己注册到Eureka Server，默认为true。eureka.client.register-with-eureka=true# 表示是否从Eureka Server获取注册信息，默认为true。eureka.client.fetch-registry=true#设置与Eureka Server交互的地址，查询服务和注册服务都需要依赖这个地址。多个地址可使用 , 分隔。eureka.client.serviceUrl.defaultZone=http://localhost:8000/eureka/,http://localhost:8002/eureka/ 8002 端口12345678spring.application.name=spring-cloud-eureka-server-8002server.port=8002#表示是否将自己注册到Eureka Server，默认为true。eureka.client.register-with-eureka=true# 表示是否从Eureka Server获取注册信息，默认为true。eureka.client.fetch-registry=true#设置与Eureka Server交互的地址，查询服务和注册服务都需要依赖这个地址。多个地址可使用 , 分隔。eureka.client.serviceUrl.defaultZone=http://localhost:8000/eureka/,http://localhost:8001/eureka/ 我们现在分别启动这个这三个配置文件，你们可以用profile 来指向，我这为了分明，直接创建了三个模块。启动后，我们分别访问123http://localhost:8000/http://localhost:8001/http://localhost:8002/ 这里可以看到其实已经相互监控了。我们了解一下这两个配置参数。1234#定义服务续约任务的调用时间间隔，默认30seureka.instance.lease-renewal-interval-in-seconds=30#定义服务失效的时间默认90seureka.instance.lease-expiration-duration-in-seconds=90 我们现在再将我们的服务提供者和服务消费者注册进来，但是这里，需要修改的地方也是eureka.client.serviceUrl.defaultZone。将服务注册到集群中。1eureka.client.serviceUrl.defaultZone=http://localhost:8000/eureka/,http://localhost:8001/eureka/,http://localhost:8002/eureka/ 然后启动项目可，可以看到注册到了注册中心，并且可以调用服务提供者提供的接口。 总结最后画了一张图来说明整个注册中心的架构图。 可以看到注册服务端可以是一个集群。相互注册监控。服务消费者和服务提供者都是服务客户端，都会将服务注册到服务中心，同时这些服务也都可以使是集群或者分布式的。服务提供者会从服务端获取服务提供者可用的服务实例列表，通过负载均衡策略选择其中某一实例进行调用。这个算是Eureka 的总结吧哈哈 番外好啦，总是是写完了，这篇文章真是是卡了我好几天，有的地方写的不是很好，欢迎大家指点。 代码上传到github：https://github.com/QuellanAn/SpringCloud 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springCloud</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springCloud</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[九、Spring Boot 优雅的实现CORS跨域]]></title>
    <url>%2F20210810%2F%E4%B9%9D%E3%80%81Spring%20Boot%20%E4%BC%98%E9%9B%85%E7%9A%84%E5%AE%9E%E7%8E%B0CORS%E8%B7%A8%E5%9F%9F.html</url>
    <content type="text"><![CDATA[前言我们的springboot 架手架已经包含了mysql,redis，定时任务，邮件服务，短信服务，文件上传下载，以及docker-compose 构建镜像等等。 接下来让我们解决另一个常见的问题。一般的情况下，都是前后端分离的，我这个架手架的初衷也是前后端进行分离，所以这里就涉及到一个很严重的问题啦，当协议，端口，IP三者有其一不同就会产生跨域，所以需要做跨域支持。 测试跨域的文件在这之前，我们先写一个测试接口是否跨域的html ,这样下面的测试比较方便。12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;link type="test/css" href="css/style.css" rel="stylesheet"&gt;&lt;body&gt; &lt;input type="text" style="width:600px;height:30px;font-size:14px;" id="urlText" value="" /&gt; &lt;br&gt; &lt;input type="button" style="margin: 10px"; id="cors" value="判断是否可访问"/&gt;&lt;p&gt;http://localhost:9090/zlflovemm/&lt;/p&gt;&lt;script type="text/javascript" src="https://code.jquery.com/jquery-3.2.1.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; $(function()&#123; $("#cors").click( function()&#123; var url2 = $("#urlText").val(); $.post(&#123; contentType:'application/x-www-form-urlencoded;charset=UTF-8', url:url2, data: "/rAIeKeSBG1LV XoIq82/O", success:function(data)&#123; alert("success"); &#125; &#125;) &#125;); &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 接下来我们来学习下在springboot 项目中怎么实现支持跨域。 @CrossOrigin 注解这种方法是springboot 自带的，使用比较简单，在需要支持的跨域的接口上加上这个注解就可以了。比如在我们项目的demo 接口加上注解.就表示这个接口支持跨域，其中origins = “*”表示所有的地址都可以访问这个接口，也可以写具体的地址，表示只有这个地址访问才能访问到接口。 1@CrossOrigin(origins = "*") 测试我们也来测试一下，启动项目后，在浏览器上运行我们的测试的html文件。发现localhost:9090/zlflovemm/ 是可以访问的。说明跨域是支持的。大伙可以先将注解去掉测试一下，然后加上注解测试一下进行对比。 这种方式虽然很简单，但是缺点也不小，需要跨域的接口都需要加上这个注解，这对前后端分离的项目是不友好的，所以这种方式基本上用的很少。 重写WebMvcConfigurer的addCorsMappings 方法。这种方法在实际项目中也用的比较多，是一种全局支持跨域的方法。我们创建一个CorsConfig 类。内容如下：1234567891011@Configurationpublic class CorsConfig implements WebMvcConfigurer &#123; @Override public void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping("/**")//项目中的所有接口都支持跨域 .allowedOrigins("*")//所有地址都可以访问，也可以配置具体地址 .allowCredentials(true) .allowedMethods("*")//"GET", "HEAD", "POST", "PUT", "DELETE", "OPTIONS" .maxAge(3600);// 跨域允许时间 &#125;&#125; 加上@Configuration 表示是配置类，在项目启动的时候会加载。实现WebMvcConfigurer 接口并重写addCorsMappings 方法。代码比较简单，也有注释。 测试的话，大家可以自行测试，我测试都是通过的和上面一样测试就可以，这里就不占篇幅了。 Filter除了上面方法外，也可以使用过滤器。我们创建一个CorsFilter 类，内容如下：12345678910111213141516@Slf4j@Componentpublic class CorsFilter implements Filter &#123; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletResponse response = (HttpServletResponse)servletResponse; response.setHeader("Access-Control-Allow-Origin", "*"); response.setHeader("Access-Control-Allow-Methods", "POST, PUT, GET, OPTIONS, DELETE"); response.setHeader("Access-Control-Max-Age", "3600"); response.setHeader("Access-Control-Allow-Headers", "Origin, X-Requested-With, Content-Type, Accept, client_id, uuid, Authorization"); response.setHeader("Cache-Control", "no-cache, no-store, must-revalidate"); response.setHeader("Pragma", "no-cache"); filterChain.doFilter(servletRequest,response); &#125;&#125; 上面代码中设置response.setHeader(“Access-Control-Allow-Origin”, “*”);表示所有的地址都可以访问项目接口。 番外接下来我们再介绍一个常用的功能，前后端分离，在访问接口的时候，有的 公司往往会增加一下专属的后缀名才能访问。实际上没有什么太大的作用，能稍微增加一下系统的安全性。这里我就简单是实现一下。真个都非常简单。一样的是实现WebMvcConfigurer 接口，重写configurePathMatch你方法和增加一个dispatcherServlet。 代码如下：1234567891011@Override public void configurePathMatch(PathMatchConfigurer configurer) &#123; configurer.setUseRegisteredSuffixPatternMatch(true); &#125; @Bean public ServletRegistrationBean servletRegistrationBean(DispatcherServlet dispatcherServlet) &#123; ServletRegistrationBean bean = new ServletRegistrationBean(dispatcherServlet); bean.addUrlMappings("*.zlf"); return bean; &#125; 这个功能实现，就只用这个多代码，configurePathMatch方法中设置的configurer.setUseRegisteredSuffixPatternMatch(true); 主要是将index 和index.* 都指向我们controller 中配置的@RequestMapping(“/index”)。 下面的servletRegistrationBean 方法主要是增加自定义拦截器，只有后缀为“.zlf”的接口才放行。 这样两步就简单的实现了接口增加自定义的后缀名啦。 到此为止，springboot 支持跨域的方式就差不多了，当然还有其他的实现方式没有研究。这些希望对大家有帮助。 好了，就说这么多啦代码上传到github：https://github.com/QuellanAn/zlflovemm 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三、Vue 的一些语法样例]]></title>
    <url>%2F20210810%2F%E4%B8%89%E3%80%81Vue%20%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AF%AD%E6%B3%95%E6%A0%B7%E4%BE%8B.html</url>
    <content type="text"><![CDATA[前言其实vue 的语法在官网上都有详细的讲解和例子，我这里就不多做什么说明，只是把自己学习这些语法是练习的例子贴出来。另外官网上的例子是一个个的html文件。我这里的是一个的vue 文件，通过不同的路由进行访问。类似就上图的这种效果吧，没有什么样式，大伙将就看看嘿嘿。好了，下面我们就一起来看下主题的vue 语法吧。 路由其实不应该先讲路由的，但是想要做这种点击跳转的就是通过路由实现的。其实也很简单，我们只求会用，不求为什要这样吧先。123&lt;router-link :to="&#123;name: 'IfAndFor'&#125;"&gt;条件与循环&lt;/router-link&gt; 可以看到我们通过 router-link 就可以实现跳转。to 表示跳转的地址，name 指跳转的路由。当然这个路由需要我们在src–router–index.js 中配置好，并且有相关的组件才行哟。 我们要新增路由的话，就在index.js 中增加对应配置就好了，然后就可以通过router-link来实现界面见的跳转。 条件与循环我们配置好路由后，现在我们来看看v-if 和v-for 我们新建一个组件如下:12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;template xmlns:v-bind="http://www.w3.org/1999/xhtml"&gt; &lt;div&gt; &lt;div id="for"&gt; &lt;p&gt;一&lt;/p&gt; &lt;table&gt; &lt;tr v-for="(value, key, index) in object"&gt; &lt;td v-if="key === 'url'"&gt; &lt;a v-bind:href="value"&gt; &#123;&#123;value&#125;&#125;&lt;/a&gt; &lt;/td&gt; &lt;td v-else&gt; &#123;&#123; value &#125;&#125; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;br&gt; &lt;p&gt;二&lt;/p&gt; &lt;ul&gt; &lt;li v-for="(value, key, index) in object"&gt; &#123;&#123; index &#125;&#125;. &#123;&#123; key &#125;&#125; : &#123;&#123; value &#125;&#125; &lt;/li&gt; &lt;/ul&gt; &lt;br&gt; &lt;p&gt;二&lt;/p&gt; &lt;ul&gt; &lt;li v-for="(value, key) in object"&gt; &#123;&#123; key &#125;&#125; : &#123;&#123; value &#125;&#125; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default &#123; name: "", data()&#123; return &#123; object: &#123; name: 'quellanan', url: 'http://quellanan.xyz', slogan: '学的不仅是技术，更是梦想！' &#125; &#125; &#125; &#125;&lt;/script&gt; 可以看到我使用了三种方式进行for 循环。index 是索引，key 是键， value 是值。这些其实和Java 中的循环差不多。无非就是通过索引遍历，要不就是通过键值遍历。 v-if 和v-else-if v-else 也是一样的。满足条件就显示组件，知道这样用就可以。 但是有一点，上面代码也发现了，无论是v-if 还是v-for, 都要与某个标签结合使用。单独是无法使用的。 监听事件听起来很高大上，其实就是一个 watch 方法。我们写一个单位换算的组件:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889&lt;template&gt; &lt;div&gt; &lt;div style="margin: 20px"&gt; 千米 : &lt;input type = "text" v-model = "kilometers"&gt; 米 : &lt;input type = "text" v-model = "meters"&gt; &lt;p id="info"&gt;&lt;/p&gt; &lt;/div&gt; &lt;div style="margin: 20px"&gt; 小时 : &lt;input type = "text" v-model = "hour"&gt; 分钟 : &lt;input type = "text" v-model = "minute"&gt; 秒 : &lt;input type = "text" v-model = "second"&gt; &lt;br&gt; 天 : &lt;input type = "text" v-model = "day"&gt; &lt;br&gt; 星期 : &lt;input type = "text" v-model = "week"&gt; &lt;/div&gt; &lt;div style="margin: 20px"&gt; &lt;p &gt;计数器: &#123;&#123; counter &#125;&#125;&lt;/p&gt; &lt;button @click = "counter++"&gt;点我&lt;/button&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default &#123; name: "", data()&#123; return&#123; kilometers : 0, meters:0, second : 0, minute : 0, hour : 0, day : 0, week : 0, counter: 0 &#125; &#125;, watch : &#123; kilometers:function(val) &#123; this.kilometers = val; this.meters = this.kilometers * 1000 &#125;, meters : function (val) &#123; this.kilometers = val/ 1000; this.meters = val; &#125;, week:function(val) &#123; this.week = val; this.day = this.week * 7; this.hour = this.day * 24; this.minute = this.hour * 60; this.second = this.minute * 60; &#125;, day : function (val) &#123; this.day = val; this.week = this.day/7; this.hour = this.day * 24; this.minute = this.hour * 60; this.second = this.minute * 60; &#125;, hour : function (val) &#123; this.hour = val; this.day = this.hour/24; this.week = this.day/7; this.minute = this.hour * 60; this.second = this.minute * 60; &#125;, minute : function (val) &#123; this.minute = val; this.hour = this.minute/60; this.day = this.hour/24; this.week = this.day/7; this.second = this.minute * 60; &#125;, second : function (val) &#123; this.second = val; this.minute = this.second/60; this.hour = this.minute/60; this.day = this.hour/24; this.week = this.day/7; &#125;, counter :function(nval, oval) &#123; //alert('计数器值的变化 :' + oval + ' 变为 ' + nval + '!'); &#125; &#125; &#125;;&lt;/script&gt; v-model 表示数据双向绑定，这个没有什么好说的。data 初始化数据，watch 方法中就是监听函数，监听各自的组件并进行处理。 发送HTTP 请求我们要做前后端分离，那么通过http 请求访问后端数据是避免不了的。所以我们一起来看下。我这里也是查看资料中的例子。直接拿过来用了。我们创建一个BlogList.vue 文件，内容如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;template&gt; &lt;div &gt; &lt;table&gt; &lt;tr v-for="blog in blogs"&gt; &lt;!--&lt;td @click='show_blog(blog.id)'&gt;&#123;&#123;blog.title&#125;&#125;&lt;/td&gt;--&gt; &lt;td&gt; &lt;router-link :to="&#123;name: 'Blog', query: &#123;id: blog.id&#125;&#125;"&gt; &#123;&#123;blog.title&#125;&#125; &lt;/router-link&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default &#123; data () &#123; return &#123; title: '博客列表页', blogs: [] &#125; &#125;, mounted () &#123; this.$http.get('api/interface/blogs/all').then((response) =&gt; &#123; console.info(response.body) this.blogs = response.body.blogs &#125;, (response) =&gt; &#123; console.error(response) &#125;); &#125;, methods:&#123; show_blog: function(blog_id) &#123; this.$router.push(&#123;name: 'Blog', query: &#123;id: blog_id&#125;&#125;) &#125; &#125; &#125;&lt;/script&gt;&lt;style &gt; td &#123; border-bottom: 1px solid grey; &#125;&lt;/style&gt; 上面的代码可以看到。mounted 方法中发送http 请求。mounted 函数是初始化页面后，将数据渲染到界面上的。1234567mounted () &#123; this.$http.get('api/interface/blogs/all').then((response) =&gt; &#123; this.blogs = response.body.blogs &#125;, (response) =&gt; &#123; console.error(response) &#125;);&#125;, 我们启动项目，发现报这种错误。这是因为我们项目中没有引入 vue-resource 所以我们需要在项目中引入。 我们在idea 中打开控制台（alt+F12）。1npm install vue-resource 安装好之后，我们在在main.js 中引入它123import VueResource from 'vue-resource'Vue.use(VueResource)Vue.http.options.emulateJSON = true //允许使用post 请求。 在config–index.js 中设置一下代理，模拟一下跨域请求，不然接口访问不了。123456789proxyTable: &#123; '/api': &#123; // 1. 对于所有以 "/api" 开头的url 做处理． target: 'http://siwei.me', // 3. 转发到 siwei.me 上． changeOrigin: true, pathRewrite: &#123; '^/api': '' // 2. 把url中的 "/api" 去掉． &#125; &#125; &#125;, 好了，我们启动看一下，后面是获取详情的，上面没有传递参数，获取详情需要传递参数，代码如下：1234567891011121314151617181920212223242526272829303132&lt;template&gt; &lt;div &gt; &lt;div&gt; &lt;p&gt; 标题： &#123;&#123; blog.title &#125;&#125; &lt;/p&gt; &lt;p&gt; 发布于： &#123;&#123;blog.created_at &#125;&#125;&lt;/p&gt; &lt;div&gt; &lt;div v-html='blog.body'&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default &#123; data () &#123; return &#123; blog: &#123;&#125; &#125; &#125;, mounted() &#123; this.$http.get('api/interface/blogs/show?id='+this.$route.query.id).then((response) =&gt; &#123; this.blog = response.body.result &#125;, (response) =&gt; &#123; console.error(response) &#125;); &#125; &#125;&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt; 这是别人的接口，好像不支持post 请求。所以post 请求就先算了，并且这种算是原生的http 请求吧，我们以后使用的时候，可以使用 axios 来发送http 请求。这个我们后面再尝试。 番外 这篇就讲到这吧，都是一些例子。如果要看语法的话，还得看看官网的教程。 代码上传到github：https://github.com/QuellanAn/zlflovemmVue 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>vue</category>
      </categories>
      <tags>
        <tag>vue</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三、Spring Cloud之软负载均衡 Ribbon]]></title>
    <url>%2F20210810%2F%E4%B8%89%E3%80%81Spring%20Cloud%E4%B9%8B%E8%BD%AF%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%20Ribbon.html</url>
    <content type="text"><![CDATA[前言上一节我们已经学习了Eureka 注册中心，其实我们也使用到了Ribbon ,只是当时我们没有细讲，所以我们现在一起来学习一下Ribbon。 什么是Ribbon之前接触到的负载均衡都是硬负载均衡，什么是硬负载均衡呢？硬负载均衡就是在以往的大型系统中，会有单独一套系统来负责负载均衡策略，我们所以的请求都会先走到负载均衡的系统上，进行分配到不同的服务器处理。比如我们熟悉的nginx 。其实就可以算作一个负载均衡的系统，客户端请求的接口会先通过nginx 的负载均衡策略分配到不同的服务器上。那Ribbon 不是这样的吗？那又是怎样的呢？Ribbon 是和 Eureka 一样是Netflix 推出的开源产品，它可以和Eureka 完成无缝结合，Ribbon 主要实现客户端负载均衡。那什么是客户端负载均衡呢？就是在客户端请求的时候，就通过均衡策略将请求分发到不同的服务器上，如下图这个图是根据上节的Eureka 的架构图改编来的，主要的流程还是没有变，服务消费者和服务提供者都会注册到服务中心，然后服务消费者会从服务中心获取可用实例列表 ，这里就会通过负载均衡策略选择其中一个实例进行访问。 好了我们来用代码来看一下。 demo我们为了简化，注册中心服务端，我们还是用上节的单节点。怎么配置我不说了。然后我们新建一个module 用来做服务提供者，其实也可以用上一节的服务提供者，但是我怕揉在一起不好，所以就全都分开了，不过很多代码都是一样的。 服务提供者我们新建一个模块后pom.xml 文件如下：12345678910111213141516171819202122&lt;parent&gt; &lt;groupId&gt;cn.quellanan&lt;/groupId&gt; &lt;artifactId&gt;SpringCloud&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/parent&gt; &lt;groupId&gt;com.quellanan.springcloud&lt;/groupId&gt; &lt;artifactId&gt;ribbon-provider-9004&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;name&gt;ribbon-provider-9004&lt;/name&gt; &lt;description&gt;ribbon-provider-9004 服务提供者&lt;/description&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 主要就是引入了eureka-client 可以注册到注册中心去，然后启动类加上@EnableEurekaClient 注解在配置文件中加上配置如下：123server.port=9004spring.application.name=ribbon-providereureka.client.service-url.defaultZone=http://localhost:8000/eureka/ 我们在创建一个测试类：HelloController12345678910111213@RestController@Slf4jpublic class HelloController &#123; @Value("$&#123;server.port&#125;") private String port; @RequestMapping("/hello") public String hello()&#123; log.info(port); return "hello "+port; &#125;&#125; 这样我们一个服务提供者就弄好了，为了看出负载均衡的效果，我们还需要创建一个一样的服务提供者。或者不同的端口启动。我们将端口改为9005.其他的和上面一样。 服务消费者服务提供者有了，我们再来创建一个服务消费者的模块。pom.xml 较服务提供者就多了一个ribbon 的依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; 然后启动类中加上@EnableEurekaClient 和 RestTemplate123456789101112131415@SpringBootApplication@EnableEurekaClientpublic class RibbonConsumerApplication &#123; @Bean @LoadBalanced public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(RibbonConsumerApplication.class, args); &#125;&#125; @LoadBalanced 注解就是来实现客户端负载均衡的。 配置文件中加入如下配置：1234server.port=9003#服务名，在注册时所用spring.application.name=ribbon-consumereureka.client.serviceUrl.defaultZone=http://localhost:8000/eureka/ 最后我们来写一个调用服务提供者的接口，创建一个IndexController类，内容如下123456789101112@RestControllerpublic class IndexController &#123; private static final String applicationName = "ribbon-provider"; @Autowired private RestTemplate restTemplate; @RequestMapping("/index") public String getHello()&#123; String url = "http://"+ applicationName +"/hello"; return restTemplate.getForObject(url,String.class); &#125;&#125; 测试我们现在来启动服务中心，两个服务提供者，一个服务消费者。启动之后我们输入：1http://localhost:8000/ 重点看下ribbon-provider 有两个端口，分别对应的我们的两个服务提供者。他们的appliaction.name是相同的。再来调下面接口看看1http://localhost:9003/index 可以看到每次调用访问了不同的服务提供者，两个服务端提供者是轮寻调用的。从而实现客户端的负载均衡 RestTemplate上面说的负载均衡，其实还是RestTemplate 对象加上@LoadBalanced来实现的。并且前面只是简单的调用，没有涉及参数和请求方式，接下来我们看看常见的请求方式和有参数的调用。 Get 请求其实我们之前写的就是get 请求的方式，我们在来写一个有参数的请求12345@RequestMapping("index2") public String getHello2()&#123; String url = "http://"+ applicationName +"/hello2?name=&#123;1&#125;"; return restTemplate.getForObject(url,String.class,"quellanan"); &#125; 可以看到url 中请求的参数有占位符代替，getForObject或者getForEntity的第三个参数就是我们实际传的参数。这里说明一下getForObject 是直接获取返回的内容，而getForEntity返回的是一个http对象，包含相应状态码，想要回去内容需要getForEntity().getBody() 才行。 那如果多个参数的呢？多个参数的常用的有两种方式，一个是和上面一样，直接在后面加参数就好了如下：123456@RequestMapping("index3") public String getHello3()&#123; //多个参数拼接 String url = "http://"+ applicationName +"/hello3?name=&#123;1&#125;&amp;age=&#123;2&#125;"; return restTemplate.getForObject(url,String.class,"quellanan","18"); &#125; 还有一种方式就是将参数封装到map 中，传过去。一样的也可以解析123456789@RequestMapping("index4") public String getHello4()&#123; //多参数组装 Map&lt;String,String&gt; parms=new HashMap&lt;&gt;(); parms.put("name","quellanan"); parms.put("age","18"); String url = "http://"+ applicationName +"/hello3?name=&#123;name&#125;&amp;age=&#123;age&#125;"; return restTemplate.getForObject(url,String.class,parms); &#125; 我们在提供者中写两个方法便于测试12345678910@RequestMapping("/hello2") public String hello2(@RequestParam("name") String name)&#123; log.info(name); return "hello "+name+port; &#125; @RequestMapping("/hello3") public String hello3(@RequestParam("name") String name,@RequestParam("age") String age)&#123; log.info(name+age); return "hello "+name+age+port; &#125; 我们启动来看下结果可以看到参数是传递成功的啦。 Post 请求post 请求和get 请求差不多，我这里就将参数封装到map中了postForEntity123456789101112@RequestMapping("index6")public String getHello6()&#123; //postForEntity JSONObject params=new JSONObject(); params.put("name","quellanan"); params.put("age","18"); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); HttpEntity request = new HttpEntity(params.toJSONString(), headers); String url = "http://"+ applicationName +"/hello4"; return restTemplate.postForEntity(url,request,String.class).getBody();&#125; postForObject123456789101112@RequestMapping("index7") public String getHello7()&#123; //postForObject JSONObject params=new JSONObject(); params.put("name","quellanan"); params.put("age","18"); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); HttpEntity request = new HttpEntity(params.toJSONString(), headers); String url = "http://"+ applicationName +"/hello4"; return restTemplate.postForObject(url,params,String.class); &#125; 主要是先将参数封装在JSONObject 中，然后设置HttpHeaders 和HttpEntity ，然后请求。我们采用的application/json 的格式，我们在服务提供者中加一个方法。用来接收json格式的参数。1234@RequestMapping("/hello4")public String hello4(@RequestBody Map&lt;String, Object&gt; parms)&#123; return "hello "+parms.get("name")+parms.get("age")+port;&#125; 现在我们启动看下效果。证明都是可以正常传递的。 Feign 简化微服务调用上面我们可以看到，我们进行微服务调用，不管是使用get 或者post 方法，带有参数过多就会导致代码变得很臃肿，所以我们就可以使用同样是netflix 推出的Feign 来简化微服务调用，Feign 结合了Ribbon 以及Hystrix.Ribbon的功能它都有，并且还进行了封装，更加方便我们使用。所以我们使用的时候，只用引入 Feign 的依赖就可以。 那我们现在对上面的这些进行调整一下。 pom.xml在我们的ribbon-consumer 的pom 文件中删除ribbon 的依赖，增加feign 的依赖。1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; 增加@EnableFeignClients在启动类中增加@EnableFeignClients 注解在启动类中增加了@EnableFeignClients 注解，就可以在项目中使用Fegin 啦，那我们怎么使用呢？其实还要使用@FeignClient 注解，这个注解是在具体的应用中注入的，用来指定服务提供者的服务名称。并且这个注解只能作用 interface 上。前面我们调用服务提供者的接口需要写url,参数，返回类型等等非常的繁琐，所以Fegin 就帮我们进行了简化，让我们调用服务提供者的接口，可以像自身调用一样，非常放方便。 HelloService我们来创建一个HelloService 的接口。内容如下12345678910111213141516@FeignClient("ribbon-provider")public interface HelloService &#123; @RequestMapping("/hello") public String hello(); @RequestMapping("/hello2") public String hello2(@RequestParam(value = "name") String name); @RequestMapping("/hello3") public String hello3(@RequestParam(value = "name") String name,@RequestParam(value = "age") String age); @RequestMapping("/hello4") public String hello4(@RequestBody Map&lt;String, Object&gt; parms);&#125; 可以看到，上面的接口内容主要是针对服务提供者暴露出的几个接口进行调用。对比服务消费者中的接口，和服务提供者中的接口，可以发现其实是服务提供者中的接口对消费者中的HelloService 的实现。这个待会再说。从HelloService 中我们可以看到，我们调用服务提供者的接口一样的采用@RequestMapping，@RequestParam，@RequestBody来操作，这样更加简洁和方便。 FeginController我们再创建一个FeginController 来测试一下，内容如下：1234567891011121314151617181920212223242526272829303132333435@RestControllerpublic class FeginController &#123; @Autowired public HelloService helloService; @RequestMapping("/fegin") public String getHello()&#123; return helloService.hello(); &#125; @RequestMapping("/fegin2") public String getHello2()&#123; String name="quellanan"; return helloService.hello2(name); &#125; @RequestMapping("/fegin3") public String getHello3()&#123; String name="quellanan"; String age="18"; return helloService.hello3(name,age); &#125; @RequestMapping("/fegin4") public String getHello4()&#123; Map&lt;String, Object&gt; parms=new HashMap&lt;&gt;(); parms.put("name","quellanan"); parms.put("age","18"); return helloService.hello4(parms); &#125;&#125; 可以看到就是普通的controller层调用service 层。 测试好了我们现在来测试一下。分别输入如下地址来看看效果：1234http://localhost:9003/feginhttp://localhost:9003/fegin2http://localhost:9003/fegin3http://localhost:9003/fegin4 继承好了，来说最后一个问题，刚刚上面我们说了服务消费者中的HelloService 和服务提供者的HelloController很像，感觉像是HelloController 实现了HelloService 。不错，当我们正式开发的时候，会发现接口调用非常多，并且也很复杂，如果按照上面的方式来的话，会存在很多的重复代码且很容易出错，所以我们可以将服务调用单独提取成一个模块么，然后分别在服务提供者和服务消费者中引入其依赖，然后在消费中的HelloService 继承其对应的接口。而在服务提供者中实现其对应的接口。当然@FeignClient还是在服务消费者之中的。 这里只是提供了一种思路，没有给出实现方式，感兴趣的可以看看《Spring cloud 微服务实战》，也可以和我讨论下嘿嘿。 番外总算是写完了，算是对ribbon 和fegin 有了一些了解，最起码现在可以使用他们，并将其使用到到项目中没有什么问题啦。 代码上传到github： https://github.com/QuellanAn/springcloud 后续加油♡ 很荣幸，今年参加了CSDN博客之星评选活动，帮忙投下票，可以投5票 ，谢谢您 CSDN博客之星评选活动 最后啦，欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springCloud</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springCloud</tag>
        <tag>Ribbon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三、DockerFile 定制属于自己的专属镜像]]></title>
    <url>%2F20210810%2F%E4%B8%89%E3%80%81DockerFile%20%E5%AE%9A%E5%88%B6%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84%E4%B8%93%E5%B1%9E%E9%95%9C%E5%83%8F.html</url>
    <content type="text"><![CDATA[前言上篇文章我们知道了怎么操作镜像和容器，到基础都是从已经存在的镜像开始的，那我们自己怎样搭建一个镜像并使用它呢？接下来就让我们学习使用dockerfile 创建属于自己的镜像吧。 dockerfile在这之前，我们需要知道dockerfile ,因为我们就是通过dockerfile 来创建镜像的。那dockerfile 是什么呢？dockerfile 是一个文件，文件里面是我们写的一条条的指令，然后通过build ```12345命令来构建一个镜像。 现在难就难在这个指令怎么写，所以接下让我们一起看看dockfile 指令吧。 ## dockerfile 指令 ### FROM FROM FROM : #tag是可选的,默认会使用latest版本的基础镜像 1from 指令是依赖的基础镜像，所谓的定制镜像，是在其他的镜像上添加一些我们自己东西，定制成我们自己的镜像。当然我们也可以不依赖任何镜像，自己从头开始搭建。那就使用 FROM scratch 123456789 scratch 其实也是一个docker 镜像，但是这个镜像比较难特殊，它是一个虚拟镜像，里面什么都没有，是一个空白的镜像，所以如果想不依赖任何镜像，可以使用```from scratch```。 那现在又有一个问题了，dockfile 文件中可以出现多个From 么？在docker 17.05 版本之前是不支持出现多个From 的，一个dockefile只能有一个From 指令，且必须放在文件中的第一行。因为作为基础镜像使用。在docker17.05 后支持多From 。表示构建的多重阶段，不过最终生成的镜像还是以最后一个From 基础镜像为基础的。### RUNrun 指令 是表示在镜像构建时运行的指令。两种格式： #shell格式run &lt;命令&gt;eg: run apt-get update #exec 格式run [“可执行文件”，“参数1”，“参数2”…]123### COPY复制文件的指令 copy 源路径 目标路径 #支持通配符eg:copy hom?.txt /mydir/12345678### ADDadd 是更高级的复制。copy 有的功能它都用，它还能访问网络资源，源路径可以是一个URL。源路径文件也可以是一个压缩文件，可以直接解压。所以如果想要直接复制一个压缩包进去的话，就要使用COPY 而不能只用ADD了。官方建议是能使用COPY 的就使用COPY ,因为COPY 命令语义比较明确就是复制文件，并且ADD 指令会使得镜像构建缓存失效，使得镜像构建比较缓慢。### CMDcmd 指令是表示在运行容器时执行的指令。 #shell 格式cmd &lt;命令&gt;eg:cmd echo $HOME #exec 格式cmd [“可执行文件”，“参数1”，“参数2”]eg: cmd [“sh”,”-c”,”echo $HOME”]123### ENTRYPOINTentrypoint 入口点 entrypoint &lt;命令&gt; entrypoint [“可执行文件”,”参数1”,”参数2”]1234entryPoint 指令和 cmd 指令功能类似，不过entrypoint 可以让镜像变成像命令一样使用，可以做应用运行前的准备工作。这个具体的后面讲。### ENV env 是设置环境变量的指令， env MY_VERSION 1.0.0123### ARGarg 用于构建时传递的参数 arg &lt;参数名&gt;[=&lt;默认值&gt;] eg:arg versionarg myversion=1.0.0123### VOLUME定义匿名卷 volume &lt;路径&gt;volume [“&lt;路径1&gt;”，[“&lt;路径2&gt;”…] eg： volume /etc/docker/log123### EXPOSE申明端口 expose &lt;端口1&gt; [&lt;端口2&gt;…]12345678910这里需要注意的是，expose 是申明容器应用端口，但是容器运行是并不一定就是开启这个端口提供服务。在dockerfile 中写入端口申明有两个好处，一是当做镜像服务的守护端口，方便映射，二是在运行时使用随机端口映射时，就会映射的expose设置的端口上。好了，指令当然不止这些，更多的想了解的查看：https://docs.docker.com/engine/reference/builder/## 简单测试之前这篇文章写到一半放下了，因为中间docker出了一点问题，下载镜像一直提示超时，然后设置了国内加速，才弄好。上面我们了解了Dockerfile 指令，接下来就让我们先做一个简单的测试吧。我们穿件一个springboot项目。创建一个HelloController 类。 @RestControllerpublic class HelloController { @RequestMapping(“/“) public String hello(){ return “hello docke 我的简单测试 “; }}12然后打成jar 包。放到我们服务器的文件夹下。并且在文件下创建Dockerfile文件 vim Dcokerfile #文件内容FROM java:8VOLUME /tmpADD hello-1.0.0.jar hello-1.0.0.jarENTRYPOINT [“java”,”-jar”,”/hello-1.0.0.jar”]12345可以看到用到的命令都是我们上面介绍的。java8作为基础镜像，/tmp作为数据卷, add 将本地jar包添加到镜像中，entrypoint 运行我们的jar包。![file](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9ncmFwaC5iYWlkdS5jb20vcmVzb3VyY2UvMjEyMzhlNWUzODJmMWY0NzE0Nzk5MDE1NzIzMzYzNjYucG5n?x-oss-process=image/format,png)在该目录下构建镜像现在，最后面的点别忘记了。 docker build -t helle:v1 .1234567![file](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9ncmFwaC5iYWlkdS5jb20vcmVzb3VyY2UvMjEyMTJjYzQ2ZmUxZDE0YWQ3MGU2MDE1NzIzMzY2ODAucG5n?x-oss-process=image/format,png)可以看到我们的镜像分4不构建，也就是构建四个镜像，因为我们Dockerfile 中有四条指令。前面说了后一条指令是在前一条指令的基础上构建镜像的。所以这四个镜像中前面三个就是中间镜像了。我们现在看看我们创建的镜像。![file](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9ncmFwaC5iYWlkdS5jb20vcmVzb3VyY2UvMjEyZDk0NTYzNTY5Y2ZlMGRiNTUyMDE1NzIzMzY5OTcucG5n?x-oss-process=image/format,png)我们接下来启动镜像 docker run -d -p 8090:8080 hello:v1123![file](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9ncmFwaC5iYWlkdS5jb20vcmVzb3VyY2UvMjEyNWVlYmU2YjM0NTExMjRlNWYyMDE1NzIzMzczNDIucG5n?x-oss-process=image/format,png)其中 -d 是后台启动，-p 是映射端口，前面的是我们设置的端口，后面是项目运行的端口。启动后我们在浏览器上访问下。 http://192.168.252.53:8090123456![file](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9ncmFwaC5iYWlkdS5jb20vcmVzb3VyY2UvMjEyZTkyN2JlYmI4MTllMGIyMDE2MDE1NzIzMzczNzgucG5n?x-oss-process=image/format,png)这样我们通过docker 构建我们springboot 的项目，创建属于我们自己的镜像就完成了。# 配置docker远程访问我们现在要做的是，直接通过idea打包生成docker镜像。所以，第一步开启docker的远程访问，我的docker 是安装到服务器上的。我先在本地检测一下，服务器上的docker 是否开启的远程访问。 docker -H 192.168.252.53 info123![file](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9ncmFwaC5iYWlkdS5jb20vcmVzb3VyY2UvMjEyNmI5ZWE5NDUyNjEwMDEyYTU3MDE1NzIzNDA2MjMucG5n?x-oss-process=image/format,png)说明是没有开启docker的远程服务的。所以进入服务器。执行如下操作,在docker.service. 文件夹下创建一个http-proxy.conf文件. sudo mkdir /etc/systemd/system/docker.service.dsudo vim /etc/systemd/system/docker.service.d/http-proxy.conf1文件内容 [Service]ExecStart=ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock1然后重启daemon和docker sudo systemctl daemon-reloadsudo systemctl restart docker123456然后我们再 在本地测试一下。说明docker 的远程访问已经配置好了。![file](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9ncmFwaC5iYWlkdS5jb20vcmVzb3VyY2UvMjEyOTViZGRmZDAxNzI3YmE2NmFkMDE1NzIzNDExMTYucG5n?x-oss-process=image/format,png)# idea配置我们打开我们的hello 项目，在pom.xml 中增加配置 &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;docker.image.prefix&gt;quellanan&lt;/docker.image.prefix&gt;1在build 中增加。 &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;!-- 将插件绑定在某个phase执行 --&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;build-image&lt;/id&gt; &lt;!-- 用户只需执行mvn package ，就会自动执行mvn docker:build --&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!-- 指定生成的镜像名 --&gt; &lt;imageName&gt;${docker.image.prefix}/${project.artifactId}&lt;/imageName&gt; &lt;!-- 指定标签 --&gt; &lt;imageTags&gt; &lt;imageTag&gt;${project.version}&lt;/imageTag&gt; &lt;/imageTags&gt; &lt;!-- 指定 Dockerfile 路径 --&gt; &lt;dockerDirectory&gt;src/main/docker&lt;/dockerDirectory&gt; &lt;!-- 指定远程 docker api地址 --&gt; &lt;dockerHost&gt;http://192.168.252.53:2375&lt;/dockerHost&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;!-- jar包所在的路径此处配置的对应target目录 --&gt; &lt;directory&gt;${project.build.directory}&lt;/directory&gt; &lt;!-- 需要包含的jar包,这里对应的是Dockerfile中添加的文件名 --&gt; &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt; 123在src/main/docker 中创建Dockerfile 文件，文件内容上面Dockerfile 内容一样 FROM java:8VOLUME /tmpADD hello-1.0.0.jar hello-1.0.0.jarENTRYPOINT [“java”,”-jar”,”/hello-1.0.0.jar”]` mvn package因为我们配置在构建的时候就会进行docker 打包。所以我们知己运行mvn package 控制台查看是打包成功的。我们去服务器上看下，有没有可以看到已经成功了。 番外这篇总算写完啦算是，中间自己亲自试验，踩了一路坑，也算是初步弄好了。以后我们项目不用将jar 包放到服务器上再来创建镜像了，可以直接在我们项目中打包构建镜像就想构建jar 包一样简单。还是可以的吧。 好了，就说这么多啦 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七、springBoot 简单优雅是实现文件上传和下载]]></title>
    <url>%2F20210810%2F%E4%B8%83%E3%80%81springBoot%20%E7%AE%80%E5%8D%95%E4%BC%98%E9%9B%85%E6%98%AF%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E5%92%8C%E4%B8%8B%E8%BD%BD.html</url>
    <content type="text"><![CDATA[前言好久没有更新spring Boot 这个项目了。最近看了一下docker 的知识，后期打算将spring boot 和docker 结合起来。刚好最近有一个上传文件的工作呢，刚好就想起这个脚手架，将文件上传和下载整理进来。 配置在application.properties 中增加上传文件存放的路径配置12#文件上传目录file.upload.url=E:/test controller 层上传文件和下载文件都比较简单，我们就直接在controller层来编写。也不用在pom.xml 中增加什么依赖。所以直接上代码。在controller 包下创建一个file包，在file 包下创建一个FileController 类。12345678910111213141516171819202122232425262728293031@RestController@RequestMapping("file")@Slf4jpublic class FileController &#123; @Value("$&#123;file.upload.url&#125;") private String uploadFilePath; @RequestMapping("/upload") public String httpUpload(@RequestParam("files") MultipartFile files[])&#123; JSONObject object=new JSONObject(); for(int i=0;i&lt;files.length;i )&#123; String fileName = files[i].getOriginalFilename(); // 文件名 File dest = new File(uploadFilePath '/' fileName); if (!dest.getParentFile().exists()) &#123; dest.getParentFile().mkdirs(); &#125; try &#123; files[i].transferTo(dest); &#125; catch (Exception e) &#123; log.error("&#123;&#125;",e); object.put("success",2); object.put("result","程序错误，请重新上传"); return object.toString(); &#125; &#125; object.put("success",1); object.put("result","文件上传成功"); return object.toString(); &#125;&#125; 上面的代码看起来有点多，其实就是一个上传的方法，首先通过 MultipartFile 接收文件。这里我用的是file[] 数组接收文件，这是为了兼容多文件上传的情况，如果只用file 接收，然后在接口上传多个文件的话，只会接收最后一个文件。这里大家注意一下。看自己的需求，我这里兼容多文件所以用数组接收。 然后遍历files 获取文件，下面这段代码是判断文件在所在目录是否存在，如果不存在就创建对应的目录。1234File dest = new File(uploadFilePath '/' fileName); if (!dest.getParentFile().exists()) &#123; dest.getParentFile().mkdirs(); &#125; 1files[i].transferTo(dest); 就是将文件存放到对应的服务器，这里有一点需要说明一下，如果我们上传重复的文件会怎么样么？上传重复的文件不会报错，后上传的文件会直接覆盖已经上传的文件。 整体代码就是这样。现在就可以实现文件的上传操作。 测试我们写好之后，基本上传功能就已经实现了，我们现在来测试一下。启动项目后我们用postman 请求，因为我们需要上传文件，用get 方式请求不了。 可以看到文件上传成功了，由此可见，springboot文件上传一个方法就搞定了。 文件下载其实文件下载，不太建议用接口做，因为文件下载一般都是下载一些静态文件，我们可以先将文件处理好，然后通过Nginx 服务下载静态文件，这样速度会快很多。但是这里我们还是写一下。代码也很简单，就一个方法，也写在fileController 类中 1234567891011121314151617181920212223242526@RequestMapping("/download") public String fileDownLoad(HttpServletResponse response, @RequestParam("fileName") String fileName)&#123; File file = new File(downloadFilePath '/' fileName); if(!file.exists())&#123; return "下载文件不存在"; &#125; response.reset(); response.setContentType("application/octet-stream"); response.setCharacterEncoding("utf-8"); response.setContentLength((int) file.length()); response.setHeader("Content-Disposition", "attachment;filename=" fileName ); try(BufferedInputStream bis = new BufferedInputStream(new FileInputStream(file));) &#123; byte[] buff = new byte[1024]; OutputStream os = response.getOutputStream(); int i = 0; while ((i = bis.read(buff)) != -1) &#123; os.write(buff, 0, i); os.flush(); &#125; &#125; catch (IOException e) &#123; log.error("&#123;&#125;",e); return "下载失败"; &#125; return "下载成功"; &#125; 代码也很简单，就是根据文件名判断是否存在文件，不存在就提示没有文件，存在就将文件下载下来。response设置返回文件的格式，以文件流的方式返回，采用utf-8 字符集，设置下载后的文件名。然后就是以文件流的方式下载文件了。 测试的话也简单，我们启动项目，访问接口 12http://localhost:9090/zlflovemm/file/download?fileName=11http://localhost:9090/zlflovemm/file/download?fileName=1.rar 可以看到如果文件存在，会直接下载，不会提示下载成功或者失败。 删除文件 删除文件是很简单的，我这里讲一下删除文件下所有文件夹和文件。并做一个定时任务，每天清理一次。 1234567891011121314151617181920212223242526272829 @Scheduled(cron="0 0 3 * * ?")private void deleteFiles()&#123; deleteFile(new File(deleteFilePath));&#125;public void deleteFile(File file)&#123; //判断文件不为null或文件目录存在 if (file == null || !file.exists())&#123; log.info("暂无文件"); return; &#125; //取得这个目录下的所有子文件对象 File[] files = file.listFiles(); //遍历该目录下的文件对象 for (File f: files)&#123; //打印文件名 String name = f.getName(); log.info(name); //判断子目录是否存在子目录,如果是文件则删除 if (f.isDirectory())&#123; deleteFile(f); &#125;else &#123; f.delete(); &#125; &#125; //删除空文件夹 for循环已经把上一层节点的目录清空。 file.delete();&#125; 番外到此为止，我们常用的镜像和容器的操作就会使用啦。都是一些命令。忘记的可以–help 查看一下。 好了，就说这么多啦代码上传到github：https://github.com/QuellanAn/zlflovemm 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一、Vue 世界初探]]></title>
    <url>%2F20210810%2F%E4%B8%80%E3%80%81Vue%20%E4%B8%96%E7%95%8C%E5%88%9D%E6%8E%A2.html</url>
    <content type="text"><![CDATA[前言我们后端用SpringBoot 框架已经搭建的差不多了之前，既然我们最初的梦想是做先后端分离的架手架，终于也开始学习一下前端的框架了。自己也算是前端小白，所以将自己学习vue 的过程记录系列博客。希望对学习vue 的小伙伴有帮助，用时文章中有不对的，希望大家及时提出一起探讨。 至于为什么要使用vue ,虽然是一个前端小白，但是还是知道当前主流的三大框架，Angular、React以及Vue .优劣我就不说了，我就说说我为什么选择vue 吧。其实还是因为毕竟是后端开发，对前端的东西不要求深入理解，做到能用能复制就好了。所以基本上是本着最小学习成本来的。所以相对Angular 和React来说，vue 算是上手最快的，所以也就入坑了。自己话了一周的时间预研，勉强算自己入门了吧，所以才开始写博客记录下来，这样也算是对自己学习的内容的整理，也可以记录下来方便大家。 学习地址想要了解vue 是什么， 怎么学习？我也是参考网上的资料学习的。 vue.js 的官网：https://cn.vuejs.org/v2/guide/ 菜鸟教程：https://www.runoob.com/vue2/vue-tutorial.html gitBook: http://vue_book.siwei.me/preface.html 自己感觉官网上和菜鸟教程上，对自己的作用只是熟悉的了vue的语法，不足以我来搭建在项目中使用，但是又不能不看，不然基本的语法都不知道，怎么开展下一步。上面的gitBook 算是带我入门的，我也在网上找了很多资料，但是跟着gitBook一步步实现起来，整体流程算是清楚了，所以也推荐大家。自己记录这系列博客，也算自己vue入门吧，有不对的地方大家多多指教。 安装好啦，说了这么多，我们正式开始吧。我们直接使用vue-cli .当然大家亦可以使用其他的。我们首先电脑上 npm和git 并配置邮箱 ,至于怎么安装，网上有很多教程，这里就不说了，安装好之后，我们需要安装vue-cli 。1npm install vue vue-cli -g 安装好之后，我们控制台我们想要创建项目的目录执行：1vue init webpack zlflovemmVue 这样就可以看到项目已经初始化成功了。我们现在用IDEA 打开这个项目，当然大家也可以用其他的，后端的用惯了idea ,所以也就用idea 来开发vue 啦。 IDEA 配置vue我们既然使用idea,当然需要一些配置，不使用idea 的可以忽略。1、我们打开settings 下载vue.js 插件，然后重启。打开我们创建的项目zlflovemmVue 2、配置js 版本 ECMAScript6 3、HTML 增加 .vue 支持 4、启动项目，在edit Configurations 中增加npm 启动，配置如下图： 配置好后，我们来启动就好啦，如下图就表示启动成功啦。 我们启动成后，在浏览器上输入： 1http://localhost:8081 证明我们项目已经初始化搭建完成啦。到这里我们已经完成了第一步。但是可以看到我们到现在为止还没有开始写代码，也不知道如何下手写。 不要急，我们前面这些工作做好后，我们接下来就开始啦。 项目结构 虽然我们项目稀里糊涂的启动起来了，但是相比到此的小伙伴还是一头雾水，在那写我们的代码呢？整个流程是怎么样的呢？在写代码之前，我们还是先来看看，vue-cli 初始化为我们创建的项目有哪些东西。12345678▸ build/ // 编译用到的脚本▸ config/ // 各种配置▸ dist/ // 打包后的文件夹▸ node_modules/ // node第三方包▸ src/ // 源代码▸ static/ // 静态文件, 暂时无用 index.html // 最外层文件 package.json // node项目配置文件 build保留各种打包脚本。不可或缺，不要随意修改。 展开后如下：12345678910▾ build/ build.js //打包使用， 不要修改。 check-versions.js //检查npm的版本， 不要修改。 dev-client.js //是在开发时使用的服务器脚本。不要修改。 dev-server.js //同上 utils.js // 不要修改。 做一些css/sass 等文件的生成。 vue-loader.conf.js //非常重要的配置文件，不要修改。内容是用来辅助加载vuejs用到的css source map等内容。 webpack.base.conf.js //下面这三个都是基本的配置文件。不要修改 webpack.dev.conf.js webpack.prod.conf.js 我们初学者阶段，暂时不用管这些，也不改这些东西。 config上图我们可以看到config 目录中就有12345▾ config/ dev.env.js index.js prod.env.js test.env.js dev.env.js 开发模式下的配置文件，一般不用修改。prod.env.js 生产模式下的配置文件，一般不用修改。test.env.js 测试模式下的配置文件，一般不用修改。index.js 很重要的文件， 定义了 开发时的端口（默认是8080），定义了图片文件夹（默认static)， 定义了开发模式下的 代理服务器. 我们修改的还是比较多的。 node_modulesnode项目所用到的第三方包，特别多，特别大。 $ npm install 所产生。这个文件夹不要放到git中 src最最核心的源代码所在的目录。我们要写的代码就是写在这个里面啦。123456789▾ src/ ▾ assets/ logo.png ▾ components/ Hello.vue ▾ router/ index.js App.vue main.js assets: 用到的图片 components: 用到的”视图”和”组件”所在的文件夹。（最最核心） router/index.js 路由文件。 定义了各个页面对应的url. App.vue 如果index.html 是一级页面模板的话，这个App.vue就是二级页面模板。 所有的其他vuejs页面，都作为该模板的 一部分被渲染出来。 main.js 废代码。没有实际意义，但是为了支撑整个vuejs框架，存在很必要。 Hello World好啦，我们已经知道了项目的结构了，现在就要开始实现我们自己的hello world 啦。不然我们当程序员还有什么意义。其实我们程序已经帮我们写了一个helloworld 。但是我们还是自己来创建一个，这样自己才能熟悉点。最终添加的内容图如下： Hello.vue我们在src–components 新建Hello.vue 。内容如下:123456789101112131415&lt;template&gt; &lt;div&gt; &#123;&#123;message&#125;&#125; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default &#123; data()&#123; return &#123; message: "hello world" &#125; &#125; &#125;&lt;/style&gt; 可以看到内容很简单，就是返回一个hello world 。 修改index.js接下来我们在src–router–index.js 中增加一个路由。 启动这样的话我们就可以来启动项目啦。启动的时候报这种错误：1✘ http://eslint.org/docs/rules/indent 启用eslint检测不通过导致的，我们这里的解决办法： 在build/webpack.base.conf.js文件中，注释config.dev.useEslint?这行配置，然后重启项目就好了。 启动之后，我们在界面上输入： 1http://localhost:8081/#/hello 这里我们的hello world 出来了，但是我们可能会感觉到奇怪，我们只是仅仅写了helloworld 为什么还有logo ,并且还有居中的样式。我们这个问题留在下篇文章接着将。这里我们先记着。 番外 到此为止，我们也算是将vue安装成功了，并运行一个非常简单的例子。 代码上传到github：https://github.com/QuellanAn/zlflovemmVue 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>vue</category>
      </categories>
      <tags>
        <tag>vue</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《剑指offer》之顺时针打印矩阵]]></title>
    <url>%2F20210810%2F%E3%80%8A%E5%89%91%E6%8C%87offer%E3%80%8B%E4%B9%8B%E9%A1%BA%E6%97%B6%E9%92%88%E6%89%93%E5%8D%B0%E7%9F%A9%E9%98%B5.html</url>
    <content type="text"><![CDATA[前言今天做一道关于矩阵的题目。思路很简单，就是要考虑全面。 题目输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字，例如，如果输入如下4 X 4矩阵： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 则依次打印出数字1,2,3,4,8,12,16,15,14,13,9,5,6,7,11,10. 分析就是顺时针打印，不能重复打印元素。注意四个变量，上下左右。 解法我们先直接思路解题，代码不是很简洁，但是思路算是比较清晰，先判断数组是否为空。12345678910111213141516171819202122232425262728293031323334353637383940414243444546public ArrayList&lt;Integer&gt; printMatrix(int [][] matrix) &#123; if(matrix==null)&#123; return null; &#125; ArrayList&lt;Integer&gt; list=new ArrayList&lt;&gt;(); //设置四个边界值。 int n=matrix.length; int m=matrix[0].length; int x=0; int y=0; while(n&gt;x &amp;&amp; m&gt;y)&#123; int i=x; int j=y; //最外层从左往右输出 while(j&lt;m)&#123; list.add(matrix[i][j]); j++; &#125; j--; i++; //最外层从上往下输出 while(i&lt;n)&#123; list.add(matrix[i][j]); i++; &#125; i--; j--; //最外层从右往左输出，注意排除和前面的从左往右重复 while(j&gt;=y&amp;&amp;n!=x+1)&#123; list.add(matrix[i][j]); j--; &#125; j++; i--; //最外层从下往上输出，注意排除和前面的从上往下重复 while(i&gt;x &amp;&amp;m!=y+1)&#123; list.add(matrix[i][j]); i--; &#125; n--; m--; x++; y++; &#125; return list; &#125; 测试main 方法12345678910111213141516public static void main(String[] args) &#123; int [][]matrix=&#123;&#123;1,2,3,4,5&#125;,&#123;6,7,8,9,10&#125;,&#123;11,12,13,14,15&#125;&#125;; //int [][]matrix=&#123;&#123;1,2,3,4&#125;,&#123;5,6,7,8&#125;,&#123;9,10,11,12&#125;,&#123;13,14,15,16&#125;,&#123;17,18,19,20&#125;&#125;; for(int i=0;i&lt;matrix.length;i++)&#123; for (int j=0;j&lt;matrix[0].length;j++)&#123; System.out.print(matrix[i][j]+"\t"); &#125; System.out.println(); &#125; Solution solution=new Solution(); ArrayList&lt;Integer&gt; list=solution.printMatrix(matrix); for(int i=0;i&lt;list.size();i++)&#123; System.out.print(list.get(i)+"\t"); &#125; &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>《剑指offer》</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《剑指offer》之栈的压入、弹出序列]]></title>
    <url>%2F20210810%2F%E3%80%8A%E5%89%91%E6%8C%87offer%E3%80%8B%E4%B9%8B%E6%A0%88%E7%9A%84%E5%8E%8B%E5%85%A5%E3%80%81%E5%BC%B9%E5%87%BA%E5%BA%8F%E5%88%97.html</url>
    <content type="text"><![CDATA[前言我们关于栈的题目，这两天做的还是挺多的，无非就是压栈出栈。 题目输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否可能为该栈的弹出顺序。假设压入栈的所有数字均不相等。例如序列1,2,3,4,5是某栈的压入顺序，序列4,5,3,2,1是该压栈序列对应的一个弹出序列，但4,3,5,1,2就不可能是该压栈序列的弹出序列。（注意：这两个序列的长度是相等的） 分析输入两个数组，第一个是入栈的顺序，第二个是出栈的顺序，判断第二个数组出栈的顺序是否正确。比如入栈：1，2，3，4，5那出栈：5，4，3，2，1 可以4，5，3，2，1也可以。4，5，3，1，2就不行。所以我们遍历第二个数组，找到在第一个数组找中的位置，这样在这之前的都先入栈，然后出栈。最后栈内容为空则表示，出栈的顺序是可以的，否则就不行。具体例子说明，比较清楚。比如list1：{1,2,3,4,5}list2：｛4，5，3，2，1｝先遍历数组list2第一个为4，找到在list1 中的位置为3记录下来，将前面的数字都入栈。这时栈中的数据为1-&gt;2-&gt;3-&gt;4然后出栈4，此时栈的数据为1-&gt;2-&gt;3。第二个为5，找到在list1 中为4大于3 ，位置为4记录下来，所以将list1 中的3+1 到4的数据压入栈中，即将5压入栈，此时栈的数据为：1-&gt;2-&gt;3-&gt;5然后出栈5，此时栈的数据为1-&gt;2-&gt;3第三个为3，此时在list1 中的位置为2小于4，等于3，直接出栈。此时栈的数据为1-&gt;2第四个为2，此时在list1 中的位置为1小于4，等于2，直接出栈。此时栈的数据为1第四个为1，此时在list1 中的位置为0小于4，等于1，直接出栈。此时栈的数据为空所以说明list2 是一种出栈方式。 解法123456789101112131415161718192021222324252627282930313233public boolean IsPopOrder(int [] pushA,int [] popA) &#123; Stack&lt;Integer&gt; stack=new Stack&lt;&gt;(); if(pushA==null||popA==null||popA.length==0||pushA.length==0)&#123; return false; &#125; int temp=-1; for(int i=0;i&lt;popA.length;i++)&#123; int j=0; //找到i 在list1 中的位置。 while(j&lt;popA.length &amp;&amp;pushA[j]!=popA[i])&#123; j++; &#125; //如果找不到，则返回false if(j==popA.length)&#123; return false; &#125; while(temp&lt;j)&#123; temp++; stack.push(pushA[temp]); &#125; //如果相等，则出栈 if(stack.peek()==popA[i])&#123; stack.pop(); &#125; &#125; //如果为空，为真 if(stack.isEmpty())&#123; return true; &#125; return false; &#125; 测试main 方法1234567public static void main(String[] args) &#123; int [] pushA=&#123;1,2,3,4,5&#125;; int [] popA=&#123;4,5,3,2,1&#125;; Solution solution=new Solution(); boolean b=solution.IsPopOrder(pushA,popA); System.out.println(b); &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>《剑指offer》</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《剑指offer》之斐波那契数列系列]]></title>
    <url>%2F20210810%2F%E3%80%8A%E5%89%91%E6%8C%87offer%E3%80%8B%E4%B9%8B%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97%E7%B3%BB%E5%88%97.html</url>
    <content type="text"><![CDATA[前言斐波那契数列 算是比较常见的算法题了。f(1)=1;f(2)=1;f(3)=2;…f(n)=f(n-1)+f(n-2);一般采用递归的思想。今天做了几个关于斐波那契数列，都记录下来。 题目一大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项（从0开始，第0项为0）。n&lt;=39 这个是最原始的，就是上面我说的斐波那契数列。代码实现如下：12345678public int Fibonacci(int n) &#123; if(n&lt;0)&#123; return 0; &#125;else if(n==1 || n==2)&#123; return 1; &#125; return Fibonacci(n-1)+Fibonacci(n-2); &#125; 可以看到非常简单，但是递归算法虽然方便，但是耗时比较长，我们也可以用循环实现。1234567891011121314151617public int Fibonacci(int n) &#123; if(n&lt;0)&#123; return 0; &#125;else if(n==1 || n==2)&#123; return 1; &#125; int a=1; int b=1; int c=0; for(int i=3;i&lt;=n;i++)&#123; c=a+b; a=b; b=c; &#125; return c; &#125; 用循环实现的话，减少了时间损耗，增加了空间成本。所以具体情况具体分析还得。 题目二一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法（先后次序不同算不同的结果）。 这是一道斐波那契数列，我们读题可以发现。只有一个台阶，一种跳法。f(1)=1;只要两个台阶，两种跳法。f(2)=2； 只要三个台阶，从第一个台阶跳2步上来，或者从第二个台阶跳一步上来。f(3)=f(1)+f(2) n 个台阶，从n-1台阶跳一步上来，或者从n-2 台阶跳2步上来。f(n)=f(n-1)+f(n-2);所以这就是一道典型的斐波那契数列。代码和上面一样。 题目三一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 在上面的基础上，可以跳n个台阶。f(n)=f(n-1)+f(n-2)+f(n-3)+……+f(3)+f(2)+f(1);f(n-1)=f(n-2)+f(n-3)+……+f(3)+f(2)+f(1); 所以上试减下试。f(n)-f(n-1)=f(n-1)+f(n-2)+f(n-3)+……+f(3)+f(2)+f(1)-[f(n-2)+f(n-3)+……+f(3)+f(2)+f(1)]; 所以： f(n)-f(n-1)=f(n-1)； f(n)=2f(n-1);n&gt;1所以代码为：12345public int JumpFloorII(int target) &#123; if(target&lt;1) return 0; else if (target==1) return 1; else return 2*JumpFloorII(target-1); &#125; 题目四我们可以用21的小矩形横着或者竖着去覆盖更大的矩形。请问用n个21的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？ 这道题目相对前面几道，比较难理解是斐波那契数列。我们来分析一下。当n=1 时，只有一种情况。f(1)=1;当n=2时，2个21的小矩形，拼成22的大矩形。有2种方法。f(2)=2;当n=3时，3个21的小矩形，拼成23的大矩形。这个时候我们就要想下，23的矩形是一个21 和一个22的矩形组成的。当n=5时，5个21的小矩形，拼成25的大矩形。这个时候我们就要想下，25的矩形是一个24的矩形加一个21的矩形组成，或者一个23的矩形加一个22 的矩形组成。 所以可以推测出还是一个斐波那契数列。f(n)=f(n-1)+f(n-2); 代码和最开始一样，就不重复啦。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>《剑指offer》</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《剑指offer》之扑克牌顺子]]></title>
    <url>%2F20210810%2F%E3%80%8A%E5%89%91%E6%8C%87offer%E3%80%8B%E4%B9%8B%E6%89%91%E5%85%8B%E7%89%8C%E9%A1%BA%E5%AD%90.html</url>
    <content type="text"><![CDATA[前言接着来刷一道简单的算法题 题目LL今天心情特别好,因为他去买了一副扑克牌,发现里面居然有2个大王,2个小王(一副牌原本是54张^_^)…他随机从中抽出了5张牌,想测测自己的手气,看看能不能抽到顺子,如果抽到的话,他决定去买体育彩票,嘿嘿！！“红心A,黑桃3,小王,大王,方片5”,“Oh My God!”不是顺子…..LL不高兴了,他想了想,决定大\小 王可以看成任何数字,并且A看作1,J为11,Q为12,K为13。上面的5张牌就可以变成“1,2,3,4,5”(大小王分别看作2和4),“So Lucky!”。LL决定去买体育彩票啦。 现在,要求你使用这幅牌模拟上面的过程,然后告诉我们LL的运气如何， 如果牌能组成顺子就输出true，否则就输出false。为了方便起见,你可以认为大小王是0。 分析就是一个数组，0表示大小王，可以当癞子，其他的最小是1，最大是13，求给出的这个数组能否组成顺子。 我们仔细想想一个正常的顺子，比如6，7，8，9，10.那最大值和最小值差为4，并且不能重复。所以我们应该得出两个结论。1，最大值和最小值相差小于等于4，为什么会小于4呢，因为有癞子0导致的。2.除了癞子0以外，其他的数字不能重复。 所以根据上面的条件我们就可以写出算法了。求出最小值，最大值。 重复数字怎么判断呢？先判断是否为0，不为0，将这个数字作为脚标存到另一个数组中，并计数加1，从而判断是否重复。 解法12345678910111213141516171819202122232425public boolean isContinuous(int [] numbers) &#123; int count[]=new int[14]; if(numbers==null|| numbers.length&lt;1)&#123; return false; &#125; int min=14; int max=0; for(int i=0;i&lt;numbers.length;i++)&#123; if(numbers[i]==0)&#123; continue; &#125;else if(count[numbers[i]]&gt;0) &#123; //如果存在重复的数字就返回false; return false; &#125;else if(numbers[i]&lt;min)&#123; min=numbers[i]; &#125;else if(numbers[i]&gt;max)&#123; max=numbers[i]; &#125; count[numbers[i]]++; &#125; if(max-min&lt;5)&#123; return true; &#125; return false; &#125; 测试main方法12345public static void main(String[] args) &#123; Solution solution=new Solution(); int array[]=&#123;1,5,3,3,4,&#125;; System.out.println(solution.isContinuous(array)); &#125; 番外测试的时候发现牛客上的这道题测试用例不全。比如我最开始这样写的12345678910111213for(int i=0;i&lt;numbers.length;i++)&#123; if(numbers[i]==0)&#123; continue; &#125;else if(numbers[i]==min||numbers[i]== max) &#123; //如果存在重复的数字就返回false; return false; &#125;else if(numbers[i]&lt;min)&#123; min=numbers[i]; &#125;else if(numbers[i]&gt;max)&#123; max=numbers[i]; &#125; count[numbers[i]]++; &#125; 可以看到我通过1(numbers[i]==min||numbers[i]== max 来判断是否存在重复的数字，其实这是不正确的，比如我是上面的测试用例1,5,3,3,4就不满足上面的要求。可以看到返回的是true,实际应该是false才对，算法不正确的，但是提交到牛客上竟然通过了，有点无语，也不敢问哈哈]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>《剑指offer》</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《剑指offer》之和为S的连续正数序列]]></title>
    <url>%2F20210810%2F%E3%80%8A%E5%89%91%E6%8C%87offer%E3%80%8B%E4%B9%8B%E5%92%8C%E4%B8%BAS%E7%9A%84%E8%BF%9E%E7%BB%AD%E6%AD%A3%E6%95%B0%E5%BA%8F%E5%88%97.html</url>
    <content type="text"><![CDATA[前言今天刷的一道题目是是关于穷举的。 题目小明很喜欢数学,有一天他在做数学作业时,要求计算出9~16的和,他马上就写出了正确答案是100。但是他并不满足于此,他在想究竟有多少种连续的正数序列的和为100(至少包括两个数)。没多久,他就得到另一组连续正数和为100的序列:18,19,20,21,22。现在把问题交给你,你能不能也很快的找出所有和为S的连续正数序列? Good Luck! 输出描述: 输出所有和为S的连续正数序列。序列内按照从小至大的顺序，序列间按照开始数字从小到大的顺序 分析这里参考了答案区的思路，这个思路算是很厉害的，窗口的双指针的思路。窗口的左右两边就是两个指针，我们根据窗口内值之和来确定窗口的位置和宽度。以sum=15为例吧，初始left=1;right=2;和add=1+2=3;add&lt;sum，所以right++;所以add=1+2+3=6;还是add&lt;sum,right++到right=5时，add=1+2+3+4+5=15;刚好等于15，所以这一组是我们求的。我们继续left++,所以此时left=2,right=5;此时add=2+3+4+5=14;add&lt;sum；所以right++;此时right=6,add=2+3+4+5+6=20;add&gt;sum，所以left++,此时left=3,add=3+4+5+6=18;add&gt;sum，所以left++,此时left=4,add=4+5+6=15;add=sum ，将这组记录下来，继续left++;此时left=5,rigt=6;add=5+6=11;add&lt;sum；所以right++;此时right=7,add=5+6+7=21;add&gt;sum，所以left++,此时left=6,rigt=7;add=6+7=14;add&lt;sum；所以right++;此时left=6,rigt=8;add=6+7+8=21;add&gt;sum，所以left++,此时left=7,rigt=8;add=7+8=21;add=sum ，将这组记录下来，继续left++;此时left=8,rigt=8;left&gt;=right，循环结束退出，这时我们就可以得到三组满足条件的序列啦。 通过上面的例子，思路算是非常清楚了，主要是左右两个指针，当left&lt;right 就执行循环体。循环体做的事情就是，先求left加到right 的和。1add=(left+right)*(right-left+1)/2; 这个求和很好算吧，等差数列就和12345add=(a1+an)*n/2a1=left;an=right;n=right-left+1;代替上去就可以了。 然后就比较add 与sum 的大小，如果add&lt; sum ，则右指针right右移一位，如果add&gt;sum，则左指针右移一位，如果add=sum,就表明该组是我们想要的，记录下来，同时l左指针右移一位,继续查找其他。当left&gt;=right的时候就退出循环体。 解法123456789101112131415161718192021public ArrayList&lt;ArrayList&lt;Integer&gt;&gt; FindContinuousSequence(int sum) &#123; ArrayList&lt;ArrayList&lt;Integer&gt; &gt; lists = new ArrayList&lt;&gt; (); int left=1; int right=2; while(left&lt;right)&#123; int add=(left+right)*(right-left+1)/2; if(add==sum)&#123; ArrayList&lt;Integer&gt; list=new ArrayList&lt;&gt;(); for(int i=left;i&lt;=right;i++)&#123; list.add(i); &#125; lists.add(list); left++; &#125;else if(add&lt;sum)&#123; right++; &#125;else &#123; left++; &#125; &#125; return lists; &#125; 测试main 方法12345678910public static void main(String[] args) &#123; Solution solution= new Solution(); ArrayList&lt;ArrayList&lt;Integer&gt;&gt; lists=solution.FindContinuousSequence(15); for(ArrayList&lt;Integer&gt; list:lists)&#123; for(Integer tmp:list)&#123; System.out.print(tmp+"\t"); &#125; System.out.println(); &#125; &#125; 再测一个100的]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>《剑指offer》</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《剑指offer》之和为S的两个数字]]></title>
    <url>%2F20210810%2F%E3%80%8A%E5%89%91%E6%8C%87offer%E3%80%8B%E4%B9%8B%E5%92%8C%E4%B8%BAS%E7%9A%84%E4%B8%A4%E4%B8%AA%E6%95%B0%E5%AD%97.html</url>
    <content type="text"><![CDATA[前言昨天刷的和为S的连续正数序列，用到的窗口双指针的方法很好用，今天刚好刷到一道类似的，也是用窗口双指针的，一次就过的感觉还不错。 题目输入一个递增排序的数组和一个数字S，在数组中查找两个数，使得他们的和正好是S，如果有多对数字的和等于S，输出两个数的乘积最小的。 输出描述: 对应每个测试案例，输出两个数，小的先输出。 分析输出两个数的乘积最小的。这句话的理解？假设：若b&gt;a,且存在，a + b = s;(a - m ) + (b + m) = s则：(a - m )(b + m)=ab - (b-a)m - m*m &lt; ab；说明外层的乘积更小也就是说依然是左右夹逼法！！！ 上面这些是用来说明还是窗口双指针的方法，left=0;right=array.length-1;左右夹逼，两个的和大于sum,right–,小于sum,left++，等于sum,退出 解法1234567891011121314151617181920212223public ArrayList&lt;Integer&gt; FindNumbersWithSum(int [] array, int sum) &#123; ArrayList&lt;Integer&gt; list=new ArrayList&lt;&gt;(); if(array==null||array.length==0||sum&lt;=0)&#123; return list; &#125; int left=0; int right=array.length-1; while(left&lt;right)&#123; int add=array[left]+array[right]; if(add==sum)&#123; list.add(array[left]); list.add(array[right]); break; &#125;else if(add&lt;sum)&#123; left++; &#125;else&#123; right--; &#125; &#125; return list; &#125; 测试main 方法12345678public static void main(String[] args) &#123; int [] array=&#123;1,2,3,4,5,6,7,8,9,10&#125;; Solution solution= new Solution(); ArrayList&lt;Integer&gt; list=solution.FindNumbersWithSum(array,9); for(Integer tmp:list)&#123; System.out.print(tmp+"\t"); &#125; &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>《剑指offer》</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《剑指offer》之从上往下打印二叉树]]></title>
    <url>%2F20210810%2F%E3%80%8A%E5%89%91%E6%8C%87offer%E3%80%8B%E4%B9%8B%E4%BB%8E%E4%B8%8A%E5%BE%80%E4%B8%8B%E6%89%93%E5%8D%B0%E4%BA%8C%E5%8F%89%E6%A0%91.html</url>
    <content type="text"><![CDATA[前言从上往下打印二叉树，这里会用到队列，所以先将一下Java队列。 队列创建队列1Queue&lt;String&gt; queue = new LinkedList&lt;String&gt;(); 添加元素1queue.offer("a"); 出队列12345678//返回第一个元素，并在队列中删除queue.poll()//返回队列头部的元素,如果队列为空，则抛出一个NoSuchElementException异常queue.element()//返回队列头部的元素, 如果队列为空，则返回nullqueue.peek() 主要可能就用到这几个方法啦。下面来看题目 题目从上往下打印出二叉树的每个节点，同层节点从左至右打印。 分析打印一颗二叉树，如果直接遍历打印的话，回先打印根节点-&gt;左节点-&gt;右节点。想要按层次打印，可以依照队列来实现，从根节点依次将节点加入队列中，然后从队列中取出来达到层次打印的目的。 解法1234567891011121314151617ArrayList&lt;Integer&gt; list=new ArrayList&lt;&gt;(); if(root==null)&#123; return list; &#125; Queue&lt;TreeNode&gt; queue=new LinkedList&lt;&gt;(); queue.offer(root); while (!queue.isEmpty())&#123; TreeNode temp=queue.poll(); list.add(temp.val); if(temp.left!=null)&#123; queue.offer(temp.left); &#125; if(temp.right!=null)&#123; queue.offer(temp.right); &#125; &#125; return list; 测试main 方法1234567891011121314public static void main(String[] args) &#123; TreeNode root =new TreeNode(1); root.left=new TreeNode(2); root.right=new TreeNode(3); root.left.left=new TreeNode(4); root.right.left=new TreeNode(5); root.left.left.left=new TreeNode(6); TreeOperation.show(root); Solution solution= new Solution(); ArrayList&lt;Integer&gt; list=solution.PrintFromTopToBottom(root); for(int i=0;i&lt;list.size();i++)&#123; System.out.print(list.get(i)+"\t"); &#125; &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>《剑指offer》</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《剑指offer》之反转链表]]></title>
    <url>%2F20210810%2F%E3%80%8A%E5%89%91%E6%8C%87offer%E3%80%8B%E4%B9%8B%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8.html</url>
    <content type="text"><![CDATA[前言今天又刷了一道关于链表的，本来打算接着前面一篇关于链表的写，但是想想还是再起一篇。 题目输入一个链表，反转链表后，输出新链表的表头。 分析最开始我以为输出表头的值，直接找到链表结尾的元素输出就好了，后来发现是输出表头。这就要从新思考了。需要反转链表，比如我们现在的链表为1-&gt;3-&gt;5-&gt;8 我们要反转成8-&gt;5-&gt;3-&gt;1 也就是说之前1的下一个节点是3，要锋、改成下一个节点是null3的下一个节点是5，改成下一个节点是1. 这里我们遍历链表，listNode.next的节点先保存起来，然后将listNode.next的指向改成pre. 解法12345678910111213141516public ListNode ReverseList(ListNode head) &#123; if(head==null)&#123; return null; &#125; ListNode listNode=head; ListNode pre=null; while(listNode!=null)&#123; ListNode next=listNode.next; listNode.next=pre; pre=listNode; listNode=next; &#125; return pre; &#125; 可以看到代码很简短，就是遍历listNode。将listNode.next 先保存到next 中，因为接着遍历会用到。1ListNode next=listNode.next; 然后listNode.next。然后将当前节点保存到pre 中，用于下个节点的前节点。最后将 next赋给listNode，用于执行下个节点。 源代码12345678910111213141516171819202122232425262728public ListNode ReverseList(ListNode head) &#123; if(head==null)&#123; return null; &#125; ListNode listNode=head; ListNode pre=null; while(listNode!=null)&#123; ListNode next=listNode.next; listNode.next=pre; pre=listNode; listNode=next; &#125; return pre; &#125; public static void main(String[] args) &#123; ListNode listNode=new ListNode(1); listNode.next=new ListNode(3); listNode.next.next=new ListNode(5); listNode.next.next.next=new ListNode(8); Solution solution=new Solution(); ListNode dd=solution.ReverseList(listNode); System.out.println(dd.val); &#125; 测试 合并两个排序的链表输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。 分析把两个有序的链表整合成一个有序的列表。思路其实也很简单。比如我们两个链表为：list1:1-&gt;3-&gt;5-&gt;8list2: 2-&gt;4-&gt;6-&gt;7先比较1和21小于2，则list1.next在比较3和23大于2，则list2.next直到整个链表都是有序的。 解法1使用递归，我们返回的是是一个有序的链表12345678910111213141516public ListNode Merge(ListNode list1, ListNode list2) &#123; if(list1==null)&#123; return list2; &#125;else if(list2==null)&#123; return list1; &#125; if(list1.val&lt;list2.val)&#123; list1.next=Merge(list1.next,list2); return list1; &#125;else &#123; list2.next=Merge(list1,list2.next); return list2; &#125; &#125; 解法2使用循环12345678910111213141516171819202122232425262728public ListNode Merge2(ListNode list1, ListNode list2) &#123; if(list1==null)&#123; return list2; &#125;else if(list2==null)&#123; return list1; &#125; ListNode head=new ListNode(-1); ListNode root=head; while(list1!=null&amp;&amp;list2!=null)&#123; if(list1.val&lt;list2.val)&#123; head.next=list1; head=list1; list1=list1.next; &#125;else&#123; head.next=list2; head=list2; list2=list2.next; &#125; &#125; if(list1!=null)&#123; head.next=list1; &#125; if(list2!=null)&#123; head.next=list2; &#125; return root.next; &#125; 主方法123456789101112131415public static void main(String[] args) &#123; ListNode list1=new ListNode(1); list1.next=new ListNode(3); list1.next.next=new ListNode(5); list1.next.next.next=new ListNode(8); ListNode list2=new ListNode(2); list2.next=new ListNode(4); list2.next.next=new ListNode(6); list2.next.next.next=new ListNode(7); Solution solution=new Solution(); ListNode dd=solution.Merge2(list1,list2); System.out.println(dd.val); &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>《剑指offer》</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《剑指offer》之二叉树的深度]]></title>
    <url>%2F20210810%2F%E3%80%8A%E5%89%91%E6%8C%87offer%E3%80%8B%E4%B9%8B%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%B7%B1%E5%BA%A6.html</url>
    <content type="text"><![CDATA[前言我们今天接着来看一道关于二叉树的算法题，关于二叉树的深度。 题目输入一棵二叉树，求该树的深度。从根结点到叶结点依次经过的结点（含根、叶结点）形成树的一条路径，最长路径的长度为树的深度。 分析求该树的深度，主要就是看最长路径。比如下图的深度为5，最长的路径为34，99，35，64，77那应该怎么做了？这里用递归，如果当前节点没有左右节点，就返回当前节点，如果有左右节点，就返回左右节点的，比较左节点和右节点的深度，谁的深度大就返回那个。这样就可以获得树的最大深度啦。 解法12345678910111213public int TreeDepth(TreeNode root) &#123; if(root==null)&#123; return 0; &#125; int left=TreeDepth(root.left); int right=TreeDepth(root.right); if(left&gt;right)&#123; return left+1; &#125; return right+1; &#125; 上面主要注意的是left+1 和right+1;为什么要加一呢，因为我们递归的出口是当前节点为null ,返回0，为1个节点的话返回1. 测试测试main方法12345678910111213public static void main(String[] args) &#123; TreeNode root =new TreeNode(34); root.left=new TreeNode(23); root.right=new TreeNode(99); root.left.left=new TreeNode(1); root.left.right=new TreeNode(27); root.right.left=new TreeNode(35); root.right.left.right=new TreeNode(64); root.right.left.right.right=new TreeNode(77); TreeOperation.show(root); Solution solution= new Solution(); System.out.println(solution.TreeDepth(root)); &#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>《剑指offer》</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centOS7 安装nginx]]></title>
    <url>%2F20210810%2FcentOS7%20%E5%AE%89%E8%A3%85nginx.html</url>
    <content type="text"><![CDATA[前言在家呆的时间很长，没有linux 服务器，所以就在腾讯云上买了一个云服务器折腾一下，重置秘密重装系统和用远程连接什么的就不讲了，都比较简单，在控制台上都可以操作。我安装后，想搭建一个nginx试试。 自己也是采坑一路，虽然以前也在Ubuntu上安装nginx 的，但是还是和centOS 上有些不一样的。 如果是在腾讯云上买的服务器，其实可以一步到位1yum install nginx 但是我是下载的nginx 安装包，上传到服务器，安装的。 下载1https://nginx.org/download/ 想要各个什么版本，自己选，我这里选的是1.16.2 上传&amp;解压因为服务器上什么都没有，要上传安装包的，需要先安装lrzsz.我这里有rz 明了上传的。1yum install lrzsz 安装好之后，就将安装包解压1tar -zxvf nginx-1.6.2.tar.gz 解压后如下 安装刚开始我直接运行123cd nginx-1.6.2./configure make &amp;&amp; make install 会报错，就是安装不成功，提示没有什么包，最后想到 nginx 是c语言编写的，需要编译的话，可能是没有c语言环境，所以需要安装环境1yum install -y gcc gcc-c++ 最后才安装成功。 操作安装成功后，怎么启动呢，安装到什么位置了呢？默认安装到了这个目录下，我们可以来到这个目录下找到他们。1/usr/local/nginx 可以看到主要就 conf 、logs、sbin 这三个目录啦。conf中的nginx.conf 就是我们主要配置的配置文件，这个我们稍候说，logs 就是nginx 的日志，对我们查看接口请求情况很有帮助。sbin 就是nginx 的命令目录，可以看到就一个nginx 的命令。 启动那我们怎么启动nginx 呢？1sudo /usr/local/nginx/sbin/nginx 检查配置文件是否正确12cd /usr/local/nginx/sbin/./nginx -t 如上表示成功。 重启1./nginx -s reload 停止1./nginx -s stop 当然我们可以通过查看进程号，来杀死进程。查看nginx 的进程1ps -ef|grep nginx 权限问题在nginx 已经搭建好之后，我网上找了一个静态html 文件试了一下，结果配置好路劲后发现，一直访问不了，界面上报403f.。看了一下nginx 日志发现如下错误1/root/love5/index.html" failed (13: Permission denied), client: xx.xx.xx.xx, server: localhost, request: "GET /index/index.html HTTP/1.1", host: "xx.xx.xx.xx:8080" 造成这个原因是因为我们运行nginx 的时候权限不是root 权限，所以需要在nginx.conf 做如下修改1user root; 最后总算是通啦，在本地浏览器上成功的显示了静态文件。网上找的资源么，但是女朋友不知道，把做好的这个给女朋友看，女朋友以为是我自己做的送给她的，着实开心了一下哈哈。 番外安装nginx 不是终极目的，还是想把项目放到服务器上跑的，由于自己学的都是Java，所以就在服务器上安装jdk ，但是自带的都是openjdk ，而我们本地的用的都是Oracle jdk.所以想安装oracle jdk 。但是官网上不知道怎么回事，一直下载不下。官网：https://www.oracle.com/java/technologies/javase-jdk8-downloads.html提示我需要勾选许可，但是没有地方勾选，把我气得不轻，没办法我就安装的open jdk。然后在本地打包一个测试spring boot jar 包，看在服务器上能否运行。发现是可以运行的。看来在服务器上安装open jdk 也是可以的。]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka也没那么难--kafka的安装与简单使用]]></title>
    <url>%2F20210810%2Fkafka%E4%B9%9F%E6%B2%A1%E9%82%A3%E4%B9%88%E9%9A%BE--kafka%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8.html</url>
    <content type="text"><![CDATA[前言前短时间在腾讯云上买了一个linux 服务器，决心把kafka这一模快的知识补充起来啦。所以就搞起来。 安装安装算是比较简单的，可以直接用wget 下载，也可以将安装包下载下来，上传到服务器上，都是一样的。kafka 安装包网址：1http://mirror.bit.edu.cn/apache/kafka 我选择的版本2.4.0：1wget http://mirror.bit.edu.cn/apache/kafka/2.4.0/kafka_2.13-2.4.0.tgz 下载zookeeper ,这个暂时不用也可以，kafka 中自带了zookeeper，暂时学习也可以直接用。zookeeper 安装包网址：1http://mirror.bit.edu.cn/apache/zookeeper 我这里选择的是3.5.61http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.5.6/apache-zookeeper-3.5.6.tar.gz 将下载好了压缩包，解压就安装成功可以用了，可以直接运行的。12tar -zxvf apache-zookeeper-3.5.6.tar.gz tar -zxvf kafka_2.13-2.4.0.tgz 这里需要说明的是，需要jdk 环境，我直接装的openjdk8,一样可以用。 安装包文件我们解压后的kafka 进文件夹，如下目录。我们主要用到的就是bin和config 这两个目录。 bin 目录bin 文件夹下都是一些执行的命令文件，我们暂时会用到图中圈出的这几个命令。具体用法后面再讲，先说说这几个分别干啥。1是消费者连接topic 消费消息的命令。2是生产者连接topic 推送消息的命令。3分别是启动和停止kafka服务的。4是操作topic 的指令，比如查看topic 列表或者删除topic5分别是启动和停止zookeeperd服务，这里的zookeeper 是kafka 自带的。 config 目录我们再来看看config 里面的文件。我们主要就用到server.propertie 和zookeeper.properties server.propertieserver.propertie 是启动kafka 时加载的配置文件。点击去看看，基本要改的就是下面这两个地方。每一个broker都需要一个标识符，使用broker.id来表示。它的默认值是0，也可以被设置成任意其它整数。这个值在整个kafka集群里必须是唯一的。这个值可以任意选定。我这里设置的broker.id=1 还有kafka 默认启动服务的默认端口是9092.如果我们想要修改的话，就需要在server.propertie 中加上1port = 9093 当然改了这里，还得改其他对应配置文件的连接。这里是网上截图的。 zookeeper.propertieszookeeper.connect 主要配置 zookeeper的链接。如果我们在其他地方安装的zookeeper ,就需要修改这里的配置了。zookeeper.properties 文件是启动kafka 自带的zookeeper 时加载的配置。里面的配置就比较少了，主要是libs 文件夹是kafka 运行依赖的jar 包，我们可以不用管，logs是kafka 运行产生的日志，我们排查问题时用到，暂时也不用管。 简单操作zookeeper我们按顺序来，因为kafka 启动要依赖zookeeper服务。所以我们来看zookeeper的命令。12345# 启动zookeeper 服务bin/zookeeper-server-start.sh ./config/zookeeper.properties# 停止zookeeper 服务bin/zookeeper-server-stop.sh kafka 服务启动好zookeeper 后，我们来启动kafka 服务。1bin/kafka-server-start.sh ./config/server.properties 关闭kafka 服务命令1bin/kafka-server-stop.sh topic启动好kafka 服务后，我们就可以创建topic 啦。创建topic的命令1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test1 这里可以看到创建topic 的命令算是比较复杂的， –zookeeper localhost:2181是指定zookeeper 服务。-replication-factor是指创建分区。partitions 是创建备份。test1是topic 名称。 我们在创建一个tpoic test2. 然后查看topic 列表,需要指定zookeeper 连接1bin/kafka-topics.sh --list --zookeeper localhost:2181 删除一个topic,需要指定zookeeper 和删除的topic1bin/kafka-topics.sh --delete --topic quellanan --zookeeper localhost:2181 producer我们已经创建了topic 。接下来我们可以让生产者推送消息到这个topic 上。1bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test1 –broker-list localhost:9092 连接上指定的kafka 服务器。 consumer生产者生产了消息，接下来就需要消费者消费消息啦。1bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test1 --from-beginning –bootstrap-server localhost:9092 是连接特定的kafka 服务–from-beginning 读取历史未消费的数据。 Springboot整合使用kafka上面哪些都是在服务器上操作的，所以接下来我们需要在我们代码中使用kafka ,主要是推送消息和消费消息。 这里由于我们kafka 部署在服务器上，不是我们本地，所以需要kafka 配置文件中设置远程访问。主要修改config/server.properties123listeners=PLAINTEXT://:9092advertised.listeners=PLAINTEXT://192.168.1.51:9092zookeeper.connect=192.168.1.51:2181 做如上修改就可以在远程访问啦。 produecer准备工作做好了，我们现在创建一个springboot 项目 ，名为kafka-producer，作为kafka 生产者。我这里Springboot 版本是最新的2.2.4。在pom.xml 文件中引入kafka 依赖。12345&lt;!--引入Kafka--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;/dependency&gt; 在配置文件中，配置kafka 连接12server.port=9000spring.kafka.bootstrap-servers=192.168.1.51:9092 然后我们创建一个推动消息的接口。KafkaProducerController内容如下：1234567891011@RestControllerpublic class KafkaProducerController &#123; @Resource private KafkaTemplate&lt;String,String&gt; KafkaTemplate; @RequestMapping("/send") public String sendMsg(@RequestParam(value = "topic")String topic,@RequestParam(value = "msg")String msg)&#123; KafkaTemplate.send(topic,msg); return "success"; &#125;&#125; 主要是通过KafkaTemplate 向topic 推送消息的。这样就可以了，我们启动项目，调接口1http://localhost:9000/send?topic=test3&amp;msg=hello world 控制台可以看到连接kafka 的信息。并可以看到推送的是时间和commitID consumer接下来我们就需要创建一个kafka 消费者来监控topic ，如果有新的消息就接收。pom.xml 文件和配置文件连接kafka 服务器都是一样的。我们创建一个类KafkaConsumer。内容如下123456789@Component@Slf4jpublic class KafkaConsumer &#123; @KafkaListener(groupId = "test-group",topics = "test3") public void listen(String msg)&#123; log.info("接收消息："+msg); &#125;&#125; 可以看到主要是使用KafkaListener的注解，groupId 随意写。topics 是我们需要监听的topic。至于listen方法的参数，看我们推送的是什么类型，就接收什么类型。好了，我们启动消费者进行监听。可以看到可以接收生产者推送的消息了。 这些都是比较简单的使用，我们后续接着学习kafka的内容吧，一起加油！]]></content>
      <categories>
        <category>springCloud</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springCloud</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UE激活（亲测有效，通过注册机激活）]]></title>
    <url>%2F20210810%2FUE%E6%BF%80%E6%B4%BB%EF%BC%88%E4%BA%B2%E6%B5%8B%E6%9C%89%E6%95%88%EF%BC%8C%E9%80%9A%E8%BF%87%E6%B3%A8%E5%86%8C%E6%9C%BA%E6%BF%80%E6%B4%BB%EF%BC%89.html</url>
    <content type="text"><![CDATA[前言之前一直用的是SublimeText系列，也感觉很好用的，在文本编辑上UE 和 SublimeText感觉差不多，用起来都比较舒服，但是我看中的UE一个强大的功能，可以在编辑时切换行模式和列模式。同时操作多列，虽然很少用到，但是真用的时候就方便很多了。另外UE也有一系列的产品，比如UC就是一个比较的好的比较工具。好了说了这么多开始激活吧。 准备工作：1.下载好UE(官网下载即可，https://www.ultraedit.com/)2.下载注册机，我的（https://pan.baidu.com/s/1I4uEGxL5s3P3iB2nVvXBEQ 提取密码：8myi）3.断网。 激活接下打开UE ,点击”输入许可证秘钥”。然后出来下面界面，需要输入许可证和密码，这个随便输入就可以了，但是最好不要输入字符和字母。输入数字就好了点击激活会提示没有网络，然后就选择脱机激活点击脱机激活，弹出一下界面：界面上回有上个用户码，双击运行注册机，出现一下界面，将两个用户码填入对应位置，点击Generate,会生成对应的验证码将验证码输入到UEd激活界面。点击激活，就可以激活成功啦，然后可以看一下设置，发现已经激活成功了，可以愉快的玩耍了 番外我使用了一段时间后又提示我的许可证到期了，让我重新激活，我一想不得劲呀这。然后我就在激活以后对这个软件做了禁网操作。我想这样它不会总让我激活吧哈哈，佩服自己的灵机一动。怎么给单个软件禁网，不好意思我用的是 腾讯电脑管家-工具箱-上网-流量监控。找到UE，禁用网络就好了。 当然我想360卫士、金山卫士都有类似的禁用网络的功能吧，自己找找，网上还有大佬说通过防火墙-高级设置对应用程序进行禁网，不会弄哈哈。 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>UE</tag>
        <tag>激活</tag>
        <tag>注册码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一、docker 入坑(win10和Ubuntu 安装)]]></title>
    <url>%2F20191011%2F%E4%B8%80%E3%80%81docker%20%E5%85%A5%E5%9D%91(win10%E5%92%8CUbuntu%20%E5%AE%89%E8%A3%85).html</url>
    <content type="text"><![CDATA[前言终究还是绕不过去了，要学的知识真的是太多了，好在我们还有时间，docker 之前只闻其声，不曾真正的接触过，现在docker 越来越火，很多公司也都开始使用了。所以对于我们程序员而言，又得修炼一项必备技能了。所以让我们勇敢的踏出第一步，学海无涯，让我们一步一个脚印。从安装开始讲起吧。 windows10安装参考：https://yeasy.gitbooks.io/docker_practice/content/install/windows.html 开启Hyper-Vwin10 安装需要先开启 Hyper-V。控制面板–&gt;所有控制面板项–&gt;程序和功能–&gt;启用或关闭 Windows 功能 下载安装然后下载安装程序：Stable 或者Edge 下载下来之后直接双击运行完成后的截图。 点击close and log out 会重启电脑。 设置重启完电脑后，在我们的导航栏会有docker 的图标，点击图标，选择setting ,genneral 勾选最后一个选项。 设置镜像，我们使用国内的镜像，会让我们下载速度提升，在setting的daemon中设置12https://registry.docker-cn.comhttps://dockerhub.azk8s.cn 测试在cmd 控制台查看docker 版本1docker version 运行hello-world 镜像1docker run hello-world 证明docker在win 10 上安装成功啦。至于接下来怎么使用，我们下篇再讲。 Ubuntu 安装我的是Ubuntu18.0.4 的，安装方法也很简单。1234567891011121314151617#卸载旧版本sudo apt-get remove docker docker-engine docker.io# 安装包更新sudo apt-get update# 安装依赖sudo apt-get install apt-transport-https ca-certificates curl software-properties-common# 加Docker官方GPG keysudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -#设置稳定版的Docker仓库sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"#安装 docker-cesudo apt-get install docker-ce 查看安装docker版本1docker version 运行hello-world1docker run hello-world 发现并没有出现下面错误 docker进程使用Unix Socket而不是TCP端口。而默认情况下，Unix socket属于root用户，需要root权限才能访问。所以使用1sudo docker run hello-world 或者并将当前用户加入到docker用户组中。默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。1234567891011#建立 docker 组：sudo groupadd docker# 将当前用户加入 docker 组：sudo usermod -aG docker $USER#更新用户组newgrp docker #测试docker命令是否可以使用sudo正常使用docker ps 番外到此为止，我们的win10 环境和ubuntu 环境都已经搭建好docker 啦。下篇就让我们继续学习怎么使用docker 吧。 好了，就说这么多啦 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四、springBoot优雅的创建定时任务]]></title>
    <url>%2F20190926%2F%E5%9B%9B%E3%80%81springBoot%20%E4%BC%98%E9%9B%85%E7%9A%84%E5%88%9B%E5%BB%BA%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1.html</url>
    <content type="text"><![CDATA[前言好几天没写了，工作有点忙，最近工作刚好做一个定时任务统计的，所以就将springboot 如何创建定时任务整理了一下。总的来说，springboot创建定时任务是非常简单的，不用像spring 或者springmvc 需要在xml 文件中配置，在项目启动的时候加载。spring boot 使用注解的方式就可以完全支持定时任务。不过基础注解的话，可能有的需求定时任务的时间会经常变动，注解就不好修改，每次都得重新编译，所以想将定时时间存在数据库，然后项目读取数据库执行定时任务，所以就有了基于接口的定时任务。下面就分基于注解和基于接口详细讲解。 基于注解pom.xml 文件不用修改，我们原本的项目就支持，其实定时器是springboot框架自带的，不用引入什么依赖。我们直接创建一个autotask 包，创建一个AutoTask类。123456789@EnableScheduling@Component@Slf4jpublic class AutoTask &#123; @Scheduled(cron="*/6 * * * * ?") private void process()&#123; log.info("autoTask "); &#125;&#125; 这样一个定时器就创建啦，在项目启动后，会每隔6s 打印“autoTask”的日志。是不是很简单。主要用到的两个注解就是@EnableScheduling 和 @Scheduled。注解@EnableScheduling 就是开启定时任务的。哪个类的中的方法想要定期执行，就在这个类上加入这个注解。当然这个这个注解也可以加在启动类上。加在启动类上表示项目中所有的类都可以创建定时任务。 @Scheduled 注解就是我们常见的定时器啦，后面的cron 就是定时任务表达式。在方法上注解，表示这个方法定期执行。不过@Scheduled 可以进行两种配置，我们熟悉的cron ,还有一种是fixedRate。比如fixedRate=6000 表示方法每6秒钟执行一次。我们来启动项目看一下，可以看到两个方法都在定期执行。 基于接口上面可以看到springboot 基于注解是非常方便的。但是对于频繁变动或者一个项目中有很多的定时器那就不方便管理了。所以统一将定时器信息存放在数据库中。12345678DROP TABLE IF EXISTS `scheduled`;CREATE TABLE `scheduled` ( `cron_id` varchar(30) NOT NULL PRIMARY KEY, `cron_name` varchar(30) NULL, `cron` varchar(30) NOT NULL);INSERT INTO `scheduled` VALUES ('1','定时器任务一','0/6 * * * * ?'); 在dao 层mapper1包下创建一个CronMapper接口，很简单的就获取cron12345public interface CronMapper &#123; @Select("select cron from scheduled where cron_id = #&#123;id&#125;") public String getCron(int id);&#125; 这里我们就不写service 层了。直接在autotask 包下创建一个AutoTaskFromDB类12345678910111213141516171819202122232425@Slf4j@Componentpublic class AutoTaskFromDB implements SchedulingConfigurer &#123; @Autowired protected CronMapper cronMapper; @Override public void configureTasks(ScheduledTaskRegistrar scheduledTaskRegistrar) &#123; scheduledTaskRegistrar.addTriggerTask(() -&gt; process(), triggerContext -&gt; &#123; String cron = cronMapper.getCron(1); if (cron.isEmpty()) &#123; log.info("cron 为空"); &#125; return new CronTrigger(cron).nextExecutionTime(triggerContext); &#125; ); &#125; private void process()&#123; log.info("formDB "); &#125;&#125; 可以看到也很简单，就是实现SchedulingConfigurer 这个吧接口，addTriggerTask（）是添加一个定时器。process（）方法是我们需要定时执行的方法体。CronTrigger(cron).nextExecutionTime(triggerContext) 就是从数据库读取的cron 创建定时器。 这个类我没有加上@EnableScheduling 注解，因为我在启动类上加上了，如果你们启动类上没有加，这里记得加上。 测试一下;下图可以看到三个定时任务都执行了，fromDB 是从数据库读取的。 croncron 用法网上有很多，也没有什么讲的这里就附带记录下 结构cron表达式是一个字符串，分为6或7个域，每两个域之间用空格分隔，其语法格式为：”秒域 分域 时域 日域 月域 周域 年域” 取值范围 域名 可取值 可取符号（仅列部分常用） 秒域 0~59的整数 * - , / 分域 0~59的整数 * - , / 时域 0~23的整数 * - , / 日域 1~31的整数 * - , / ? L 月域 1~12的整数或JAN~DEC * - , / 周域 1~7的整数或SUN~SAT * - , / ? L # 年域 1970~2099的整数 * - , / 常例 表达式 意义 每隔5秒钟执行一次 */5 * * * * ? 每隔1分钟执行一次 0 * /1 * * * ? 每天1点执行一次 0 0 1 * * ? 每天23点55分执行一次 0 55 23 * * ？ 每月最后一天23点执行一次 0 0 23 L * ？ 每周六8点执行一次 0 0 8 ? * L 每月最后一个周五，每隔2小时执行一次 0 0 */2 ? * 6L 每月的第三个星期五上午10:15执行一次 0 15 10 ? * 5#3 在每天下午2点到下午2:05期间的每1分钟执行 0 0-5 14 * * ? 表示周一到周五每天上午10:15执行 0 15 10 ? * 2-6 每个月的最后一个星期五上午10:15执行 0 15 10 ? * 6L 每天上午10点，下午2点，4点执行一次 0 0 10,14,16 * * ? 朝九晚五工作时间内每半小时执行一次 0 0/30 9-17 ? 每个星期三中午12点执行一次 0 0 12 ? * 4 每年三月的星期三的下午2:10和2:44各执行一次 0 10,44 14 ? 3 4 每月的第三个星期五上午10:15执行一次 0 15 10 ? * 6#3 每月一日凌晨2点30执行一次 0 30 2 1 * ? 每分钟的第10秒与第20秒都会执行 10,20 * * * * ? 每月的第2个星期的周5，凌晨执行 0 0 0 ? * 6#2 番外本来这个知识点不应该放在这里讲的，但是不多，顺带写了，刚好也能做定时器。我们项目中往往有一些需求需要在项目启动的时候就执行，那这个我们怎么实现了。其实spring boot 使用起来也非常简单，只用实现 ApplicationRunner 就好了。我们在autotask 包下创建一个AutoTaskFromSpringRunner类 12345678910111213@Slf4j@Componentpublic class AutoTaskFromSpringRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; process(); &#125; private void process()&#123; log.info(" run ApplicationArguments"); &#125;&#125; 启动项目看一下，可以发现这个会在项目启动后执行，但是只会执行一次。 那这个怎么用来做定时器呢？当然是结合线程来做啦，但是这个方法其实不建议，b毕竟线程很容易出问题，但是提供一种思路： 12345678910111213141516171819202122232425@Slf4j@Componentpublic class AutoTaskFromSpringRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; process(); new Thread(() -&gt; &#123; while (true) &#123; process2(); try &#123; Thread.sleep(6000); &#125; catch (InterruptedException e) &#123; log.error("&#123;&#125;",e); &#125; &#125; &#125;).start(); &#125; private void process()&#123; log.info(" run ApplicationArguments"); &#125; private void process2()&#123; log.info("线程定时器"); &#125;&#125; 启动项目看下，发现也是可以起到定时器的作用的。 好了，就说这么多啦，今天项目的代码也同步到github 上啦。github地址：https://github.com/QuellanAn/zlflovemm 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三、SpringBoot 整合mybatis 多数据源以及分库分表]]></title>
    <url>%2F20190921%2F%E4%B8%89%E3%80%81SpringBoot%20%E6%95%B4%E5%90%88mybatis%20%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E4%BB%A5%E5%8F%8A%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8.html</url>
    <content type="text"><![CDATA[前言说实话，这章本来不打算讲的，因为配置多数据源的网上有很多类似的教程。但是最近因为项目要用到分库分表，所以让我研究一下看怎么实现。我想着上一篇博客讲了多环境的配置，不同的环境调用不同的数据库，那接下来就将一个环境用到多个库也就讲了。所以才有了这篇文章。我们先来看一下今天项目的项目结构，在上篇博客的基础上进行了一定的增改，主要是增加了一个 config 文件，在dao 中分了两个子包mapper1 和mapper2 将原先的UserMapper 移入到了 mapper1 中。好了，开始正文 多数据源配置背景在这之前，还是先说一下为什么会存在多数据源。如果项目小的话，当然是所有的数据以及逻辑处理都操作同一个库。但是当业务量大的话，就会考虑到分库了。比我会将也日志入库数据存放到单独的数据库。或者用户权限信息单独的一个库存放。这种如果只是简单的分库，一个项目中就用到2~4 个数据库的话，这种多数据源配置就有意义啦。在配置文件中配置好这几个数据源，都有唯一标识。项目在启动加载的时候都进行初始化，然后在调用的时候，想用哪个库就哪个数据源的连接实例就好了。 如果不整合 mybatis 的话，直接使用使用spring 自带的jdbcTemplate ，那配置多数据源，以及使用都比较简单，但是整合 mybatis 的话，就相对复杂点。我们一步一步来将讲解。 修改配置文件打开application-dev.yml 文件，添加数据源。12345678910111213141516171819202122#开发环境spring: # 数据源配置 datasource: one: driver-class-name: com.mysql.jdbc.Driver jdbc-url: jdbc:mysql://192.168.252.53:3306/zlflovemm?characterEncoding=utf-8&amp;useSSL=false&amp;zeroDateTimeBehavior=CONVERT_TO_NULL username: root password: 123456 max-idle: 10 max-wait: 10000 min-idle: 5 initial-size: 5 two: driver-class-name: com.mysql.jdbc.Driver jdbc-url: jdbc:mysql://192.168.252.53:3306/zlfdb?characterEncoding=utf-8&amp;useSSL=false&amp;zeroDateTimeBehavior=CONVERT_TO_NULL username: root password: 123456 max-idle: 10 max-wait: 10000 min-idle: 5 initial-size: 5 这里需要注意的是如果使用的是springboot 2.0 以上的，那么注意是 driver-class-name 和 jdbc-url 而不是driverClassName和url.这里是一个坑，提醒大家一下。 配置数据源接下来就需要我们手动的加载什么什么数据源了，我们在config中创建 DataSourcesConfig 类1234567891011121314151617@Configurationpublic class DataSourcesConfig &#123; @Bean(name="dbOne") @ConfigurationProperties(prefix = "spring.datasource.one") @Primary DataSource dbOne()&#123; return DataSourceBuilder.create().build(); &#125; @Bean(name="dbTwo") @ConfigurationProperties(prefix = "spring.datasource.two") DataSource dbTwo()&#123; return DataSourceBuilder.create().build(); &#125;&#125; 这里定义了两个数据源的DataSource。分别是我们在配置文件中配置的one 和two 。注解@Primary 表示默认使用的数据源。 MyBatisConfigOne 类12345678910111213141516171819@Configuration@MapperScan(basePackages = "com.quellan.zlflovemm.dao.mapper1",sqlSessionFactoryRef = "sqlSessionFactory1",sqlSessionTemplateRef = "sqlSessionTemplate1")public class MyBatisConfigOne &#123; @Resource(name = "dbOne") DataSource dbOne; @Bean @Primary SqlSessionFactory sqlSessionFactory1()throws Exception &#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dbOne); return bean.getObject(); &#125; @Bean @Primary SqlSessionTemplate sqlSessionTemplate1() throws Exception&#123; return new SqlSessionTemplate(sqlSessionFactory1()); &#125;&#125; MyBatisConfigTwo 类1234567891011121314151617@Configuration@MapperScan(basePackages = "com.quellan.zlflovemm.dao.mapper2",sqlSessionFactoryRef = "sqlSessionFactory2",sqlSessionTemplateRef = "sqlSessionTemplate2")public class MyBatisConfigTwo &#123; @Resource(name = "dbTwo") DataSource dbTwo; @Bean SqlSessionFactory sqlSessionFactory2()throws Exception &#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dbTwo); return bean.getObject(); &#125; @Bean SqlSessionTemplate sqlSessionTemplate2()throws Exception &#123; return new SqlSessionTemplate(sqlSessionFactory2()); &#125;&#125; 注意连个文件的区别： dao 层在dao 层创建了两个包mapper1 和mapper2 .包里面的UserMapper类的内容是完全一样，放在不同的包中只是区分使用哪个数据源。和昨天是一样的。123456789101112public interface UserMapper &#123; @Select("select id,username as userName,password,email,role_code as roleCode,gmt_create as gmtCreate,gmt_update as gmtUpdate,nickname as nickName,user_create as userCreate from sys_user") List&lt;UserEntry&gt; findUserList(); @Insert(&#123;"insert into sys_user(username,password,email) values('$&#123;user.userName&#125;','$&#123;user.password&#125;','$&#123;user.email&#125;')"&#125;) int add(@Param("user") UserEntry user); @Delete("delete from sys_user where id = #&#123;id&#125;") int delete(int id);&#125; service 层UserService接口1234567891011121314public interface UserService &#123; List&lt;UserEntry&gt; findUserList(); int addUser(String userName,String password,String email); int deleteUser(int id); List&lt;UserEntry&gt; findUserList2(); int addUser2(String userName,String password,String email); int deleteUser2(int id);&#125; UserServiceImpl类：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired protected UserMapper userMapper; @Autowired protected UserMapper2 userMapper2; @Override public List&lt;UserEntry&gt; findUserList() &#123; return userMapper.findUserList(); &#125; @Override public int addUser(String userName, String password, String email) &#123; UserEntry user=new UserEntry(); user.setUserName(userName); user.setPassword(password); user.setEmail(email); return userMapper.add(user); &#125; @Override public int deleteUser(int id) &#123; return userMapper.delete(id); &#125; @Override public List&lt;UserEntry&gt; findUserList2() &#123; return userMapper2.findUserList(); &#125; @Override public int addUser2(String userName, String password, String email) &#123; UserEntry user=new UserEntry(); user.setUserName(userName); user.setPassword(password); user.setEmail(email); return userMapper2.add(user); &#125; @Override public int deleteUser2(int id) &#123; return userMapper2.delete(id); &#125;&#125; controller 层userController12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Slf4j@RestController@RequestMapping("/user")public class UserController &#123; @Autowired private UserService userService; @RequestMapping(value = "/list",method = RequestMethod.GET) public List&lt;UserEntry&gt; findUserList()&#123; return userService.findUserList(); &#125; @RequestMapping(value = "/add",method = RequestMethod.GET) public String addUser(@RequestParam(value = "userName")String uaserName,@RequestParam(value = "password")String password,@RequestParam(value = "email")String email)&#123; int falg=userService.addUser(uaserName,password,email); if(falg&gt;0)&#123; return "success"; &#125; return "error"; &#125; @RequestMapping(value = "/delete",method = RequestMethod.GET) public String deleteUser(@RequestParam(value = "id")int id)&#123; if(userService.deleteUser(id)&gt;0)&#123; return "success"; &#125; return "error"; &#125; @RequestMapping(value = "/list2",method = RequestMethod.GET) public List&lt;UserEntry&gt; findUserList2()&#123; return userService.findUserList2(); &#125; @RequestMapping(value = "/add2",method = RequestMethod.GET) public String addUser2(@RequestParam(value = "userName")String uaserName,@RequestParam(value = "password")String password,@RequestParam(value = "email")String email)&#123; int falg= userService.addUser2(uaserName,password,email); if(falg&gt;0)&#123; return "success"; &#125; return "error"; &#125; @RequestMapping(value = "/delete2",method = RequestMethod.GET) public String deleteUser2(@RequestParam(value = "id")int id)&#123; if(userService.deleteUser2(id)&gt;0)&#123; return "success"; &#125; return "error"; &#125;&#125; 测试可以看到是从不同的库中调出来的。这样就说明我们springboot配置多数据源整合mybatis 已经成功了。其实最主要就是config 包下的那三个配置类。其他的都是常见的业务逻辑，所以后面我就没有怎么讲了，代码会同步到github 上，想要实践的可以拿源码下来实践。 到此我们springboot整合mybatis 多数据源已经配置好了，但是我们配置下来可以发现，我们如果想要配置几个数据源就得在 dao 层创建多少个子包用来区分。那如果我们数据量足够大，要分库分表而不是几个库呢？ 分库分表背景其实分库分表和多数据源是一样的，只不过是数据源更多了，多到在配置中配置所有的连接显得很臃肿，所以不得不另觅它法。分库分表就是 在项目中配置连接主库的连接，从主库中读取各个分库的连接，然后进行动态的加载，那个接口想调用那个分库就加载这个分库的连接。我现在项目做的由于不用整合mybatis 直接使用jdbcTemplate ，所以实现起来不是很麻烦。 思路主要就两个类；GetDynamicJdbcTemplate类：手动的创建连接。123456789101112131415161718192021222324252627282930313233343536/** * @ClassName GetDynamicJdbcTemplate * @Description 获取动态的jdbcTemplate * @Author zhulinfeng * @Date 2019/9/20 14:35 * @Version 1.0 */public class GetDynamicJdbcTemplate &#123; private String driverClassName; private String url; private String dbUsername; private String dbPassword; private JdbcTemplate jdbcTemplate; public JdbcTemplate getJdbcTemplate() &#123; return jdbcTemplate; &#125; public GetDynamicJdbcTemplate(String driverClassName, String url, String dbUsername, String dbPassword)&#123; this.driverClassName=driverClassName; this.url=url; this.dbUsername=dbUsername; this.dbPassword=dbPassword; this.jdbcTemplate=new JdbcTemplate(getDataSource()); &#125; public DriverManagerDataSource getDataSource() &#123; DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName(driverClassName); dataSource.setUrl(url); dataSource.setUsername(dbUsername); dataSource.setPassword(dbPassword); return dataSource; &#125;&#125; GetJdbcTemplateMap类在项目启动的时候，会读取主库中的配置，将所有分库的连接都创建好放到map中。我们是按照地市分表的，接口在调用的时候根据前端传过来的地市就可以知道使用哪个数据库连接了。1234567891011121314151617181920212223242526272829303132@Component@Slf4j public class GetJdbcTemplateMap implements ApplicationRunner &#123; @Autowired @Qualifier("baseTemplate") private JdbcTemplate jdbcTemplate; public static Map&lt;String,JdbcTemplate&gt; JdbcTemplateMap=new HashMap&lt;&gt;(); @Override public void run(ApplicationArguments args) throws Exception &#123; String sql="CALL proc_baseinfo_cfg_dbsetting_query()"; List&lt;Map&lt;String, Object&gt;&gt; list = jdbcTemplate.queryForList(sql); if(list!=null &amp;&amp; !list.isEmpty())&#123; insertMap(list); &#125; &#125; private void insertMap(List&lt;Map&lt;String, Object&gt;&gt; list)&#123; for(Map&lt;String, Object&gt; map :list)&#123; String url="jdbc:mysql://" map.get("serverip") ":" map.get("dbport") "/" map.get("dbname") "?allowMultiQueries=true&amp;useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull"; log.info(url); String dbUsername= map.get("user").toString(); String dbPassword= map.get("password").toString(); GetDynamicJdbcTemplate getDynamicJdbcTemplate=new GetDynamicJdbcTemplate(ConstantClass.DRIVERCLASSNAME,url,dbUsername,dbPassword); JdbcTemplate jdbcTemplate=getDynamicJdbcTemplate.getJdbcTemplate(); JdbcTemplateMap.put(map.get("cityid").toString(),jdbcTemplate); &#125; &#125;&#125; 在接口中调用也很方便。 但是上面讲的只适合我们自己特有的业务，并且也没有整合mybatis ,所以我就没有写在我自己的项目中，这里提供出来是给大家一个思路。 番外也算是写完了这篇，感觉写的不是很好，但是有不知道怎么修改，暂时就先这样吧，后续有思路了再进行修改。又问问我为什么不先整合Thymeleaf 弄出页面来。之所以没有弄，是因为我想后期做前后端分离都是以接口的形式调用。所以想先将后端的部分都搭建好，再来整合前端的。好了，就说这么多啦，今天项目的代码也同步到github 上啦。github地址：https://github.com/QuellanAn/zlflovemm 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二、springBoot 整合 mybatis 项目实战]]></title>
    <url>%2F20190919%2F%E4%BA%8C%E3%80%81springBoot%20%E6%95%B4%E5%90%88%20mybatis%20%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98.html</url>
    <content type="text"><![CDATA[前言上一篇文章开始了我们的springboot序篇，我们配置了mysql数据库，但是我们sql语句直接写在controller中并且使用的是jdbcTemplate。项目中肯定不会这样使用，上篇文章也说了，会结合mybatis 或者JPA 使用。我们这篇文章就来结合 mybatis 来使用吧，至于为什么选mybatis 而不是JPA ，这个看个人洗好吧。然后这篇文章会附带一讲一下今天为项目新增的配置。主要是为了保持项目和文章的一致性。 先贴出我们今天项目的结构吧，和昨天贴出来的差不多，在那基础上添加了一些东西，整个框架的模型算是成型了。 引入mybatis依赖一般改动都是从pom.xml 开始的，我们在昨天基础上的pom.xml 文件中加上mybatis 依赖,版本自己选吧。12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; Entry层昨天我们创建了一个user表 并插入了一条数据，我们就先用这张表吧，所以我们在entry 包中创建一个UserEntry 的实体类.代码如下：1234567891011121314@Getter@Setterpublic class UserEntry &#123; private int id; private String userName; private String password; private String email; private String roleCode; private String roleName; private String gmtCreate; private String gmtUpdate; private String nickname; private String userCreate;&#125; 可以看到这里用的注解和@Getter 和@Setter。这里就是避免代码中写入过多的get和 set 方法，使得代码变得更加简洁。 Dao 层Dao是用来处理数据的，这里我们引入了mybatis ,可以使用注解，也可以创建xml 文件，将sql 语句写在xml 文件中。我们这里就采用注解的方式吧，毕竟我们springboot项目，不想再出现xml配置文件了(后期也说不定哈哈)。 在dao包下创建一个userMapper 接口。代码如下：1234567891011121314@Mapperpublic interface UserMapper &#123; @Select("select id,username as userName,password,email,role_code as roleCode,gmt_create as gmtCreate,gmt_update as gmtUpdate,nickname as nickName,user_create as userCreate from sys_user") List&lt;UserEntry&gt; findUserList(); @Insert(&#123;"insert into sys_user(username,password,email) values('$&#123;user.userName&#125;','$&#123;user.password&#125;','$&#123;user.email&#125;')"&#125;) int add(@Param("user") UserEntry user); @Delete("delete from sys_user where id = #&#123;id&#125;") int delete(int id);&#125; 我们这里就先写一个查询、删除和插入的方法吧。可以看到，在接口上引入@Mapper 注解，然后就可以直接使用@Select 和@Insert 等注解啦，直接把注解sql 语句写在这里面就可以了。 Service 层service层我们一般都以一个接口和一个实现接口的具体类。 service 接口代码如下：123456789public interface UserService &#123; List&lt;UserEntry&gt; findUserList(); int addUser(String userName,String password,String email); int deleteUser(int id);&#125; serviceImpl 具体实现类。在service 包的impl 包创建 UserServiceImpl 类。代码如下：123456789101112131415161718192021222324252627@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired protected UserMapper userMapper; @Override public List&lt;UserEntry&gt; findUserList() &#123; return userMapper.findUserList(); &#125; @Override public int addUser(String userName, String password, String email) &#123; UserEntry user=new UserEntry(); user.setUserName(userName); user.setPassword(password); user.setEmail(email); return userMapper.add(user); &#125; @Override public int deleteUser(int id) &#123; return userMapper.delete(id); &#125;&#125; controller 层我们在controller 包下的userinfo 包下创建UserController 类。代码如下：12345678910111213141516171819202122232425262728293031@Slf4j@RestController@RequestMapping("/user")public class UserController &#123; @Autowired private UserService userService; @RequestMapping(value = "/list",method = RequestMethod.GET) public List&lt;UserEntry&gt; findUserList()&#123; return userService.findUserList(); &#125; @RequestMapping(value = "/add",method = RequestMethod.GET) public String addUser(@RequestParam(value = "userName")String uaserName,@RequestParam(value = "password")String password,@RequestParam(value = "email")String email)&#123; int falg=userService.addUser(uaserName,password,email); if(falg&gt;0)&#123; return "success"; &#125; return "error"; &#125; @RequestMapping(value = "/delete",method = RequestMethod.GET) public String deleteUser(@RequestParam(value = "id")int id)&#123; if(userService.deleteUser(id)&gt;0)&#123; return "success"; &#125; return "error"; &#125;&#125; 测试好了，万事具备，来测试吧。我们启动项目后，在浏览器输入12添加一个用户http://localhost:9090/zlflovemm/user/add?userName=qaz&amp;password=123456&amp;email=123@qq.com 12查询所有用户http://localhost:9090/zlflovemm/user/list 12删除一个用户http://localhost:9090/zlflovemm/user/delete?id=19 都没有问题啦，说明基本的增删改查整合 mybatis 都是可行的。 配置多环境文件好了，大头讲完了，我们现在来讲讲项目今天进行了哪些配置。首先我们来看下我们项目中多了好几个配置文件。分别对应的是开发环境，测试环境，生产环境。毕竟我们在实际开发过程中，这三个环境都是经常有用到的，总会有数据库连接改来改去的问题。这里直接配置多份，想用哪个用那个就可以了。避免反复改容易出错的问题。我这里就暂时把连接mysql 的链接放到不同环境了。先在application.properties中加入12spring.profiles.active=dev表示用的是开发环境，就会读取application-dev.yml 文件中的配置。 application-dev.xml文件内容如下，另外两个文件也差不多，就不贴出来了。 配置日志项目中怎么能缺乏日志文件呢，我这里用的springboot 自带的日志框架logback 也很方便。我们先在application.properties 中加入1234#日志配置logging.level.org.springframework.web=infologging.config=classpath:logback.xmldebug=true 然后在 application.properties 同目录下创建一个 logback.xml.内容如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration debug="false"&gt; &lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径--&gt; &lt;property name="LOG_HOME" value="./logs" /&gt; &lt;property name="INFO_FILE" value="zlflovemm_log" /&gt; &lt;property name="ERROR_FILE" value="zlflovemm_error" /&gt; &lt;!--控制台日志， 控制台输出 --&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度,%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 文件保存日志的相关配置，同步 --&gt; &lt;appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;Prudent&gt;true&lt;/Prudent&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--日志文件输出的文件名--&gt; &lt;FileNamePattern&gt; $&#123;LOG_HOME&#125;/$&#123;INFO_FILE&#125;-%d&#123;yyyy-MM-dd&#125;.log &lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;[%t][%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--日志文件最大的大小--&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;MaxFileSize&gt;10MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;/appender&gt; &lt;!-- 文件保存日志的相关配置，同步 --&gt; &lt;appender name="ERROR" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;/filter&gt; &lt;Prudent&gt;true&lt;/Prudent&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--日志文件输出的文件名--&gt; &lt;FileNamePattern&gt; $&#123;LOG_HOME&#125;/$&#123;ERROR_FILE&#125;-%d&#123;yyyy-MM-dd&#125;.log &lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;[%t][%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--日志文件最大的大小--&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;MaxFileSize&gt;10MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;/appender&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level="INFO"&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;appender-ref ref="FILE"/&gt; &lt;appender-ref ref="ERROR" level="error" /&gt; &lt;/root&gt;&lt;/configuration&gt; 这样项目日志就配置好了，至于日志的具体配置，修改logback.xml 里面参数就可以了。和log4g差不多。 配置banner最后既然是一个项目，当然得有点标志性的东西，比如logo。springboot 给我们留下了一个彩蛋就是banner。我们可以在项目启动的时候，显示我们独一无二的logo .在application.properties 同目录下创建 banner.txt艺术字大家在网上自行搜索，这里就不推荐啦哈哈。这样我们在项目启动的时候就会加载我们的logo. 算是给广大的我们一点福利吧。 番外今晚总算是写完了，本来会早点的，但是不知道怎么就弄这么晚了。今天项目的代码也同步到github 上啦。github地址：https://github.com/QuellanAn/zlflovemm 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一、springboot起航]]></title>
    <url>%2F20190918%2F%E4%B8%80%E3%80%81springboot%E8%B5%B7%E8%88%AA.html</url>
    <content type="text"><![CDATA[前言之前零零散散的学习了一些springboot的知识，以及搭建一些springboot的项目，甚至还有一些项目应用到实际项目中了，但是突然有一天想要建一个自己的项目网站。发现自己不知道从何开始。发现自己虽然用了很久，但是让自己 从头开始搭建一个却处处碰壁。所以静下心来好好的整理一下springboot的知识点。以及给自己搭建一个springboot 项目的脚手架。以后方便自己套用。 创建spring boot项目springboot的之所以火热便是因为开箱即用的特效，低配置甚至无配置使用，方便我们快速上手，我们这里先就什么都不配置吧。在idea 上直接可以创建springboot 类型项目。项目名就随便起吧，整个系列就都以这个项目为例啦，整个项目会分享到github 上，大家需要的可以跟着下载学习。建好的项目目录如下：其中选中的文件夹是我自己加的，因为我想整个项目的目录大概就是这个样子了。文件名起了zlflovemm 没有什么项目含义，起名太难了，就起了一个自己纪念的名字，大家勿怪。我们pom.xml 内容，因为后期不管是加其他组件，还是引用 jar 包什么的都是改这里。所以把最初版本拿出来。 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.quellan&lt;/groupId&gt; &lt;artifactId&gt;zlflovemm&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;name&gt;zlflovemm&lt;/name&gt; &lt;description&gt;zlflovemm project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 可以看到pom.xml 文件里面东西很少了，parent 中是 springboot 版本信息。properties 是 jdk 版本信息。dependencies中的依赖只有一个starter-web 和starter-test 前面是这个项目支持web 项目，后面一个是支持单元测试，这两个都是创建项目的时候自带的。build 中就是项目构建打包的方式啦。这里暂时先用这种方式。 hello world我们还是来写一个hello world 吧，虽然有点幼稚，但毕竟遵循一下古训。我们在controller 包下创建一个demo 包。在demo 包下创建一个 demo.java . 12345678@RestControllerpublic class Demo &#123; @RequestMapping("/") public String demo()&#123; return "hello world"; &#125;&#125; 在controller 层用到的注解最多的就是@RestController 和@RequestMapping 了。@RestController和@Controller 注解是使用在controller层的。和@RequestMapping注解是用于设置映射路径的。这里注解就不深入讲解了，后面会进行深入的讲解。我们代码写完之后，我们来启动项目看一下，这里我们就直接运行 ZlflovemmApplication中的 main 方法就好了。然后在浏览器输入 1localhost:8080 到此原型已经搭建好了，可以发现我们什么都没有配置，都是使用的默认的配置，直接写的测试代码，然后就可以直接使用。 但是这样对于一个项目来说远远不够的，我们来为项目增加一些配置。 配置mysql其实一开始就配置mysql 太唐突了，但是一些小配置，不想再起一节，所以就一起了。 准备工作首先当然是创建数据库和表啦，这里idea 也可以连接mysql 数据库，我们就一切都在idea上操作吧。配置我们数据库连接，我这里已经在我的虚拟机上搭建好了mysql,说到搭建MySQL 也遇到一些坑。没有整理成单独的博客，大家可以参考Ubuntu18.04下安装MySQL连接好之后，我们执行一下sql ,创建数据库，创建表，插入数据。 12345678910111213141516171819CREATE DATABASE /*!32312 IF NOT EXISTS*/`zlflovemm` /*!40100 DEFAULT CHARACTER SET utf8 */;USE `zlflovemm`;CREATE TABLE `sys_user` ( `id` INT(11) NOT NULL AUTO_INCREMENT, `username` VARCHAR(255) NOT NULL, `password` VARCHAR(255) NOT NULL, `email` VARCHAR(255) NOT NULL, `role_code` VARCHAR(255) NOT NULL, `role_name` VARCHAR(255) NOT NULL, `gmt_create` DATETIME NOT NULL, `gmt_update` DATETIME NOT NULL, `nickname` VARCHAR(255) DEFAULT NULL, `user_create` INT(11) NOT NULL, PRIMARY KEY (`id`)) ENGINE=INNODB AUTO_INCREMENT=17 DEFAULT CHARSET=utf8;/*Data for the table `sys_user` */INSERT INTO `sys_user`(`id`,`username`,`password`,`email`,`role_code`,`role_name`,`gmt_create`,`gmt_update`,`nickname`,`user_create`) VALUES (1,'admin','123456','345849402@qq.com','admin','管理员','2019-03-21 14:30:57','2019-03-21 14:30:57','admin',1); 我们测试一下我们数据库建成功没有。 1select * from sys_user 这样说明我们数据库是没有问题的。 pom.xml 中添加依赖我们现在pom.xml 中添加依赖123456789101112131415&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; 前面两个是mysql 依赖，lombok 是方便我们getter方法和setter方法以及引入日志的。后面代码中会体现。 配置application.properties在application.properties中配置如下 12345678910111213141516server.port=9090server.servlet.context-path=/zlflovemmserver.tomcat.uri-encoding=UTF-8spring.http.encoding.charset=UTF-8spring.http.encoding.enabled=truespring.http.encoding.force=truespring.messages.encoding=UTF-8spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.url=jdbc:mysql://192.168.252.53:3306/zlfdb?characterEncoding=utf-8&amp;useSSL=false&amp;zeroDateTimeBehavior=CONVERT_TO_NULLspring.datasource.username=rootspring.datasource.password=123456spring.datasource.max-idle=10spring.datasource.max-wait=10000spring.datasource.min-idle=5spring.datasource.initial-size=5 前面配置访问端口为9090，访问路径为/zllovemm/，设置编码格式为utf-8.下面就是配置mysql 。 编写测试为了方便，我们就直接在controller编写测试。在controller包中建一个包 userinfo ,在userinfo中创建一个UserController并编写 12345678910111213@RestControllerpublic class UserController &#123; @Autowired private JdbcTemplate jdbcTemplate; @RequestMapping("/getUser") public List&lt;Map&lt;String, Object&gt;&gt; getUser()&#123; String sql="select * from sys_user"; return jdbcTemplate.queryForList(sql); &#125;&#125; 然后我们来启动项目，在浏览器中输入 1http://localhost:9090/zlflovemm/getUser 可以看到数据库是配置成功的。当然正式的项目肯定不能这样写，正式的项目会采用mybatis 或者JPA ,这个后期项目肯定也是会用的，所以这里就暂时这样写。 番外项目的雏形就先这样吧，后续加入其它组件，会继续在这个项目上跟新。github地址：https://github.com/QuellanAn/zlflovemm 这篇就到这里吧，也算是开篇了 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一、让我们开启单元测试之旅]]></title>
    <url>%2F20190910%2F%E4%B8%80%E3%80%81%E8%AE%A9%E6%88%91%E4%BB%AC%E5%BC%80%E5%90%AF%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%97%85.html</url>
    <content type="text"><![CDATA[前言思量良久在考虑要不要写这一篇，是不是直接看门见山将在项目中怎么进行单元测试。最后想想觉得是不是太猴急了写那样，就好比你想和一个姑娘滚床单，是不是先应该请姑娘吃顿饭、送点礼物什么的。所以我才决定写这篇序言，让我们一起慢慢的揭开单元测试的面纱。 什么是单元测试这个在网上有很详细的解释。我这就简单的给出一个概念：单元测试是开发者编写一小段代码，用于检测被测代码的一个很小的、很明确的功能是否正确。 单元测试是对软件基本单元进行的测试，实际应用中是对public 函数进行的测试。执行单元测试，是为了验证某段代码的行为确实和开发者所期望的一致。 为什么要进行单元测试理由千千万，我只宠这三点： 减少调试时间 自动化测试 令设计变得更好 我们或多或少也都听说过单元测试，只知道用来检测写的代码有没有问题，这导致之前都没有写过测试用例，测试一些重要的方法最多也一个 main方法正常的数据调通了就过了，这样导致后期出现各种各样的问题，一遍遍的改代码，一遍遍的改bug。费时费力还不一定能处理好。我以为这是软件开发的诟病，其实不然，是因为我们不能确认我们写的那部分代码没有问题，所以总花费很长时间找问题上。所以才需要进行单元测试，虽然在刚开始写单元测试会花费时间，但是我们单元测试全都通过之后，我们对自己写的代码更有自信，可以确定没有代码没有问题了，而不是自己认为没有问题的那种。这样后期修复bug,也可以通过单元测试哪些执行成功哪些执行失败可以快速的定位到问题。我觉得这一点就足以让我们为我们写的代码编写相应的单元测试啦，毕竟找问题真是太痛苦，大家应该也深有体会。 单元测试怎么做简单而言，就是对一个 public 方法编写测试用例，那测试用例又怎么写呢？测试用例说白了也是一个方法，用来验证目标方法是否符合我们的预期。那这样就知道怎么写了吧，就是和我们平时写方法一样，但是它有一个标准俗称 “3A 模式” Arrange-Act-Assert（准备上下文环境–执行被测函数–断言）。也就是说一个测试用例的方法包含三部分就可以了。 测试用例应该具备的特征上面说的测试用例包含这三部分就可以了，那我们的测试用例应该具备怎样的特征呢，短小精悍且快准繁 小：一个测试几行代码（15）精准：一个测试之测一个场景隔离：每个测试都可以独立、重复运行，无耦合快：每个测试都应该是毫秒级别的频繁：应该频繁的执行，没增加、修改、删除一个测试都要运行一遍 那什么样的是好的单元测试呢？自动化可重复的彻底的独立的专业的 好的测试用例测试用例应该短小精悍且快准狠。这些是对测试用例的函数本身而言的，但在实际项目中出问题往往就是某些情况没有考虑到导致程序出错的，我们在自测的时候往往会测试正常数据的情况然而却忽略的了错误情况和边界值的测试，这些才是校验一个项目的健壮性的标准。所以好的测试用例必定是有全面的测试数据。那怎样获取全面的测试数据呢？在这之前需要知道哪些是好的测试数据 最优可能抓住错误的 不是重复的，多余的 一组相似测试用例中最有效的 既不是太简单，也不是太复杂 那怎样获取好的测试数据呢？有等价类划分法、边界值法、路径分析法。 等价类划分法等价类划分法是把所有可能的输入数据，划分成若干个子集，然后从每个子集中选取少数的具有代表性的数据作为测试用例。该方法是一种重要的、常用的黑盒测试用例设计方法。 有效等价类：对程序的规范说明是合理的，有意义的输入数据构成的集合。无效等价类：对程序的规范说明不是合理的或者无意义的输入数据构成的集合。 我们来看一个例子：计算两个点距离的函数 1public double getDistance(double x1, double y1, double x2, double y2) 边界值法边界值分析法是对输入或者输出的边界值进行测试的一组黑盒测试方法。 通常情况下，边界值分析法是作为等价类划分法的补充，这种情况下，其测试用例来自等价类的边界。 比如上面一个例子中取边界值做为测试用例。 路径分析法基本路径测试是一种白盒测试方法，它在程序控制图的基础上，通过分析程序的流程，构造导出基本可执行路径集合，从而设计测试用例的方法。 设计出的测试用例要保证在测试程序中的每一个可执行语句至少执行一次。我们来看一个例子可能的路径为： 12341-2-3-4-51-2-3-4-61-2-4-51-2-4-6 断言我们这里说的断言只是Junit断言，java 本身也有断言的，但是貌似我们使用的很少以至于我们都忘记了它的存在。Junit 断言说是断言，其实也就是一份方法，没有什么语法。我们测试用例中使用断言，也就是使用这些方法来进行验证是否达到我们的预期。方法有很多，大家可以看看源码，我这里给出几个常见的。|函数名|描述 ||–|–|| assertEquals| 判断实际产生的值与期望值是否相等||assertNull|判断对象是否为null||assertNotNull|判断对象是否为非null||assertSame|判断实际产生的对象与期望对象是否为同一个对象||assertNotSame|判断实际产生的对象与期望对象是否为不同的对象||assertTrue|判断bool变量是否为真||assertFalse|判断bool变量是否为假||Fail|使测试立即失败| 上面这样说好像没有什么效果，我们先来看其中一个断言方法的源代码。我们就看第一个assertEquals 吧可以看到有很多assertEquals方法。这样的方法的重载在底层很常见。我们来看下三个参数类似是Object的这个吧。 123456789101112131415161718192021222324252627282930313233343536public static void assertEquals(String message, Object expected, Object actual) &#123; if (!equalsRegardingNull(expected, actual)) &#123; if (expected instanceof String &amp;&amp; actual instanceof String) &#123; String cleanMessage = message == null ? "" : message; throw new ComparisonFailure(cleanMessage, (String)expected, (String)actual); &#125; else &#123; failNotEquals(message, expected, actual); &#125; &#125; &#125;private static boolean equalsRegardingNull(Object expected, Object actual) &#123; if (expected == null) &#123; return actual == null; &#125; else &#123; return isEquals(expected, actual); &#125; &#125; private static boolean isEquals(Object expected, Object actual) &#123; return expected.equals(actual); &#125;private static void failNotEquals(String message, Object expected, Object actual) &#123; fail(format(message, expected, actual)); &#125; static String format(String message, Object expected, Object actual) &#123; String formatted = ""; if (message != null &amp;&amp; !message.equals("")) &#123; formatted = message + " "; &#125; String expectedString = String.valueOf(expected); String actualString = String.valueOf(actual); return expectedString.equals(actualString) ? formatted + "expected: " + formatClassAndValue(expected, expectedString) + " but was: " + formatClassAndValue(actual, actualString) : formatted + "expected:&lt;" + expectedString + "&gt; but was:&lt;" + actualString + "&gt;"; &#125; equalsRegardingNull() 函数就是判断两个值是否相等，底层还是相当于用的object.equals()。如果两个值相等就断言通过，如果不相等就判断expected和actual是否是string类型，如果是直接将message输出。如果不是就failNotEquals().failNotEquals方法的源码我也贴出来了，可以看也很简单，就是message、expected、actual转换成string格式输出出来，并执行fail()使得测试失败。 从上面看断言也就不过如此(Junit 断言)。我们会使用常用的方法就可以写好测试用例啦，至于其他的方法，我们用到的时候可以直接其源代码，毕竟也不会很复杂。 简单案例目标代码及功能说明这段代码在项目中的作用是对特殊字段的对应的值进行处理并返回。如果字段是包含time，那将值改成日期格式返回。如果字段是包含iphone,那将值截取后11位返回。其他情况，直接返回。 12345678910111213141516171819202122232425262728293031323334public class DataHandle &#123; public static final String REGEX_MOBILE = "^((13[0-9])|(15[0-9])|(17[0-9])|(18[0-9])|(19[0-9])|(14[0-9]))\\d&#123;8&#125;$"; public String fieldDataHandle(String key,String value)&#123; //如果是时间类型，将时间戳转成时间 if(key.toLowerCase().contains("ipone"))&#123; //如果手机号长于11位，截取后11位 if(value.length()&gt;11)&#123; value=value.substring(value.length()-11); &#125; if(!isMobile(value))&#123; return null; &#125; &#125;else if(key.toLowerCase().contains("time"))&#123; value=timeStampToDate(value,"yyyy-MM-dd HH:mm:ss"); &#125; return value; &#125; private static String timeStampToDate(String time,String timeFormat) &#123; Long timeLong = Long.parseLong(time); SimpleDateFormat sdf = new SimpleDateFormat(timeFormat);//要转换的时间格式 Date date; try &#123; date = sdf.parse(sdf.format(timeLong)); return sdf.format(date); &#125; catch (Exception e) &#123; return null; &#125; &#125; private static boolean isMobile(String mobile) &#123; return Pattern.matches(REGEX_MOBILE, mobile); &#125;&#125; 单元测试设计等价类设计 等价类划分 有效等价类 无效等价类 key 包含time, 包含ipone,包含time和ipone 不包含time 和ipone value 时间戳，手机号，带区号的手机号 不是时间戳，也不是手机号 我们根据这个来设计测试用例|key|value |预期值||–|–|–||字段包含time | 时间戳 | 返回日期格式的的字符串 || 字段包含time | 不是时间戳 | null || 字段包含ipone |不是手机号 | null || 字段包含ipone |是11位的手机号 | 返回11位手机号字符串 ||字段包含ipone | 是手机号，但位数大于11位 | 返回11位手机号字符串|| 字段包含time,ipone |时间戳 | 返回日期格式的的字符串||字段包含time,ipone |不是手机号，也不是时间戳 | null ||字段包含time,ipone| 手机号| null||字段不包含time 和ipone |时间戳| 时间戳字符串||字段不包含time 和ipone |11位手机号| 手机号字符串||字段不包含time 和ipone |大于11位手机号 |返回值字符串||字段不包含time 和ipone| 不是手机号，也不是时间戳 |值对应字符串 | 编写测试用例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class DataHandleTest &#123; DataHandle dataHandle = null; @Before public void setup() &#123; dataHandle = new DataHandle(); &#125; @After public void tearDown() &#123; dataHandle = null; &#125; @Test public void testFieldDataHandle_包含time是时间戳_返回日期字符串()&#123; assertEquals("2019-09-10 19:02:30", dataHandle.fieldDataHandle("atime","1568113350000")); &#125; @Test public void testFieldDataHandle_包含time不是时间戳_返回NULL()&#123; assertNull(dataHandle.fieldDataHandle("atime","1568113350aaa")); &#125; @Test public void testFieldDataHandle_包含ipone不是手机号_返回NULL()&#123; assertNull(dataHandle.fieldDataHandle("bipone","aaa")); &#125; @Test public void testFieldDataHandle_包含ipone是11位手机号_返回手机号字符串()&#123; assertEquals("13265459362",dataHandle.fieldDataHandle("bipone","13265459362")); &#125; @Test public void testFieldDataHandle_包含ipone是大于11位手机号_返回手机号字符串()&#123; assertEquals("13265459362",dataHandle.fieldDataHandle("bipone","+8613265459362")); &#125; @Test public void testFieldDataHandle_包含time和ipone是时间戳_返回NULL()&#123; assertNull(dataHandle.fieldDataHandle("atimebipone","1568168656000")); &#125; @Test public void testFieldDataHandle_包含time和ipone是手机号_返回手机号字符串()&#123; assertEquals("13265459362",dataHandle.fieldDataHandle("atimebipone","13265459362")); &#125; @Test public void testFieldDataHandle_包含time和ipone不是时间戳手机号_返回NULL()&#123; assertNull(dataHandle.fieldDataHandle("atimebipone","aaabbb")); &#125; @Test public void testFieldDataHandle_不包含time和ipone是时间戳_返回时间戳字符串()&#123; assertEquals("1568114439",dataHandle.fieldDataHandle("ccc","1568114439")); &#125; @Test public void testFieldDataHandle_不包含time和ipone是11位手机号_返回时间手机号字符串()&#123; assertEquals("13112341234",dataHandle.fieldDataHandle("ccc","13112341234")); &#125; @Test public void testFieldDataHandle_不包含time和ipone是大于11位手机号_返回值字符串()&#123; assertEquals("+8613412341234",dataHandle.fieldDataHandle("ccc","+8613412341234")); &#125; @Test public void testFieldDataHandle_不包含time和ipone不是时间戳手机号_返回值字符串()&#123; assertEquals("abcdefg",dataHandle.fieldDataHandle("ccc","abcdefg")); &#125;&#125; 然后我们执行一下测试用例；可以看到有一个地方的测试用例是不通过的，那就说明有问题，我们看一下。 1234@Test public void testFieldDataHandle_包含time不是时间戳_返回NULL()&#123; assertNull(dataHandle.fieldDataHandle("atime","1568113350aaa")); &#125; 这个是抛异常了，因为日期格式转换错误，但是我们在日期转换的时候已经捕获了呀，并且返回为null 。那为什么测试用例没有通过呢，而是直接抛异常出来了，调试发现这个方法没有捕获到异常，而是直接抛出给Junit了。所以这里提示代码不能这么写。一般异常了不建议返回null.而是打印出异常把信息抛出。这里我们就不改了。我们将测试用例改一下，在测试用例中捕获一下异常。改成如下： 1234@Test(expected = NumberFormatException.class) public void testFieldDataHandle_包含time不是时间戳_throwsException()&#123; dataHandle.fieldDataHandle("atime","1568113350aaa"); &#125; 再全部执行一下这样就不抱错了。好啦这个就是一个简单的测试用例啦。 总结最后总结一下吧，我觉得应该知道以下几点 认识到单元测试的必要性 好的测试用例是关键 测试用例中断言必不可少 编写测试用例的规范要遵循 看到这啦的小伙伴，如果觉得喜欢就点个赞吧嘿嘿。如果有什么意见，欢迎给我提。嘿嘿。后续想写一下测试用例的规范，喜欢的可以持续关注❤ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>单元测试</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Junit</tag>
        <tag>单元测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内网穿透ngrok_ngrokcc_cpolar]]></title>
    <url>%2F20190905%2F%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8Fngrok_ngrokcc_cpolar.html</url>
    <content type="text"><![CDATA[前言先来说说问题吧，我们的项目在测试环境上搭建好了，也就是在内网上可以正常运行，但是呢，局方的人想要看一下效果先，那问题就来了，不在同一个局域网，他们访问不了我们的内网啊，现在又想看。这咋整。所以就有了这篇文章。这三个软件都差不多，都有一个免费的，我自己都试了一下，window和Linux的都可以，做演示的话问题不大。刚刚好满足要求。 官网ngrok:https://ngrok.com/ngrokc:http://www.ngrok.cc/cpolar:https://www.cpolar.com/ 大家对着官网教程来就可以了，无非都是注册会员，领取那个免费的authtoken.然后下载客户端，设置端口，启动项目，用域名进行访问。 说明1、ngrok 和 cpolar 基本用法都是一致的，都是生成一个authtoken ,然后设置一个ip和端口，会随机的生成一个http的域名和一个https 的域名随机访问。2、ngrokcc 是国内的一个网站，没有authtoken ,但是有隧道，需要你在控制台建好隧道，然后在客户端连接隧道id 就好了 1./sunny clientid 隧道id 总结使用起来还是比较简单，能满足我们将项目搭建在本地，用公网访问演示。 番外这几个是三个软件都是利用Nginx反向代理实现的。但是免费的只有一个隧道或者一个端口，这个时候我们可以在自己本地再搭建一个Nginx做虚拟主机，这样就可以自由飞翔了吧哈哈 再番外因为看了一下官方文档，发现不仅可以代理一个端口网站，还能代理tcp协议。 我来举一个例子。我有两台电脑，一台装的是win ,一台装的是Ubuntu，一般我都是把Ubuntu当做服务器用。两台电脑在同一个局域网直接用xhell 的ssh 连接起来当然很方便啦。但是我有时候需要把win 带到其他地方，那做服务器的那台电脑就不能访问啦，所以我参考一下官网的，可以在用外网访问这台服务器啦。操作也很简单，我三个也都测试了一下，用的是cpolar 的，感觉比ngrok 要稳定些。1、在我们Ubuntu服务器上安装好cpolar客户端，然后认证tocken 这些和之前是一样哒。2、 1cpolar tcp 22 就这么简单。 然后在主机和端口号填上对应的就好了，就是这么简单。 这样之后，就算两台电脑不在同一个局域网，也可以直接访问了，很实用。 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>建站之路</category>
      </categories>
      <tags>
        <tag>内网穿透</tag>
        <tag>ngrok</tag>
        <tag>ngrokcc</tag>
        <tag>cpolar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[八、redis集群]]></title>
    <url>%2F20190903%2F%E5%85%AB%E3%80%81redis%E9%9B%86%E7%BE%A4.html</url>
    <content type="text"><![CDATA[前言前面写完了 Redis 的主从复制、哨兵模式、Redis 持久化方式。这篇文章开始写 Redis 集群啦。 我们项目中使用 Redis 一般都不是使用单台 Redis 提供服务，除非是很小的项目，不过很小的项目也没有必要使用Redis了。所以一般使用 Redis 都会配上 Redis主从备（就是前面将的主从复制），配上哨兵模式实现故障转移。更大的项目就搭建一个 Redis 集群。 但是呢，我们大多数在项目中即使使用了 Redis ，都是直接使用的，框架什么的都已经被前面的人搭建好了。所以我们在使用的时候其实就是配置的时候有些不同，代码中使用起来和单机的 Redis 是没有什么区别的。所以并不能说我们对 Redis 集群有多了解。 所以接下来，就让我们来了解一下 Redis 集群吧，手把手搭建一个 Redis 集群 ，让我们对 Redis 集群有更多的了解 。 什么是 Redis 集群进入正文啦，既然学习 Redis 集群，那什么是 Redis 集群呢？ Redis 集群是 Redis 提供的分布式数据库方案，集群通过分片( sharding )来实现数据共享，并提供复制和故障转移。 可以说上面这句话是对 redis 集群的高度概括了，redis 集群提供分布式数据库方案，前面我们将的主从复制和哨兵模式可以知道，只会有一个主服务器( master )。主从复制，只会有一个 master ，可以有多个 slave。而哨兵模式是在主从复制的基础上，发现 master 挂掉，会自动的将其中一个 salve 升级成 master 。但是最终结果还是只有一个 master。所以如果系统很大，对Redis 写操作的压力就会很大，所以才出现的集群的模式。集群模式可以有多个 master 。来看下面集群模式的图(下面的图不是最终版，便于理解的。后文有最终版的)：手动画的可能有点丑，但是大概的意思就是这样啦。单个节点就是我们之前了解的主从复制的一主多从(图中是一主两从)，加上哨兵模式，来监听节点的 master 是否正常。 那集群就是多个节点组成的，多个节点的 master 数据共享，横向分担单个节点 master 的压力。那从上图可以看出 哨兵模式 其实是 集群模式的一个子集，集群模式是哨兵模式的一个拓展。 Redis 集群有什么好处，用在哪些场景上面讲了什么是 Reids 集群，那为什么要使用 Redis 集群呢，不直接使用哨兵模式呢？使用 Redis 集群有什么好处呢？ 要回答上面这个问题，其实在上一节已经差不多介绍了，集群模式是哨兵模式的一种拓展，既然是拓展，当时是因为哨兵模式不能满足需求才会产生的。 在没有Redis 集群的时候，人们使用哨兵模式，所有的数据都存在 master 上面，master 的压力越来越大，垂直扩容再多的 salve 已经不能分担 master 的压力的，因为所有的写操作集中都集中在 master 上。所以人们就想到了水平扩容，就是搭建多个 master 节点。客户端进行分片，手动的控制访问其中某个节点。但是这几个节点之间的数据是不共享的。 并且如果增加一个节点，需要手动的将数据进行迁移，维护起来很麻烦。所以才产生了 Redis 集群。 所以 Redis 集群有什么好处，就是进一步提升 Redis 性能，分布式部署实现高可用性，更加的稳定。当然还包含主从复制的数据热备份以及哨兵模式的故障转移等有点啦。 那 Redis 集群用在哪些场景呢？ 其实我感觉一般较大的项目使用了 redis 的话，都会使用 redis 集群。毕竟在部署的时候先做好充分的拓展准备，比到时候项目出现瓶颈再去拓展成本就要小太多了。并且 Redis 是轻量级的，采用 redis 集群，也许在项目初期根本就用不上多个节点，单个节点就够用，多节点造成浪费。但是其实我们启动多个节点没有用到的话，节点所占用的内存和CPU 是非常小的。所以建议一般项目使用 Redis的话，尽量使用 Redis 集群吧。 集群的主从复制和故障转移Redis 集群的主从复制，其实和单机的主从复制是一样的。前面 Redis 集群结构图可以看到。单个节点中有一个 master 和多个 slave 。这些 slave 会自动的同步 master中的数据。注意的是，这些 salve 只会同步 所属的 master 中的数据，集群中其他的 master 数据是不会同步的。 同样的 ，当个节点中可以配置多个哨兵，来监控这个节点中的master 是否下线了，如果下线了就会将这个节点的slave 选择一个升级成 master 并继承之前 master 的分片，继续工作。 但是其实啊，在集群模式中，并没有配置哨兵，我们也能实现故障的自动转移。其实真正的集群的图是这样的：如图可以看到并没有为每个节点配置 sentinel 。那怎么实现对 master 的监听，实现故障的自动转移呢？ 我们在讲哨兵模式的时候说过，其实哨兵也是一种特殊的 redis 服务对吧。我们master 是通过 redis-server 启动的。我们哨兵是通过 redis-sentinel启动的。然后哨兵的作用就是定期的给 master 发送 ping检测 master 是否下线，然后通过选举的方式选择 slave 升级成 master那放在集群中可以发现，哨兵的这些工作，完全可以交给master 来做。之前单个节点，master 做不了才交给 sentinel 的。现在有多个 master ，当然就可以用 master 来代替salve 的工作啦在集群中，每个节点的master 定期的向其他节点 master 发送 ping命令，如果没有收到pong 响应，则会认为主观下线，并将这个消息发送给其他的 master。其他的 master 在接收到这个消息后就保存起来。当某个节点的 master 收到 半数以上的消息认为这个节点主观下线后，就会判定这个节点客观下线。并将这个节点客观下线的消息通知给其他的master。这个客观节点下线后，其他的 master 节点 就会选举 下线的master中的 slave 一个变成 新的master 继续工作。从而实现故障自动转移。这个选举过程和哨兵模式中是一样的，只不过是 master 代替了 sentinel 的工作。 搭建一个 Redis 集群的实例好接下来让我们一起来搭建一个集群模式吧，因为我只有一台服务器，所以我集群就搭建在一台服务器上，在实际项目中肯定是多台服务器搭建集群的。但是搭建的方式都是一样的。这里我将两种集群的搭建方式，第一种是手动的搭建集群，手动分片，这种方便我们对集群有更多的了解，第二种的话借助 Redis 自带的辅助工具来搭建集群，方便快捷。 方式一好了，让我们开始吧，在开始之前，我们不用觉得搭建集群很麻烦，其实一样的是修改redis.conf配置文件中的内容。只需要将配置文件中集群模式打开就可以了。如下：1cluster-enabled yes 是不是很简单，还是不说废话的，搞起来。 准备工作先创建一个 cluster 目录，然后在 cluster 目录下创建6个文件夹。因为的演示中我的cluster 目录已经占用了，我就再创建是cluster2 目录。 123456789cd /usr/local/redis/etcmkdir cluster2cd cluster2mkdir 8000mkdir 8001mkdir 8002mkdir 8003mkdir 8004mkdir 8005 然后将redis.conf文件copy到这六个文件中。 123456cp ~/workSpace/redis-4.0.9/redis.conf ./8000/redis.confcp ~/workSpace/redis-4.0.9/redis.conf ./8001/redis.confcp ~/workSpace/redis-4.0.9/redis.conf ./8002/redis.confcp ~/workSpace/redis-4.0.9/redis.conf ./8003/redis.confcp ~/workSpace/redis-4.0.9/redis.conf ./8004/redis.confcp ~/workSpace/redis-4.0.9/redis.conf ./8005/redis.conf 修改配置文件准备工作做好了，现在我们来修改这六个目录下的配置文件吧。都将开启集群模式。 1vim ./8000/redis.conf 修改配置文件如下，我们为了方便就先不进行太复杂的配置，我们就配置搭建集群最小力度修改。 12345port 8000daemonize yescluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000 上面修改的是8000这个目录下的redis.conf ，接下来我们按部就班的把其他几个文件中的配置也进行修改。和上面的基本一样。这里就不一一写出来了。贴一个8002的修改，大家就一目了然了。 12345port 8002daemonize yescluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000 启动修改好这几个配置文件后，然后就启动这些服务 1234567891011121314151617cd /usr/local/redis/etc/cluster2/8000/redis-server ./redis.conf cd /usr/local/redis/etc/cluster2/8001/redis-server ./redis.conf cd /usr/local/redis/etc/cluster2/8002/redis-server ./redis.conf cd /usr/local/redis/etc/cluster2/8003/redis-server ./redis.conf cd /usr/local/redis/etc/cluster2/8004/redis-server ./redis.conf cd /usr/local/redis/etc/cluster2/8005/redis-server ./redis.conf 如下图：上图可以看到，会先进入到对应的文件夹，然后启动redis服务，为什么要先进入对应的文件夹呢？因为我们配置了cluster-config-file nodes.conf 这个会在你启动目录下生成一个node.conf 文件，用来存放当前节点信息。所以你不先进入对应目录的话，很很可能就启动不成功哟。下图可以看到生成了 node.conf 以及里面的内容。我们在来通过线程的方式查看一下 1ps -ef |grep redis 可以发现我们启动的6个节点都已经启动了，并且后面都带有 cluster 的标识。和 6379 单机模式有区别。 节点互通到此准备工作算是真正的做完了，我们启动了六个节点，但是现在这六个节点是相互独立的，没有任何关联，那我们怎么将它们关联起来呢？我们先用客户端进入到8000节点。查看一下节点信息 12redis-cli -p 8000cluster nodes 可以看到只有自身这个节点的信息。现在我们和其他节点建立连接 1cluster meet ip port 下图可以看我们和8001节点建立连接，这个时候再查看nodes节点信息，发现就有两个节点信息啦，说明这个集群中现在存在了8000 和8001 两个节点。我们现在把8002 节点也加进来。这样原本的各自独立的节点就在同一个集群中啦，大概就是下面这张图（有点丑，将就看） 槽指派上面已经进行了节点互通了，多个节点在同一个集群中了，那我们是不是就可以使用集群了呢？其实不行，我们来看一下cluster info发现 cluster_status 还是fail。表明还是不可用的。因为我们还没有进行卡槽的分派。Redis 集群是通过分片的方式来保存数据库中的键值对的，集群整个数据库被分成16384个槽（slot）。也就是说所有数据的key都会映射到对应的 slot 中。只有当数据库中16384 个槽都在节点上有分派，集群才会上线，否则集群的状态就是 fail。所以接下来开始槽指派吧 12345cluster addslots slots[slots]样例：cluster addslots 0 1 2 cluster addslots 0 1 2 ... 5000cluster addslots &#123;0..5000&#125; 网上说的可以支持范围分配的，但是我电脑上试了 N 种方法都不行，我的 redis 版本是4.0.9 的。最后没办法，写了一个脚本跑的。如果大家也不行的话，可以用脚本跑吧。 123456789start=$1end=$2port=$3for slot in `seq $&#123;start&#125; $&#123;end&#125;`do echo "slot:$&#123;slot&#125;" redis-cli -p $&#123;port&#125; cluster addslots $&#123;slot&#125; done~ 然后执行： 123sh add-slots.sh 0 5000 8000sh add-slots.sh 5001 10000 8001sh add-slots.sh 10000 16384 8002 这样就可以把16384个卡槽分配到三个节点上啦，如果有多个节点，自己调整分配哈，我这里是以三个节点为例的。 卡槽分配完成以后，我们在来看看 cluster 的状态发现 cluster_status 变成 ok 了。说明我们的卡槽分配是成功的。 验证那现在集群上线了，是不是就可以用了呢?答案是是的，但是配到现在为止还有点瑕疵，瑕疵我们待会再说，先来看看集群能不能操作命令。可以看到，进行槽指派之后是可以进行正常的操作的，这里的set a 123提示我移动到8002端口执行。因为a 对应的卡槽为15495.这里有一个命令和可以查看key值在哪一个卡槽，从而属于哪一个节点。 123127.0.0.1:8000&gt; CLUSTER KEYSLOT a(integer) 15495127.0.0.1:8000&gt; 那假如我就想set a 呢，难道要先切换到8002端口，那岂不是很麻烦，还有另一种方法： 1redis-cli -c -p 8000 可以看到这样启动客户端，会自动的将数据存入到对应的节点上，并切换到这个节点，并且之前我在8000 端口上set data 123,我现在在8002端口上get data 会自动的找到key值并切换到8000端口上，这样在客户端就感觉这三个节点是一个整体啦，是不是很方便。 配置主从前面为止，集群模式已经搭建好了，但是呢前文说的还有点瑕疵，现在就来说说，我们现在搭建的集群只有三个主节点，任何一个主节点挂掉了，就会导致集群不可用，因为集群可用的标志是 16384 个卡槽全部都分配到可用的节点上。所以我们现在搭建的集群还是不稳定的。所以为了解决这个问题，我们需要为每一个主节点配置一个从节点。从节点的作用是数据热备份和当主节点出现故障时可以替代主节点进行工作。 好了，我们来搭建主从吧，前文中我们创建了6个节点，还有三个没用，其实就是用来搭建主从的哈哈。还没有用到的这三个节点 和搭建好的这个集群是独立的现在。第一步，将这三个节点加入到集群中来。 123cluster meet 127.0.0.1 8003cluster meet 127.0.0.1 8004cluster meet 127.0.0.1 8005 第二步，查找主节点的 nodesId。通过 cluster nodes可以查到到集群中所有节点的信息，第一列就是每个节点的nodesId.第三步，将从节点和主节点关联起来。 123redis-cli -p 8003 cluster replicate 9a86d899be55a37d3ac1c8be6c342c7f59513076redis-cli -p 8004 cluster replicate 03efbb8782a705d5978f5c1b14d4dcba14a167e8redis-cli -p 8005 cluster replicate 01f6c1888b7a103c10fffe9cf6be8a5fff8ae985 我们再来看看节点信息可以看到从节点已经搭建成功啦，那到底有没有成功呢，我们再来试试，我们手动模拟主节点8000故障了。我们用shutdown可以关闭当前节点的服务。看一下进程确定8000已经关闭了我们现在进入8001端口看一下，get data可以看到切换到8003端口上了，8003端口是8000端口的从节点，现在8000端口挂掉了，8003端口会代替8000端口继续工作。我们看一下cluster nodes 发现8000端口节点是 fail 的，8003端口升级成master了。我们现在修复了8000端口问题，将其重启起来看看。 1234quellanan@quellanan-Lenovo-G400:/usr/local/redis/etc/cluster2/8000$ redis-server ./redis.conf 26401:C 03 Sep 10:13:31.777 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo26401:C 03 Sep 10:13:31.777 # Redis version=4.0.9, bits=64, commit=00000000, modified=0, pid=26401, just started26401:C 03 Sep 10:13:31.777 # Configuration loaded 然后看看节点信息，发现8003端口变成了主节点，8000端口变成了8003端口的从节点。这和我们之前哨兵模式是一样的。好啦，到此为止，一个集群算是真正的搭建好啦。一步一步的来，不难，就几个命令而已，可能我写得比较啰嗦嘿嘿。 方式二准备工作第二种方法搭建集群就简单讲啦，准备工作和启动都是一样的，只是不用我们自己进行节点互通和分配卡槽啦。如下图，我已经启动 7000~7005 六个节点。 安装软件123yum install rubyyum install rubygemsgem install redis 我这里已经安装好了，就不演示啦。 配置执行以下命令，就会自动的帮我们进行节点互通，分配卡槽以及设置从节点。1./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 特别提醒，这里的IP用主机的IP，如果使用127.0.0.1的话，在我们代码中访问会出错，我也是在项目中使用的时候碰到的上面就已经搭建好集群啦，简单吧。 验证我们现在简单验证一下，进入7000节点； 1redis-cli -c -p 7000 可以看到集群是上线状态，可以正常使用啦，我们简单操作一波好啦，集群搭建的实例就说这么多吧，两种方式，第一种是原生的，第二种是借助工具的，效果是一样的。还有一个内容就是重新分片。这个用到的不多，我们前期在搭建集群的时候先预留多个节点就好，不然后面要扩容，就需要用到重新分片，感兴趣的可以在讨论区讨论下吧，也不难，这里就不写了(文章太长啦)。 在项目中使用集群在项目中使用集群，我这里就简单的给一个样例给大家参考。 创建一个springboot 项目基本上一直next 就好了。 修改pom.xml文件12345678910111213141516171819202122232425262728293031&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Redis使用starter--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--注解日志/get/set--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.sf.json-lib&lt;/groupId&gt; &lt;artifactId&gt;json-lib&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;classifier&gt;jdk15&lt;/classifier&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 修改application.yml123456789101112131415161718server: port: 9090# redis 集群配置spring: redis: cluster: nodes: 192.168.252.53:7000,192.168.252.53:7001,192.168.252.53:7002,192.168.252.53:7003,192.168.252.53:7004,192.168.252.53:7005 timeout: 6000ms # 连接池超时时间（毫秒） # 密码没有可以不填 password: database: 0 # 数据库索引 lettuce: pool: max-active: 8 # 连接池最大活跃连接数（使用负值表示没有限制） max-idle: 8 # 连接池最大空闲连接数 max-wait: -1ms # 连接池最大阻塞等待时间 毫秒（使用负值表示没有限制） min-idle: 0 #最小空闲连接数 配置dao层这个样例是我写的另一篇博客样例改编过来的，大家不知道项目结构的可以看一下我这篇博客中样例的项目结构。Redis在SpringBoot中使用案例创建dao 包，创建一个User 类,这里使用了lombok提供的@Getter 和@Setter 非常方便，代码看着也很简洁。 1234567891011121314151617181920@Getter@Setterpublic class User implements Serializable &#123; private static final long serialVersionUID = 1L; private Long id; private String userName; private String password; private String email; private String nickname; private String regTime; public User(String email, String nickname, String password, String userName, String regTime) &#123; super(); this.email = email; this.nickname = nickname; this.password = password; this.userName = userName; this.regTime = regTime; &#125;&#125; 创建service层创建一个service 包，创建一个RedisService类，代码如下： 12345678910111213141516171819202122232425262728@Service@Slf4jpublic class RedisService &#123; @Autowired private StringRedisTemplate stringRedisTemplate; public boolean setUserBystringRedisTemplate(User user)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); ops.set(user.getNickname(),JSONObject.fromObject(user).toString()); return true; &#125; public String getUserBystringRedisTemplate(String name)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); return JSONObject.fromObject(ops.get(name)).toString(); &#125; public boolean setString(String key,String value)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); ops.set(key,value); return true; &#125; public String getString(String key)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); return (String)ops.get(key); &#125;&#125; 创建Controller层创建一个controller 包，创建一个RedisController类代码如下： 12345678910111213141516171819202122232425262728293031@RestControllerpublic class RedisController &#123; @Autowired private RedisService redisService; @RequestMapping("/setUser") public String setUser()&#123; User user=new User("aa@qq.com","quellan","123456","朱",new Date().getTime()+""); redisService.setUserBystringRedisTemplate(user); return "添加成功"; &#125; @RequestMapping("/getUserByStringRedisTemplate") public String getUserByStringRedisTemplate()&#123; String name="quellan"; return redisService.getUserBystringRedisTemplate(name); &#125; @RequestMapping("/setString") public String setString(String key ,String value)&#123; redisService.setString(key,value); return "添加成功"; &#125; @RequestMapping("/getString") public String setString(String key)&#123; return redisService.getString(key); &#125;&#125; 测试到此为止，代码就已经写完啦，我们来启动项目测试一下。项目启动成功之后，我们调接口看看 1234567http://localhost:9090/setString?key=a&amp;value=123http://localhost:9090/setString?key=b&amp;value=1qazhttp://localhost:9090/setString?key=data&amp;value=wsxcdhttp://localhost:9090/getString?key=ahttp://localhost:9090/getString?key=datahttp://localhost:9090/setUserhttp://localhost:9090/getUser 我就截图看其中两个界面上没有问题啦，我们再用客户端看一下。 1redis-cli -c -p 7000 数据在集群中正常的读取是没有问题哒。 好了，在项目中简单使用集群就讲到这里啦，源代码我github上了，感兴趣的同学可以看下。demo源代码 总算写完了，可能写的不是很好，大家有疑问的，可以提出来，我知道的尽量给大家解答，谢谢大家！ 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七、Redis持久化的两种方式RDB和AOF理解]]></title>
    <url>%2F20190822%2F%E4%B8%83%E3%80%81Redis%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8FRDB%E5%92%8CAOF%E7%90%86%E8%A7%A3.html</url>
    <content type="text"><![CDATA[前言前面将了redis的主从复制以及怎么搭建，还介绍了哨兵模式以及哨兵模式的搭建。虽然操作跟上了，但是还是补一下redis的持久化。redis之所以这么流行，很大一部分原因便是持久化，断电重启数据不消失，使得redis在数据库领域中站稳了脚。前文将的主从复制其实就是依赖持久化的，如果没有持久化，这些数据都不会从主服务器备份到从服务器。下文我们就讲讲redis的持久化。 说起redis持久化，大家或多或少都知道一些，简单点一句话也能概括。redis通过RDB和AOF方式将数据存入磁盘，实现持久化。RDB是定期生成快照存入磁盘中，AOF是将写操作存入磁盘中。二者各有优劣，RDB 是存放数据库中数据，适合做数据备份，但是数据可能不全，最近几分钟的数据可能没有。AOF是每秒中执行一次，如果有写操作的命令就存储起来，最多只会丢失1秒钟的数据，适合做数据恢复。但是这个就不适合做数据备份了，并且由于每秒都会执行多多少少会抢占redis的内存，会影响性能。但是在实际应用中是二者是配合使用的。 下面就来具体的讲讲RDB和AOF吧 RDBRDB 的全称是 redis database. 顾名思义，RDB就是将redis数据库，用来存储数据的，所以通过RDB方式持久化就是将存在redis内存中的数据写入到RDB文件中保存到磁盘上从而实现持久化的。RDB文件是一个压缩的二进制文件，通过这个文件可以还原redis数据库的数据，从而达到数据恢复的目的，借用一下《redis设计与实现》讲的这张图，途中数据库状态可以理解为redis内存中存储的数据。既然RDB持久化的方式是生成RDB文件，那么这个RDB文件是怎么生成的呢？RDB文件生成的方式有两种，一种是通过命令手动生成快照，还有一个是通过配置自动生成快照。下面我们来分别看看。 通过save和bgsava命令生成RDB文件这两个命令都是可以直接运行的。 save命令，会阻塞服务器进程，只有当RDB文件生成成功才会接着响应服务端的其他命令。而bgsave ，既然有这个命令，肯定是和save有所不同的，bgsave 不会阻塞服务器进程，会创建一个子进程来创建RDB文件但是注意的是使用bgsave命令的时候，虽然是通过子进程生成RDB文件，不会阻塞服务进程，其他的命令可以执行，但是有几个命令是不能执行的。 123save bgsavebgrewriteaof 在bgsave 期间 服务器拒绝这三个命令，主要是方式线程间竞争产生问题。 通过配置文件自动生成RDB初了手动执行这两个命令外，还可以在配置文件中配合参数，达到条件的时候就会自动的生成RDB打开我们的配置文件redis.conf,找到如下图，这个是默认的配置。 1234567save 900 1 表示在900秒内，如果发生了一次写操作，就触发bgsave命令生成RDB同理 save 300 10 在300秒内，发生了10次写操作，就触发bgsavesave 60 10000 在60秒内发生了10000次写操作，就触发bgsave 上面的这些可以进行配置，可以看到默认的设置，如果短时间内发生大量的写操作就会自动的触发bgsave ,生成RDB文件， 防止数据丢失。 好了，上面虽然说达到这三个条件中的一个，redis就会自动的生成RDB文件，那系统是怎样控制，又是怎样识别是否满足条件呢？原来啊，服务器维持了一个dirty 计数器，以及一个lastsave属性。dirty 计数器记录着从上次save/bgave 到现在发生了多少次写操作，没进行一次写操作，计数器就加1比如 12345set a 123计数器dirty 加1 set a 123 b 234 c 456计数器dirty 加3 而lastsave 是unix时间戳，记录上次save或bgsave的时间。有了这两个属性，就可以判断什么时候执行啦，redis服务器会周期性的执行serverCron函数,默认的话是每100毫秒执行一次。这个serverCron 函数先通过当前时间减去lastsave 获取时间间隔。如果dirty 大于 saveparm.chranges并且时间间隔大于saveparm.seconds那么就会触发bgsave 生成 RDB文件 其中saveparm.seconds 和saveparm.chranges 分别对应的是配置文件中设置的save 900 1等。 既然生成了RDB文件，我们只知道RDB是一个压缩的二进制文件，那RDB文件到底结构是什么样的呢？我看了一下《redis 设计与实现》没有怎么看明白哈哈，感兴趣的可以去看看。 RDB方式就讲到这里了，记住RDB方式，是定时的执行bgsave 命令生成RDB文件保存在磁盘上实现持久化的。适合数据备份，用于数据恢复可能会丢失最近几分钟的数据。 AOF全称是append only file. AOF 持久化的方式是通过redis服务器记录保存下所有的写命令到AOF文件存放在磁盘上，实现持久化的，看下图：怎样采用AOF的方式持久化呢？打开我们的配置文件，在配置文件中找到appendonly 改成yes 就可以采用AOF的方式备份了我们启动redis服务，为了测试方便，我们新启的一个redis服务，数据库中没有任何key我们看看appendonly.aof 也是没有任何东西的。现在我们存入一个key然后我们来看下aof文件的内容：可以看到，初了一些$3等一些特殊符号外我们可以看到我们执行的命令。 12select 0set a bbb 但是我们一些读操作的就不会记录。由此可见，AOF 持久化就是将所有的写操作存入AOF文件中，当数据恢复的时候，执行AOF文件中的命令就可以获取数据了。 我们接着来看那，我向数据库中先加一个key b ,然后删除key a .好了，现在我们再来看看aof 文件中是什么情况。可以看到命令有： 1234select 0set a bbbset b ddddel a 所以aof 文件中包含了这四条命令，到这大家有没有发现一个问题，如果我重复的对某一个key值进行操作，那么aof文件中就会记录所有的操作命令，但是实际上只有最后一次操作才是有效的，那这个aof文件中是不是就有很多冗余的数据呢？ 实际上是这样的，那怎么解决这个问题呢？这里就要提到一个命令啦 1BGREWRITEAOF 和RDB中的save 以及bgsave 是类似的。不过bgrewriteaof 命令的作用是重写aof文件，为什么要重写呢，就是为了解决aof文件中冗余的问题。我们先来手动执行一下这个命令然后看看aof 文件中的内容可以看到命令变成了 12select 0set b ddd 重写之后，aof的文件里的命令就是有效的啦，但是我们总不能自己手动执行bgrewriteaof 命令吧，那我们在哪里配置呢?在redis.conf 配置文件中有这两个参数。 auto-aof-rewrite-percentage 100 当Aof log增长超过指定比例时，重写log file， 设置为0表示不自动重写Aof 日志，重写是为了使aof体积保持最小，而确保保存最完整的数据。 auto-aof-rewrite-min-size 64mb 触发aof rewrite的最小文件尺寸 也就是说在实际应用中，如果开启了aof 备份，可以设置这两个参数来重写AOF文件。 好了上面说了那么多，那redis服务怎么通过aof文件来恢复数据的呢？其实很简单，就是将aof 文件中的命令一条一条的读取出来执行。看下图 最后再说一点嘿嘿。我们在配置文件中同时启用了RDB 和AOF ,那么服务启动的时候，会在用那个文件来回复数据呢？看下面这张图。可以看到如果启动aof ,就会采用aof 文件来回复数据，这是为什么呢，因为AOF 文件更新的频率更高，模式一秒中一次，所以用AOF 恢复的数据更加准确。 好了，只有这么多了哈哈，推荐大家看看《redis 设计与实现》也不建议大家从头往后看，调感兴趣的看吧，毕竟里面还是有很多原理对我们而言也不是一定非得弄懂的，大概了解一下就行，我比较懒哈哈。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[六、主从复制原来这么简单]]></title>
    <url>%2F20190821%2F%E5%85%AD%E3%80%81%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%8E%9F%E6%9D%A5%E8%BF%99%E4%B9%88%E7%AE%80%E5%8D%95.html</url>
    <content type="text"><![CDATA[什么是redis主从复制总所周知redis之所以火因为它有着读取速度快，可持久化的优点。redis的持久化保证了断电或重启数据不会丢失。但仅仅这样是不够的的，持久化是将数据定期写入磁盘中，万一哪一天这一台服务器挂掉了，那所有数据依旧会丢失。为了解决这个单点故障问题，所以就有了主从复制。 主从复制就是 将一台redis服务器的数据自动的复制到其他redis服务器上。 一台服务器出故障的概率很高，但是多台服务器同时出故障的概率就很低了吧。所谓主从主从，当然是有主服务器 (master) 和从服务器 (slave) 啦，一个 master 可以将数据复制到多个 slave，但是特别注意的是，复制是单向的，只能从 master 到 slave 。一个master 可以有多个 slave ，一个slave 也可以有多个slave ,但是一个 slave 只能从属一个master 。如下图这样就是错误的。 主从复制的作用及场景1、数据冗余： 主从复制实现了数据的热备份，相当于一份数据在多个服务器上存储了，是持久化之外的一种数据冗余方式，这样做的目的是以空间换取安全性。如果主服务器挂掉了，可以通过从服务将数据恢复。 2、故障快速修复：当 master 出现问题的时候，可以快速的将一个 slave 切换成 master 继续提供服务 ，保证项目稳定性。 3、读写分离： 主从复制实现读写分离非常简单，写入的时候只操作 master ，读取的时候只操作 slave ，这样读的话可以多个slave 满足项目高并发的操作。 4、负载均衡：既然实现了读写分离，当然就能实现负载均衡，多个 slave 承担 数据读取操作 ，从而分担 master 服务器的压力。 5、高可用的基石：主从复制还是哨兵模式和集群模式能够实施的基础。 既然主从复制有这些作用，那在实际应用中会用在哪些场景呢？ 1、如果项目对数据安全性稳定性要求较高，就会使用主从复制搭建哨兵模式或者搭建集群。 2、海量数据读写，需要做读写分离提高防蚊效率，就会用到主从复制 3、容灾恢复，如果对数据依赖度很高，害怕数据在服务器挂掉后丢失，就可以通过主从复制防止数据丢失。 主从复制的模式一主一从这种模式在实际应用中还是比较少见的其实，一主一从主要是实现读写分离和容灾恢复。考虑到成本的问题，所以采用两台服务器，一个redis服务器master 负责读操作，并定期的复制到 另个一服务器slave 。slave 服务器负责读写操作。在项目中配置的时候配置两个redis连接。 一主多从一主多从有可以分为几种，如下图：这种就是所有的 slave 都从 master 中 进行复制，这样的好处是 配置简单，所有的slave 都只用关系 master 就好了，但是要考虑到其实复制也是会侵占CPU内存的，所有的slave 都从 master 复制，可能增大 master的负荷。 再来看看下图：这种模式也是一主多从，但是和上面的所有的 slave 都从 master 复制不一样。它是使一个到两个slave 从master 直接复制，其他的slave 从这两个slave 中复制。存在层级关系。这样的好处的降低的master 服务器的负荷，但是这样会导致如果中间某个 slave 挂掉了，那依附于它的所有slave 都不能用了。 主从复制部署这里我使用的是Ubuntu安装的redis，redis怎么安装，可以看我这篇文章Redis安装。安装好redis后，我们启动看看是否正常 12redis-server /usr/local/redis/etc/redis.confredis-cli -a 123456 证明是redis是正常启动的，那现在怎么配置主从模式呢？按理说主次模式的redis服务器当然是搭建在不同的服务器上，但是我们条件有限，我这里的三台redis服务都搭建在一个服务器上，只是他们监听的端口不同。 1、修改redis.conf我们先修改master的配置文件redis.conf 的一些配置 123456bind 0.0.0.0 表示可以被所有机器访问。daemonize yes 表示可以后台启动port 6379pidfile /var/run/redis_6379.pidlogfile "/usr/local/redis/logs/log_redis.log"requirepass 123456 2、复制两份redis.config改好redis.conf 后，将/usr/local/redis/etc/ 目录下的redis.config 复制两份为redis_slave1.confredis_slave2.config 3、修改rdis_slave1.conf12345678910bind 本机ip 表示只能本机访问daemonize yes port 6389pidfile /var/run/redis_6389.pidlogfile "/usr/local/redis/logs/log_redis_slaveof6389.log"requirepass 123456 ---上面的这些配置和redis.conf中基本一样修改一下就好了，日志是为了方便查看。下面看重点配置slaveof 192.168.252.53 6379 设置master的ip 和portmasterauth 123456 设置master的登录密码，就是redis.conf 中配置的requirepass 4、修改redis_slave2.conf同样的12345678bind 192.168.252.53daemonize yes port 6399pidfile /var/run/redis_6399.pidlogfile "/usr/local/redis/logs/log_redis_slaveof6399.log"requirepass 123456 slaveof 192.168.252.53 6379 masterauth 123456 5、启动redis服务123redis-server /usr/local/redis/etc/redis.confredis-server /usr/local/redis/etc/redis_slaveof1.confredis-server /usr/local/redis/etc/redis_slaveof2.conf 查看一下进程 1ps -ef | grep redis 6、启动客户端都启动来了，现在连到单个redis服务器看看 12345主服务redis-cli -a 123456从服务redis-cli -h 192.168.252.53 -p 6389 -a 123456redis-cli -h 192.168.252.53 -p 6399 -a 123456 7、测试启动3台客户端，分别连上master和两个slave在master中 1set c 122 在slave1和slave2 中分别 1get c 这样就说明你的主从复制服务已经搭建好啦。 8、问题记录上面的是一个完美的过程搭建的主从复制的例子，但是我相信在实际搭建的时候肯定会出现各种问题，现在记录下我搭建的时候出现的问题吧1、权限问题在搭建好主从服务后，进入从节点查看info replication发现1master_link_status:down 表明主从节点并没有建立连接，但是但是为什么一直是down 呢，看了一下日志提示不能打开rdb这个快照，当然就不能将内容复制到从节点啦，再一看这个路径，是我自己建的路径，第一反应就是权限问题，然后进这个目录一看，发现我的etc目录是root用户的。所以就修改了文件的用户和用户组。在进到etc目录下，就发现了两个快照，再去看的时候发现down变成up 了。 1234567891011121314151617181920quellanan@quellanan-Lenovo-G400:/usr/local/redis$ sudo chown quellanan etc[sudo] quellanan 的密码： quellanan@quellanan-Lenovo-G400:/usr/local/redis$ sudo chgrp quellanan etcquellanan@quellanan-Lenovo-G400:/usr/local/redis$ ll总用量 20drwxr-xr-x 5 root root 4096 8月 8 16:50 ./drwxr-xr-x 13 root root 4096 8月 1 16:28 ../drwxr-xr-x 2 root root 4096 8月 1 16:57 bin/drwxr-xr-x 2 quellanan quellanan 4096 8月 15 09:50 etc/drwxrwxrwx 2 root root 4096 8月 15 09:16 logs/quellanan@quellanan-Lenovo-G400:/usr/local/redis$ cd etc/quellanan@quellanan-Lenovo-G400:/usr/local/redis/etc$ ll总用量 196drwxr-xr-x 2 quellanan quellanan 4096 8月 15 09:50 ./drwxr-xr-x 5 root root 4096 8月 8 16:50 ../-rw-r--r-- 1 quellanan quellanan 188 8月 15 09:50 dump6389.rdb-rw-rw-r-- 1 quellanan quellanan 188 8月 15 09:50 dump.rdb-rw-rw-r-- 1 quellanan quellanan 58810 8月 14 09:18 redis.conf-rw-rw-r-- 1 quellanan quellanan 58882 8月 14 09:16 redis_slaveof1.conf-rw-r--r-- 1 quellanan quellanan 58882 8月 15 09:11 redis_slaveof2.conf 权限问题我感觉还是挺大的，因为我们一般都是远程到服务器上操作，所以用户权限很多都需要注意。 2、还有一个也是发现master_link_status:down，但是并不是用户权限问题导致的，查看一下防火墙的状态，将防火墙关闭了试试。 123ufw status 查看防火墙状态ufw enable 开启防火墙ufw disable 关闭防火墙 3、在主节点插入数据的时候出现问题 12127.0.0.1:6379&gt; set a 1qaz(error) MISCONF Redis is configured to save RDB snapshots, but it is currently not able to persist on disk. Commands that may modify the data set are disabled, because this instance is configured to report errors during writes if RDB snapshotting fails (stop-writes-on-bgsave-error option). Please check the Redis logs for details about the RDB error. 执行这个 123456127.0.0.1:6379&gt; config set stop-writes-on-bgsave-error noOK127.0.0.1:6379&gt; set a 123456OK127.0.0.1:6379&gt; get a"123456" 主从复制的原理上面以及搭建了一个主从复制的样例，是一主两从的，那是怎么redis是怎么具体实现的呢？在将原理之前，先来看看主从复制的几个概念。启动master后 123456789101112131415161718192021127.0.0.1:6379&gt; info server# Serverredis_version:4.0.9redis_git_sha1:00000000redis_git_dirty:0redis_build_id:514e9a11b2a67dfcredis_mode:standaloneos:Linux 5.0.0-23-generic x86_64arch_bits:64multiplexing_api:epollatomicvar_api:atomic-builtingcc_version:7.4.0process_id:19688run_id:136de716105e54294144003a881ba29cdfbccfb2tcp_port:6379uptime_in_seconds:4515uptime_in_days:0hz:10lru_clock:5556386executable:/usr/local/redis/etc/redis-serverconfig_file:/usr/local/redis/etc/redis.conf 这个run_id 就是redis服务的唯一标识，重启redis服务号，这个run_id 会改变，多个redis客户端连接到同一个服务端，其run_id 是一样的，也就是说run_id 指的是服务端的id 1234567891011121314127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.252.53,port=6389,state=online,offset=5541,lag=1slave1:ip=192.168.252.53,port=6399,state=online,offset=5541,lag=0master_replid:f0c89aa8040dfe869de82ee623a1212240456d76master_replid2:0000000000000000000000000000000000000000master_repl_offset:5541second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:5541 其中repl_backlog_size 复制缓存区大小，默认大小为1M，如果mater_repl_offset在这个范围内，就看是部分复制，否则就开始全量复制。 全量复制先看下图，图画的不是很好见谅1、首先slave会向 master发送一个 psync 命令，因为是第一次，所以不知道run_id 和offset，所以传过来-1表示全量复制2、 master在接收到psync 后，将run_id 和offset 发送给slave，slave存储起来3、master进行bgsave生成rdb ,并将rdb 文件发送给slave4、在bgsave 和send rdb 的过程中可能会产生write 的数据，那么就会把数据存到repl_back_buffer 中 并将buffer发送给slave .5、slave 会清空就数据，然后加载rdb和buffer 将数据存储起来。 部分复制既然是部分复制，那就是slave已经知道了master的run_id 和offset ,所以发送psync 命令带上这两个参数，master 就知道这是部分复制，然后通过偏移量将需要复制的数据发送给slave。 总结主从复制的过程中既用到了全量复制也用到了部分复制，二者是相互配合使用的。看下面的流程图：还有一点需要注意的是，如果master 重启了，那么它的run_id发生了改变，那么依赖它的slave都会进行一次全量复制后在进行部分复制。 哨兵模式哨兵模式介绍在将哨兵模式之前，先来说说主从复制的缺点吧。如果主节点出了问题，那么主节点不在提供服务，需要手动的将从节点切换成主节点。 所以这个时候哨兵模式就出现啦，当主节出现故障时，Redis Sentinel会自动的发现主节点的故障并转移，并通知应用方，实现高可用。 下面是Redis官方文档对于哨兵功能的描述：1、监控（Monitoring）：哨兵会不断地检查主节点和从节点是否运作正常。2、自动故障转移（Automatic failover）：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。3、配置提供者（Configuration provider）：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。4、通知（Notification）：哨兵可以将故障转移的结果发送给客户端。 哨兵模式的结构拓扑图大概如下，也是照书上画的哈哈大意就是1、每一个哨兵节点会监听其他的哨兵节点以及master 和所有的slave2、所有哨兵节点会定期的ping 主节点，监控是否正常3、如果认为主节点出现故障的哨兵数量达到阙zhi，就判定主节点死掉，主节点就会客观下线4、主节点客观下线后，哨兵节点通过选举模式在 slave 中选择出一个升级为主节点5、其他的salve 指向新的主节点6、原来的master 变成 slave ，并且指向新的主节点 引用官方哨兵模式处理流程 每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的Master主服务器，Slave从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。●如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）。●如果一个Master主服务器被标记为主观下线（SDOWN），则正在监视这个Master主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认Master主服务器的确进入了主观下线状态。●当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认Master主服务器进入了主观下线状态（SDOWN）， 则Master主服务器会被标记为客观下线（ODOWN）。●在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master主服务器、Slave从服务器发送 INFO 命令。●当Master主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master主服务器的所有 Slave从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。●若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master主服务器的客观下线状态就会被移除。若 Master主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。 哨兵模式部署1、首先到我们redis安装目录下，发现有sentinel.conf ，我们把它移到我们自己定义的文件夹中，和redis.conf 放在一起。1mv sentinel.conf /usr/local/redis/etc/ 2、修改sentinel.conf文件 123456789port 26379dir /usr/local/redis/etc 这里默认的是“/tmp”，如果你没有这个目录的权限就需要换啦，换一个你有权限的目录，不然后果自负哈哈，我就是从坑里爬起来的sentinel monitor mymaster 192.168.252.53 6379 2sentinel auth-pass mymaster 123456设置监控的主节点，2是一个阈值，代表有两台或两台以上哨兵判断主节点redis不通的话就认定这个节点有问题，实行故障转移。daemonize yes 后台启动logfile "/usr/local/redis/logs/redis_sentinel-26379.log" 加上日志 ，不加也无所谓 注意，这个auth-pass 要放在放在monitor 下面，不然会报错配上一些参数说明：3、将sentinel.conf 复制两份，分别为sentinel26389.conf,sentinel26399.conf并修改这个文件中的prot 和logfile 12345port 26389logfile "/usr/local/redis/logs/redis_sentinel-26389.log" port 26399logfile "/usr/local/redis/logs/redis_sentinel-26399.log" 4、启动哨兵 123redis-sentinel /usr/local/redis/etc/sentinel.confredis-sentinel /usr/local/redis/etc/sentinel26389.confredis-sentinel /usr/local/redis/etc/sentinel26399.conf 查看一下，三个哨兵都已经启动了。 5、验证先看看启动日志,，下图所示表明监控了三个节点。如果没有监控到这三个节点，证明没有配置成功。没有配置成功的原因可能是防火墙导致的，关闭调防火墙。还有就是如果redis-server重启过，那在sentinel.conf中生成的pid 和最后的运行添加的几行需要删除掉，下图这些。然后重新运行。 好的，日志看的没有问题，如果不想看日志，我们来这样验证，我们已经启动了三个redis服务，三个哨兵。我们现在把 master 杀死看看是什么情况。 1kill -9 19688 看日志，三个哨兵的监控日志基本上是一样的，下图贴出三个哨兵的日志，我们就看一下第一个哨兵的日志分析一下。看上图，启动哨兵的时候，监控到了master 6379 和两个slave 6389和6399，以及另外两个哨兵，26389和26399.然后sdown master mymaster 192.168.252.53 6379 表示刚刚我们杀死的master服务。这个时候有一个哨兵表示其主观下线，等到odown 达到我们设置的2时，表明有两个哨兵表示其主观下线，那么就认为6379这个master 已经客观下线。然后通过选举，选取26399 这个哨兵为这三个哨兵的领导者(leader)。23699 这个leader 在salve中选择6399转为 master将6389 这个slave 指向新的 master 6399这个时候重启6379 这个redis服务将6379 这个slave指向新的master 6399好，下面我们来看看界面可以看到master已经切换到6399 服务了，现在我们再切换一下，看下面这张图应该很清晰啦 到此为止，哨兵模式就搭建好啦，当 master 挂掉时，会自动的将一个slave 升级成 master 并将其他的 slave 指向新的master ，从新把原来的master启动后，会变成slave 执行新的master 。 总结写到这，其实还有一部分没有写完，但是感觉实在是太长了，就先写这么多吧，还差一个怎么在项目中使用搭建的哨兵模式，也就是集群模式，怎么做到读写分离，实现高可用的。因为前面这些讲的都是在redis数据库上直接操作，那现在部署好了，怎么在项目代码中使用呢，所以下篇接着将在项目中怎么使用redis集群。喜欢的小伙伴可以持续关注啦。 好了，上面都是题外话，下面总结一下这篇文章吧。1、主从复制是什么以及作用。2、怎样部署一个主从复制（案例一主两从）3、怎样部署哨兵模式（三哨兵）其实我感觉如果你通过这篇文章学会了这三点，就够了，其他的看看当了解。 谢谢大家 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五、redis配置信息以及常用命令]]></title>
    <url>%2F20190808%2F%E4%BA%94%E3%80%81redis%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%E4%BB%A5%E5%8F%8A%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html</url>
    <content type="text"><![CDATA[前言本来不打算写这篇的，因为网上有很多这种的，最后想想，既然打算做一个redis系列，还是把这一篇补上，刚好这段时间有个同事做了一个redis的基础培训，整理的很好，就拿来借用一下，但是我们实际开发中其实用不了那么多，我们对这些配置和命令有个大概的了解就行，也不用死记硬背的把每个命令和配置记住，当然诸位如果能记住那就更好啦。关于redis的介绍就不多说了，持久化，速度快，单线程，基于内存。 配置文件redis的配置文件是redis.conf。我们上次安装的时候把它放在了/use/local/redis/etc/redis.conf,默认的配置文件应该在安装目录下的src/redis.conf配置文件的内容有很多 Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程 daemonize no 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定 pidfile /var/run/redis.pid 指定Redis监听端口，默认端口为6379 port 6379 绑定的主机地址bind 127.0.0.1 当 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 timeout 300 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose loglevel verbose 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null，如果需要存储日志可以设置具体文件名。 logfile “/home/gdmt/mastercom/redis-4.0.5/bin/log_master.log” 设置数据库的数量，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id databases 16 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 save Redis默认配置文件中提供了三个条件： save 900 1 save 300 10 save 60 10000 分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大rdbcompression yes 指定本地数据库文件名，默认值为dump.rdbdbfilename dump.rdb 指定本地数据库存放目录dir “/home/mastercom/redis-4.0.5/bin” 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步slaveof 当master服务设置了密码保护时，slav服务连接master的密码masterauth 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH 命令提供密码，默认关闭requirepass foobared 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息maxclients 10000 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区maxmemory 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为noappendonly no 指定更新日志文件名，默认为appendonly.aof appendfilename appendonly.aof 总结一下上面那么多配置，我和大家一样没有都记住，只是了解一个大概，要用的时候能查就行，上面很多都是默认配置，感觉一般要设置的下面这几个 12345daemonize yesport 端口号bind ip slaveof &lt;masterip&gt; &lt;masterport&gt;requirepass foobared 常用命令针对key的命令123456789101112exists(key)：确认一个key是否存在del(key)：删除一个keytype(key)：返回值的类型keys(pattern)：返回满足给定pattern的所有keyrandomkey：随机返回key空间的一个keyrename(oldname, newname)：重命名keydbsize：返回当前数据库中key的数目expire：设定一个key的活动时间（s）ttl：获得一个key的活动时间move(key, dbindex)：移动当前数据库中的key到dbindex数据库flushdb：删除当前选择数据库中的所有key--慎用flushall：删除所有数据库中的所有key--慎用 真正常用的就 12345exists keydel keytype keydbsizeexpire 针对String类型的命令1234567891011121314set(key, value)：给数据库中名称为key的string赋予值valueget(key)：返回数据库中名称为key的string的valuegetset(key, value)：给名称为key的string赋予上一次的valuemget(key1, key2,…, key N)：返回库中多个string的valuesetnx(key, value)：如果key不存在，添加string，名称为key，值为valuesetex(key, time, value)：向库中添加string，设定过期时间timemset(key N, value N)：批量设置多个string的值msetnx(key N, value N)：如果所有名称为key 的string都不存在 就添加incr(key)：名称为key的string增1操作incrby(key, integer)：名称为key的string增加integerdecr(key)：名称为key的string减1操作decrby(key, integer)：名称为key的string减少integerappend(key, value)：名称为key的string的值附加valuesubstr(key, start, end)：返回名称为key的string的value的子串 我认为常用的 123456setget msetmgetincrdecr 针对List类型12345678910111213rpush(key, value)：在名称为key的list尾添加一个值为value的元素lpush(key, value)：在名称为key的list头添加一个值为value的 元素llen(key)：返回名称为key的list的长度lrange(key, start, end)：返回名称为key的list中start至end之间的元素,-1是最后一位的索引ltrim(key, start, end)：截取名称为key的listlindex(key, index)：返回名称为key的list中index位置的元素lset(key, index, value)：给名称为key的list中index位置的元素赋值lrem(key, count, value)：删除count个key的list中值为value的元素lpop(key)：返回并删除名称为key的list中的首元素rpop(key)：返回并删除名称为key的list中的尾元素blpop(key1, key2,… key N, timeout)：lpop命令的block版本。brpop(key1, key2,… key N, timeout)：rpop的block版本。rpoplpush(srckey, dstkey)：返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部 一样我认为常用的,但是感觉list 用的不多 123456rpushlpushrlangllenlpoprpop 针对set类型1234567891011121314sadd(key, member)：向名称为key的set中添加元素membersrem(key, member) ：删除名称为key的set中的元素memberspop(key) ：随机返回并删除名称为key的set中一个元素smove(srckey, dstkey, member) ：移到集合元素scard(key) ：返回名称为key的set的基数sismember(key, member) ：member是否是名称为key的set的元素sinter(key1, key2,…key N) ：求交集sinterstore(dstkey, (keys)) ：求交集并将交集保存到dstkey的集合sunion(key1, (keys)) ：求并集sunionstore(dstkey, (keys)) ：求并集并将并集保存到dstkey的集合sdiff(key1, (keys)) ：求差集sdiffstore(dstkey, (keys)) ：求差集并将差集保存到dstkey的集合smembers(key) ：返回名称为key的set的所有元素srandmember(key) ：随机返回名称为key的set的一个元素 感觉这个是用的最少了，很多都记不住，就知道添加和读取.zset 和set的都用的很少12345saddsmemberssaddzrange 针对Hash类型1234567891011hset(key, field, value)：向名称为key的hash中添加元素fieldhget(key, field)：返回名称为key的hash中field对应的valuehmget(key, (fields))：返回名称为key的hash中field i对应的valuehmset(key, (fields))：向名称为key的hash中添加元素field hincrby(key, field, integer)：将名称为key的hash中field的value增加integerhexists(key, field)：名称为key的hash中是否存在键为field的域hdel(key, field)：删除名称为key的hash中键为field的域hlen(key)：返回名称为key的hash中元素个数hkeys(key)：返回名称为key的hash中所有键hvals(key)：返回名称为key的hash中所有键对应的valuehgetall(key)：返回名称为key的hash中所有的键（field）及其对应的value hash类型用的比较多，特别是对象存储时候，基本上都是用hash 存储的。 1234hsethgethmsethmget 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四、StringRedisTemplate 和RedisTemlate有什么不同]]></title>
    <url>%2F20190807%2F%E5%9B%9B%E3%80%81StringRedisTemplate%20%E5%92%8CRedisTemlate%E6%9C%89%E4%BB%80%E4%B9%88%E4%B8%8D%E5%90%8C.html</url>
    <content type="text"><![CDATA[前言上一篇文章讲的搭建一个redis+ spring boot 的实例，用到了RedisTemplate，可以成功的访问redis数据库，也可以从中读取数据并显示在页面上，但是呢有瑕疵，那就是其实存在数据库中的Key值是乱码的，类似下面图片这样的。在网上找了一堆的解决办法，看到有StringRedisTemplate 代替RedisTemlate的，所以这边文章就来说说二者到底有什么不同，两者有哪些与缺点，以及在项目中我们如何去使用它。 二者不同先来看看StringRedisTemplate ，为什么先看他，因为它实际上是继承RedisTemplate的，并且源码很简单，只有十几行，所以先来看看它。源码： 12345678910111213141516171819public class StringRedisTemplate extends RedisTemplate&lt;String, String&gt; &#123; public StringRedisTemplate() &#123; this.setKeySerializer(RedisSerializer.string()); this.setValueSerializer(RedisSerializer.string()); this.setHashKeySerializer(RedisSerializer.string()); this.setHashValueSerializer(RedisSerializer.string()); &#125; public StringRedisTemplate(RedisConnectionFactory connectionFactory) &#123; this(); this.setConnectionFactory(connectionFactory); this.afterPropertiesSet(); &#125; protected RedisConnection preProcessConnection(RedisConnection connection, boolean existingConnection) &#123; return new DefaultStringRedisConnection(connection); &#125;&#125; 看源码可以看到，就两个构造方法，构造方法中对key和value 进行序列化，这个序列化是使用RedisSerializer.string()序列化的。看看RedisSerializer.string(）的源码可以发现就是将编码格式设置成了UTF-8再看看带参数的构造函数，多了一个RedisConnectionFactory 参数，这个参数是是在创建连接的时候，设置连接的信息。在网上copy了一个这个方法的实例，可以参考一下：看到这里，大伙差不多就应该知道StringRedisTemplate和RedisTemlate有什么不同了吧。StringRedisTemplate继承了RedisTemlate,但是又仅仅修改了key和values序列化的方式。那就说明StringRedisTemplate和RedisTemlate实际上就是key和values序列化的方式不同啦。那接下来再看看RedisTemlate是怎么序列化的。RedisTemlate的源码就比较多了，我们这里就暂时先看其序列化的：可以看到redisTemplate是使用jdk默认编码格式来序列化的。1new JdkSerializationRedisSerializer(this.classLoader != null ? this.classLoader : this.getClass().getClassLoader()) 所以才出现了文章最开始，使用redisTemplate，存的key值在redis数据库中实际上是乱码的。而StringTemplate不会。 二者优缺关于二者优缺点，我们先来看一个例子：还是上一篇博客的源代码，RedisService层使用的是RedisTemplate，界面上存取，显示都没有问题，这里重点关注一下，getUser()，我这里强转User,在界面上可以正常显示。 1234567891011@Autowired private RedisTemplate redisTemplate; public boolean setUser(User user)&#123; ValueOperations ops=redisTemplate.opsForValue(); ops.set(user.getNickname(),user); return true; &#125; public User getUser(String name)&#123; ValueOperations ops=redisTemplate.opsForValue(); return (User)ops.get(name); &#125; 那我们再使用StringTemplate修改RedisService层 123456789101112@Autowired private StringRedisTemplate stringRedisTemplate; public boolean setUser(User user)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); ops.set(user.getNickname(),user); return true; &#125; public User getUser(String name)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); return (User)ops.get(name); &#125; 再来实行set 和get 就会报错。set 方法报错，说明不能将一个对象直接当做value值传过去，没有进行转换。而RedisTemplate却可以直接把对象当做value值存进去了。因为RedisTemplate在写入和读出的时候都进行了转换。被逼无奈的修改了代码如下；RedisController层 1234567891011121314151617181920212223242526272829@RestControllerpublic class RedisController &#123; @Autowired private RedisService redisService; @RequestMapping("/getUser") public User getUser()&#123; String name="quellan"; return redisService.getUser(name); &#125; @RequestMapping("/setUser") public String setUser()&#123; User user=new User("aa@qq.com","quellan","123456","朱",new Date().getTime()+""); redisService.setUser(user); user.setEmail("bb@qq.com"); redisService.setUserBystringRedisTemplate(user); return "添加成功"; &#125; @RequestMapping("/getUserByStringRedisTemplate") public String getUserByStringRedisTemplate()&#123; String name="quellan"; return redisService.getUserBystringRedisTemplate(name); &#125;&#125; RedisService层 1234567891011121314151617181920212223242526272829303132@Service@Slf4jpublic class RedisService &#123; @Autowired private RedisTemplate redisTemplate; @Autowired private StringRedisTemplate stringRedisTemplate; public boolean setUser(User user)&#123; ValueOperations ops=redisTemplate.opsForValue(); ops.set(user.getNickname(),user); return true; &#125; public User getUser(String name)&#123; ValueOperations ops=redisTemplate.opsForValue(); return (User)ops.get(name); &#125; public boolean setUserBystringRedisTemplate(User user)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); ops.set(user.getNickname(),JSONObject.fromObject(user).toString()); return true; &#125; public String getUserBystringRedisTemplate(String name)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); return JSONObject.fromObject(ops.get(name)).toString(); &#125;&#125; server层就是分别使用RedisTemplate和StringRedisTemplate对User对象进行存和读的操作。特别注意一下StringRedisTemplate由于直接对象不能存，所以先转成string才能存进去的，读出来的时候，也是string形式返回的，如果读出来想要变成user类还得进一步转换。来看看效果现在。先setUser,往redis中插入两条数据，这里可以看到我们代码中设置的key 是一样的，都是quellan来看看获取结果getUser是使用RedisTemplate来获取的，邮箱是aa来看看getUserByStringRedisTemplate,邮箱是bb这里是不是有说明了一个问题：使用RedisTemplate和StringRedisTemplate是相互独立的，在代码中使用相同的key值进行存储，不会替换，两份都会存在，具体原因还是刚刚提到的，其实他们真实存在redis数据库的key 是不一样的，所以才会独立。我们看看redis数据库。可以发现redis数据库中有两个key值，其中key值为quellan的是使用stringRedisTemplate来来存储的，可以看到邮箱为bb。还有一个乱码的key值使用RedisTemplate存储的，在控制台怎么获取这个key值我暂时也不知道，有知道的小伙伴希望告知一下，嘿嘿。 上面说的redisTemplate 和StringRedisTemplate 是独立的，这个在项目中很容易出现坑的，所以小伙伴们得多多注意，不要存的时候用StringRedisTemplate 读的时候用redisTemplate 或者相反。这样可能回到导致死活读不出数据。 总结上面说了这么多，总结一下吧:1、RedisTemplate和StringRedisTemplate存储是分开存的，也就是代码中相同的key实际上在redis数据库中有两个key.原因是RedisTemplate进行了转换，而StringRedisTemplate直接以代码key值存储了。2、如果我们存一些简单的数据结构，建议使用StringRedisTemplate,因为方便在数据库中查看。如果我们存一些复杂的数据接口，比如对象里面还包含多个对象的，就建议使用RedisTemplate了，系统会帮忙转换，省去我们自己转换的麻烦，上面的代码可以看到直接将取到的value值强转成user都没问题，很方便。3、二者可以配合使用，但是不能混着用。 番外redis控制台中文乱码刚刚我们在控制台 get quellan的时候发现userName 是乱码的。那是因为我们进入的方式不对。需要用 1redis-cli --raw -a password 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三、Redis在SpringBoot中使用案例]]></title>
    <url>%2F20190803%2F%E4%B8%89%E3%80%81Redis%E5%9C%A8SpringBoot%E4%B8%AD%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B.html</url>
    <content type="text"><![CDATA[前言最初的目的就想要在项目中把Redis用起来，然后最近公司的项目全部需要转成springboot，所以现在的项目都是Springboot的，自己刚好也研究下Springboot的。所以才有了下文的案例。 项目结构以及相关配置先创建一个springboot 项目，目录结构大体如下。在pom.xml 加入依赖123456789101112131415161718192021&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Redis使用starter--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--注解日志/get/set--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; 说明一下，第一个依赖starter-web 是创建web应用的依赖。lombok 是我自己添加的一个依赖用来注解日志，属性的get/set方法比较方便，其他的三个依赖就是项目中使用redis的依赖啦，一般项目中想要使用redis引入这三个依赖就可以了。 在application.properties中配置redis 1234567891011121314151617#配置redis# Redis数据库索引（默认为0）spring.redis.database=0 # Redis服务器地址spring.redis.host=192.168.252.53# Redis服务器连接端口spring.redis.port=6379 # Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制） 默认 8spring.redis.lettuce.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1spring.redis.lettuce.pool.max-wait=-1# 连接池中的最大空闲连接 默认 8spring.redis.lettuce.pool.max-idle=8# 连接池中的最小空闲连接 默认 0spring.redis.lettuce.pool.min-idle=0 创建Dao层创建dao 包，创建一个User 类,这里使用了lombok提供的@Getter 和@Setter 非常方便，代码看着也很简洁。 1234567891011121314151617181920212223import lombok.Getter;import lombok.Setter;import java.io.Serializable;@Getter@Setterpublic class User implements Serializable &#123; private static final long serialVersionUID = 1L; private Long id; private String userName; private String password; private String email; private String nickname; private String regTime; public User(String email, String nickname, String password, String userName, String regTime) &#123; super(); this.email = email; this.nickname = nickname; this.password = password; this.userName = userName; this.regTime = regTime; &#125;&#125; 创建Service层创建一个service 包，创建一个RedisService类，代码如下： 12345678910111213141516171819202122import com.zlf.learning.Redis.dao.User;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.ValueOperations;import org.springframework.stereotype.Service;@Service@Slf4jpublic class RedisService &#123; @Autowired private RedisTemplate redisTemplate; public boolean setUser(User user)&#123; ValueOperations ops=redisTemplate.opsForValue(); ops.set(user.getNickname(),user); log.info("&#123;&#125;",user.toString()); return true; &#125; public User getUser(String name)&#123; ValueOperations ops=redisTemplate.opsForValue(); return (User) ops.get(name); &#125;&#125; 这里面的代码也非常的清晰，使用到的RedisTemplate ，类似于JdbcTemplate .ValueOperations ops=redisTemplate.opsForValue();就是连接了redis数据库。之后就可以从redis 中获取和添加值啦。 Controller层创建一个controller 包，创建一个RedisController类代码如下： 12345678910111213141516@RestControllerpublic class RedisController &#123; @Autowired private RedisService redisService; @RequestMapping("/getUser") public User getUser()&#123; String name="quellan"; return redisService.getUser(name); &#125; @RequestMapping("/setUser") public String setUser()&#123; User user=new User("aa@qq.com","quellan","123456","朱",new Date().getTime()+""); redisService.setUser(user); return "添加成功"; &#125;&#125; 测试到此为止基础的就已经完全搭建好了，可以测试运行下。启动spring boot项目在redis查一下，发现redis中的key 值并不是我们设置的quellan ,而是一串。这就很难受啦。查了一下，原来是使用的RedisTemplate ，spring-data-redis的RedisTemplate&lt;K, V&gt;模板类在操作redis时默认使用JdkSerializationRedisSerializer来进行序列化.这个具体的放在下一章讲吧，感觉一会讲不完，先跳过哈哈。上面的测试说明项目中已经可以正常使用redis啦。 Session共享按理说到上面就已经差不多，接下来来点骚操作。分布式怎么共享session。简单来说就是一个项目部署了多个，怎么确保一个用户访问不同的项目（用户实际是无感知的，通过Nginx转发，实现负载均衡）时确保session一致。盗一张图来展示一下吧。这张图就是多个Tomcat，那怎么实现session共享呢，就是把session存到redis中，每次去就从redis中取，这样就保证了session共享啦。 那这样是不是每次存session都需要手动存到redis中呢，常理来说当然是的，但是既然是SpringBoot 当然需要不一样啦，只需要增加一个依赖，人家就能帮你自动的加载到redis中。下面来看 增加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 配置上面已经配置好了 增加SpringSession 类在controller 包中加一个SpringSession 类，命名可能不太规范，见谅哈 123456789101112131415@RestControllerpublic class SpringSession &#123; @Value("$&#123;server.port&#125;") Integer port; @RequestMapping("/setSession") public String setSession(HttpSession session)&#123; session.setAttribute("key","quellanAn"); return String.valueOf(port); &#125; @RequestMapping("/getSession") public String getSession(HttpSession session)&#123; return session.getAttribute("key")+":"+port; &#125;&#125; 代码很简单，就是session存一个值，get获取。这里可以看到没有任何操作redis数据库的对吧。 测试场景1先运行项目，查看一下 这些都没有什么，我们去redis中看一下，redis中是有session值的。 测试场景2好的，接下来继续，因为上面还看不出来共享session。我们将项目打包成jar包运行，这样我们就可以多个端口运行啦，模拟分布式。 run.bat 中代码： 123title learingPorject8090chcpjava -jar learningproject-1.0.0.jar --server.port=8090 run2.bat 改一下端口号就好了。然后运行jar包，在界面访问 这样就实现session共享啦。 番外再多说一句，设置session的过期时间在启动类中加上注解设置过期时间1分钟1@EnableRedisHttpSession(maxInactiveIntervalInSeconds=60) 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二、设置Redis远程访问]]></title>
    <url>%2F20190802%2F%E4%BA%8C%E3%80%81%E8%AE%BE%E7%BD%AERedis%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE.html</url>
    <content type="text"><![CDATA[前言昨天在Linux服务器上安装了Redis，那我怎么在本地直接连接redis呢，不需要先登录服务器，然后再连接redis的那种。其实最初的问题是我想在项目中连接redis，进行使用，发现总是报连接不上，但是我通过xshell6连到虚拟机，然后连redis是没有问题的。所以才想应该是有什么配置需要修改才行。才有了下面的记录。 修改配置进入redis.conf目录 1vim /usr/local/redis/etc/redis.conf 1、 将bind 127.0.0.1 注释掉2、将protected-mode yes 改成 protected-mode no 3、重启redis服务昨天用到的123456查PIDnetstat -anp|grep 6379kill -9 PIDredis-server /usr/local/redis/etc/redis.conf 测试在本地运行cmd 1redis-cli -h ip -p port - a password 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一、Redis安装]]></title>
    <url>%2F20190801%2F%E4%B8%80%E3%80%81Redis%E5%AE%89%E8%A3%85.html</url>
    <content type="text"><![CDATA[1、前言其实Redis安装教程网上有很多，这里记录下来主要是记录自己的实践流程。之前学习过一些Redis的知识，但是都是朦朦胧胧的，现在Redis技术越来越火。不管多小的项目都会凑一凑热闹，所以了解一下Redis还是很有必要的。所以才有了现在的开篇。从安装开始吧。 2、windows安装软件：链接：https://pan.baidu.com/s/1JzjuFM30AAJd6jkf5pG7XQ提取码：oowy 我使用的是安装版的，下载下来运行，下一步下一步就可以，注意安装路径，并且将路径加入Path 中就可以了。 安装完成后，在服务中就可以找到Redis 服务。如果没有启动就启动，如果启动了，那么就可以直接使用Redis了。 然后在控制台输入redis-cliredis-cli就可以进去Redis啦，进行相关的操作。这里是没有设置密码，使用的是默认的6370端口。上面输入的keys * 表示查询出redis 中所有的key。 3、Linux安装本人装了一个Linux虚拟机，xshell6连接上去的。 3.1 下载解压首先下载资源：最新的应该是4.0.9123wget http://download.redis.io/releases/redis-4.0.9.tar.gztar xzvf redis-4.0.8.tar.gz 3.2 安装1234cd redis-4.0.9/ //进入解压目录make //编译cd src //进入src 目录make install PREFIX=/usr/local/redis //进行安装到usr/local/下，方便部署开机启动 3.3 部署1234#将conf文件放大etc目录下mkdir /usr/local/redis/etcmv redis.conf /usr/local/redis/etc 进入src目录，移动 mkreleasehdr.sh redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-server到/usr/local/redis/bin/ 1mv mkreleasehdr.sh redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-server /usr/local/redis/bin/ 配置redis为后台启动 1vi /usr/local/redis/etc/redis.conf //将daemonize no 改成daemonize yes 3.4 启动启动服务端：1redis-server /usr/local/redis/etc/redis.conf 启动客户端 1redis-cli 4、设置登录密码刚刚上面也看到了，直接输入 1redis-cli 就直接进去了，这样总感觉不安全，并且我们后面肯定不是通过命令行来访问Redis的，还是需要在项目中使用才行，总会配置Redis的密码的。那怎么设置呢。先来看看我们Redis的密码： 1config get requirepass 发现是没有密码的，现在设置一个，用了get 获取，当然用set设置啦。 1config set requirepass 123456 设置好之后，在想看看自己设置的密码是什么，发现没有权限，哈哈，这就证明你密码设置成功了，现在需要登录密码才能访问数据库。 12auth 123456config get requirepass 但是这样设置的密码有一个问题，那就是把控制台关了，从新进入就会发现密码失效啦，这显然不是我们想要的，原来我们那样设置没有写到conf文件中，是不会重启生效的（如果配置文件中没添加密码 那么redis重启后，密码失效）。 所以我们需要修改redis.conf中的requirepass并重新启动。 杀死Redis服务端1234#找到PIDnetstat -anp|grep 6379kill -9 PID 重启后再进去就发现需要密码啦 也可以这样进入 1redis-cli -p 6379 -a 123456 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
</search>
